{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Fake News Detection on UPFD dataset**"
      ],
      "metadata": {
        "id": "DwRMdI3yMBM-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n"
      ],
      "metadata": {
        "id": "fNsU9gSzsiOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VMFggAT1nPr",
        "outputId": "d62bb717-673b-4345-96d8-74dba2f2a670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install torch geometric\n",
        "import os\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  !pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
        "  !pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
        "  !pip install torch-geometric\n",
        "  !pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
        "\n",
        "import torch_geometric\n",
        "torch_geometric.__version__"
      ],
      "metadata": {
        "id": "krMYyS_vr7cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3fe4dfbc-b71f-4a98-ca14-0d8dc3515a00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp310-cp310-linux_x86_64.whl size=504020 sha256=9befd618a566de7cc6b7cf1ecaf3f9d8eeb6ffd1b40f81e83aadce3362c7eba9\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/f1/2b/3b46d54b134259f58c8363568569053248040859b1a145b3ce\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.25.2)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp310-cp310-linux_x86_64.whl size=1071448 sha256=ab99baf01ec23df0844eac6b8669bca289056c42d13345ff4a3aa3df50ce693b\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/dd/0f/a6a16f9f3b0236733d257b4b4ea91b548b984a341ed3b8f38c\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.5.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.3.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.5.1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m954.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for deepsnap (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmMf4WhBrjDF"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "import pandas as pd\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "\n",
        "from torch_geometric.datasets import UPFD\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GATConv, GCNConv, SAGEConv, global_max_pool, DenseSAGEConv\n",
        "from torch_geometric.transforms import ToUndirected\n",
        "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
        "from torch_geometric.nn import global_mean_pool as gmp\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import DenseDataLoader\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import DenseSAGEConv, dense_diff_pool\n",
        "from torch.utils.data import random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Load Data"
      ],
      "metadata": {
        "id": "uhaorcPis4wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import os.path as osp\n",
        "import torch\n",
        "from typing import Callable, List, Optional\n",
        "\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "\n",
        "from torch_geometric.data import (\n",
        "    Data,\n",
        "    InMemoryDataset,\n",
        "    download_url,\n",
        "    extract_zip,\n",
        ")\n",
        "from torch_geometric.io import read_txt_array\n",
        "from torch_geometric.utils import coalesce, cumsum\n",
        "\n",
        "\n",
        "class UPFD(InMemoryDataset):\n",
        "    url = 'https://drive.usercontent.google.com/download?id={}&export=download&authuser=5&confirm=t'\n",
        "\n",
        "    ids = {\n",
        "        'politifact': '1KOmSrlGcC50PjkvRVbyb_WoWHVql06J-',\n",
        "        'gossipcop': '10bEhVUnJQqsYI9-D9tmSMDHmjBki8lcX',\n",
        "    }\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        root: str,\n",
        "        name: str,\n",
        "        feature: str,\n",
        "        split: str = \"train\",\n",
        "        transform: Optional[Callable] = None,\n",
        "        pre_transform: Optional[Callable] = None,\n",
        "        pre_filter: Optional[Callable] = None,\n",
        "    ) -> None:\n",
        "        self.root = root\n",
        "        self.name = name\n",
        "        self.feature = feature\n",
        "        super().__init__(root, transform, pre_transform, pre_filter)\n",
        "\n",
        "        assert split in ['train', 'val', 'test']\n",
        "        path = self.processed_paths[['train', 'val', 'test'].index(split)]\n",
        "        self.load(path)\n",
        "\n",
        "    @property\n",
        "    def raw_dir(self) -> str:\n",
        "        return osp.join(self.root, self.name, 'raw')\n",
        "\n",
        "    @property\n",
        "    def processed_dir(self) -> str:\n",
        "        return osp.join(self.root, self.name, 'processed', self.feature)\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self) -> List[str]:\n",
        "        return [\n",
        "            'node_graph_id.npy', 'graph_labels.npy', 'A.txt', 'train_idx.npy',\n",
        "            'val_idx.npy', 'test_idx.npy', f'new_{self.feature}_feature.npz'\n",
        "        ]\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self) -> List[str]:\n",
        "        return ['train.pt', 'val.pt', 'test.pt']\n",
        "\n",
        "    def download(self) -> None:\n",
        "        path = download_url(self.url.format(self.ids[self.name]),self.raw_dir)\n",
        "        extract_zip(path, self.raw_dir)\n",
        "        os.remove(path)\n",
        "\n",
        "    def process(self) -> None:\n",
        "        x = sp.load_npz(\n",
        "            osp.join(self.raw_dir, f'new_{self.feature}_feature.npz'))\n",
        "        x = torch.from_numpy(x.todense()).to(torch.float)\n",
        "\n",
        "        edge_index = read_txt_array(osp.join(self.raw_dir, 'A.txt'), sep=',',\n",
        "                                    dtype=torch.long).t()\n",
        "        edge_index = coalesce(edge_index, num_nodes=x.size(0))\n",
        "\n",
        "        y = np.load(osp.join(self.raw_dir, 'graph_labels.npy'))\n",
        "        y = torch.from_numpy(y).to(torch.long)\n",
        "        _, y = y.unique(sorted=True, return_inverse=True)\n",
        "\n",
        "        batch = np.load(osp.join(self.raw_dir, 'node_graph_id.npy'))\n",
        "        batch = torch.from_numpy(batch).to(torch.long)\n",
        "\n",
        "        node_slice = cumsum(batch.bincount())\n",
        "        edge_slice = cumsum(batch[edge_index[0]].bincount())\n",
        "        graph_slice = torch.arange(y.size(0) + 1)\n",
        "        self.slices = {\n",
        "            'x': node_slice,\n",
        "            'edge_index': edge_slice,\n",
        "            'y': graph_slice\n",
        "        }\n",
        "\n",
        "        edge_index -= node_slice[batch[edge_index[0]]].view(1, -1)\n",
        "        self.data = Data(x=x, edge_index=edge_index, y=y)\n",
        "\n",
        "        for path, split in zip(self.processed_paths, ['train', 'val', 'test']):\n",
        "            idx = np.load(osp.join(self.raw_dir, f'{split}_idx.npy')).tolist()\n",
        "            data_list = [self.get(i) for i in idx]\n",
        "            if self.pre_filter is not None:\n",
        "                data_list = [d for d in data_list if self.pre_filter(d)]\n",
        "            if self.pre_transform is not None:\n",
        "                data_list = [self.pre_transform(d) for d in data_list]\n",
        "            self.save(data_list, path)\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}({len(self)}, name={self.name}, '\n",
        "                f'feature={self.feature})')"
      ],
      "metadata": {
        "id": "uz-vkL2ETaTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(split):\n",
        "  data_profile =  UPFD('/content/drive/MyDrive', \"politifact\", \"profile\", split, ToUndirected())\n",
        "  data_bert =  UPFD('/content/drive/MyDrive', \"politifact\", \"bert\", split, ToUndirected())\n",
        "  data_profile.data.x = torch.cat((data_profile.data.x, data_bert.data.x),dim =1)\n",
        "\n",
        "  return data_profile"
      ],
      "metadata": {
        "id": "MwS27n4ms7jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve data\n",
        "train_data = load_data('train')\n",
        "test_data = load_data('test')\n",
        "val_data = load_data('val')\n",
        "\n",
        "# Prepare data loader for GNN\n",
        "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=128, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "YV9G0q8Cug9K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a03e04-42a9-47fa-faba-0ad329810953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "Done!\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bi_GCN**"
      ],
      "metadata": {
        "id": "3uA4N1lM4lYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmDhzz-jXBuI",
        "outputId": "6eaec8f9-84dd-4811-e7b7-78e67aa16c51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting utils\n",
            "  Downloading utils-1.0.2.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: utils\n",
            "  Building wheel for utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for utils: filename=utils-1.0.2-py2.py3-none-any.whl size=13906 sha256=6d29d1913171e77cf18ac6cfd817dca1adc417f5fa1d0126f851e305270fc877\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/39/f5/9d0ca31dba85773ececf0a7f5469f18810e1c8a8ed9da28ca7\n",
            "Successfully built utils\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras\n",
        "!pip install scikit-learn\n",
        "!pip install tqdm\n",
        "!pip install numpy\n",
        "!pip install scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCFjsWaZXXr0",
        "outputId": "91939b20-f553-444e-bbf2-db236af21de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append(os.getcwd())\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "import copy as cp\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import random_split\n",
        "from torch_scatter import scatter_mean\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import DataLoader, DataListLoader\n",
        "from torch_geometric.nn import DataParallel\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/')\n",
        "from data_loader import *\n",
        "from eval_helper import *"
      ],
      "metadata": {
        "id": "u8RuFMqjWskF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append(os.getcwd())\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "import copy as cp\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import random_split\n",
        "from torch_scatter import scatter_mean\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import DataLoader, DataListLoader\n",
        "from torch_geometric.nn import DataParallel\n",
        "\n",
        "\n",
        "class TDrumorGCN(torch.nn.Module):\n",
        "\tdef __init__(self, in_feats, hid_feats, out_feats):\n",
        "\t\tsuper(TDrumorGCN, self).__init__()\n",
        "\t\tself.conv1 = GCNConv(in_feats, hid_feats)\n",
        "\t\tself.conv2 = GCNConv(hid_feats+in_feats, out_feats)\n",
        "\n",
        "\tdef forward(self, data):\n",
        "\t\tx, edge_index = data.x, data.edge_index\n",
        "\t\tx1 = cp.copy(x.float())\n",
        "\t\tx = self.conv1(x, edge_index)\n",
        "\t\tx2 = cp.copy(x)\n",
        "\t\trootindex = data.root_index\n",
        "\t\troot_extend = torch.zeros(len(data.batch), x1.size(1)).to(rootindex.device)\n",
        "\t\tbatch_size = max(data.batch) + 1\n",
        "\n",
        "\t\tfor num_batch in range(batch_size):\n",
        "\t\t\tindex = (torch.eq(data.batch, num_batch))\n",
        "\t\t\troot_extend[index] = x1[rootindex[num_batch]]\n",
        "\t\tx = torch.cat((x, root_extend), 1)\n",
        "\n",
        "\t\tx = F.relu(x)\n",
        "\t\tx = F.dropout(x, training=self.training)\n",
        "\t\tx = self.conv2(x, edge_index)\n",
        "\t\tx = F.relu(x)\n",
        "\t\troot_extend = torch.zeros(len(data.batch), x2.size(1)).to(rootindex.device)\n",
        "\t\tfor num_batch in range(batch_size):\n",
        "\t\t\tindex = (torch.eq(data.batch, num_batch))\n",
        "\t\t\troot_extend[index] = x2[rootindex[num_batch]]\n",
        "\t\tx = torch.cat((x, root_extend), 1)\n",
        "\t\tx = scatter_mean(x, data.batch, dim=0)\n",
        "\n",
        "\t\treturn x\n",
        "\n",
        "\n",
        "class BUrumorGCN(torch.nn.Module):\n",
        "\tdef __init__(self, in_feats, hid_feats, out_feats):\n",
        "\t\tsuper(BUrumorGCN, self).__init__()\n",
        "\t\tself.conv1 = GCNConv(in_feats, hid_feats)\n",
        "\t\tself.conv2 = GCNConv(hid_feats+in_feats, out_feats)\n",
        "\n",
        "\tdef forward(self, data):\n",
        "\t\tx, edge_index = data.x, data.BU_edge_index\n",
        "\t\tx1 = cp.copy(x.float())\n",
        "\t\tx = self.conv1(x, edge_index)\n",
        "\t\tx2 = cp.copy(x)\n",
        "\n",
        "\t\trootindex = data.root_index\n",
        "\t\troot_extend = torch.zeros(len(data.batch), x1.size(1)).to(rootindex.device)\n",
        "\t\tbatch_size = max(data.batch) + 1\n",
        "\t\tfor num_batch in range(batch_size):\n",
        "\t\t\tindex = (torch.eq(data.batch, num_batch))\n",
        "\t\t\troot_extend[index] = x1[rootindex[num_batch]]\n",
        "\t\tx = torch.cat((x, root_extend), 1)\n",
        "\n",
        "\t\tx = F.relu(x)\n",
        "\t\tx = F.dropout(x, training=self.training)\n",
        "\t\tx = self.conv2(x, edge_index)\n",
        "\t\tx = F.relu(x)\n",
        "\t\troot_extend = torch.zeros(len(data.batch), x2.size(1)).to(rootindex.device)\n",
        "\t\tfor num_batch in range(batch_size):\n",
        "\t\t\tindex = (torch.eq(data.batch, num_batch))\n",
        "\t\t\troot_extend[index] = x2[rootindex[num_batch]]\n",
        "\t\tx = torch.cat((x, root_extend), 1)\n",
        "\n",
        "\t\tx = scatter_mean(x, data.batch, dim=0)\n",
        "\t\treturn x\n",
        "\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "\tdef __init__(self, in_feats, hid_feats, out_feats):\n",
        "\t\tsuper(Net, self).__init__()\n",
        "\t\tself.TDrumorGCN = TDrumorGCN(in_feats, hid_feats, out_feats)\n",
        "\t\tself.BUrumorGCN = BUrumorGCN(in_feats, hid_feats, out_feats)\n",
        "\t\tself.fc = torch.nn.Linear((out_feats+hid_feats) * 2, 2)\n",
        "\n",
        "\tdef forward(self, data):\n",
        "\t\tTD_x = self.TDrumorGCN(data)\n",
        "\t\tBU_x = self.BUrumorGCN(data)\n",
        "\t\tx = torch.cat((TD_x, BU_x), 1)\n",
        "\t\tx = self.fc(x)\n",
        "\t\tx = F.log_softmax(x, dim=1)\n",
        "\t\treturn x\n",
        "\n",
        "\n",
        "def compute_test(loader, verbose=False):\n",
        "\tmodel.eval()\n",
        "\tloss_test = 0.0\n",
        "\tout_log = []\n",
        "\twith torch.no_grad():\n",
        "\t\tfor data in loader:\n",
        "\t\t\tif not args.multi_gpu:\n",
        "\t\t\t\tdata = data.to(args.device)\n",
        "\t\t\tout = model(data)\n",
        "\t\t\tif args.multi_gpu:\n",
        "\t\t\t\ty = torch.cat([d.y for d in data]).to(out.device)\n",
        "\t\t\telse:\n",
        "\t\t\t\ty = data.y\n",
        "\t\t\tif verbose:\n",
        "\t\t\t\tprint(F.softmax(out, dim=1).cpu().numpy())\n",
        "\t\t\tout_log.append([F.softmax(out, dim=1), y])\n",
        "\t\t\tloss_test += F.nll_loss(out, y).item()\n",
        "\treturn eval_deep(out_log, loader), loss_test"
      ],
      "metadata": {
        "id": "fQBOYq38NyEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bi_GCN Model Performance**"
      ],
      "metadata": {
        "id": "7UqNYwhHX6Kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument('--seed', type=int, default=777, help='random seed')\n",
        "parser.add_argument('--device', type=str, default='cpu', help='specify cuda devices')\n",
        "# hyper-parameters\n",
        "parser.add_argument('--dataset', type=str, default='politifact', help='[politifact, gossipcop]')\n",
        "parser.add_argument('--batch_size', type=int, default=128, help='batch size')\n",
        "parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
        "parser.add_argument('--weight_decay', type=float, default=0.001, help='weight decay')\n",
        "parser.add_argument('--nhid', type=int, default=128, help='hidden size')\n",
        "parser.add_argument('--TDdroprate', type=float, default=0.2, help='dropout ratio')\n",
        "parser.add_argument('--BUdroprate', type=float, default=0.2, help='dropout ratio')\n",
        "parser.add_argument('--epochs', type=int, default=50, help='maximum number of epochs')\n",
        "parser.add_argument('--multi_gpu', type=bool, default=False, help='multi-gpu mode')\n",
        "parser.add_argument('--feature', type=str, default='bert', help='feature type, [profile, spacy, bert, content]')\n",
        "\n",
        "# args = parser.parse_args()\n",
        "args, _ = parser.parse_known_args()\n",
        "torch.manual_seed(args.seed)\n",
        "if torch.cuda.is_available():\n",
        "\ttorch.cuda.manual_seed(args.seed)\n",
        "\n",
        "dataset = FNNDataset(root='/content/drive/MyDrive', feature=args.feature, empty=False, name=args.dataset,\n",
        "\t\t\t\t\t transform=DropEdge(args.TDdroprate, args.BUdroprate))\n",
        "\n",
        "args.num_classes = dataset.num_classes\n",
        "args.num_features = dataset.num_features\n",
        "\n",
        "\n",
        "num_training = int(len(dataset) * 0.2)\n",
        "num_val = int(len(dataset) * 0.1)\n",
        "num_test = len(dataset) - (num_training + num_val)\n",
        "training_set, validation_set, test_set = random_split(dataset, [num_training, num_val, num_test])\n",
        "\n",
        "if args.multi_gpu:\n",
        "\tloader = DataListLoader\n",
        "else:\n",
        "\tloader = DataLoader\n",
        "\n",
        "train_loader = loader(training_set, batch_size=args.batch_size, shuffle=True)\n",
        "val_loader = loader(validation_set, batch_size=args.batch_size, shuffle=False)\n",
        "test_loader = loader(test_set, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "model = Net(args.num_features, args.nhid, args.nhid)\n",
        "if args.multi_gpu:\n",
        "\tmodel = DataParallel(model)\n",
        "model = model.to(args.device)\n",
        "\n",
        "if not args.multi_gpu:\n",
        "\tBU_params = list(map(id, model.BUrumorGCN.conv1.parameters()))\n",
        "\tBU_params += list(map(id, model.BUrumorGCN.conv2.parameters()))\n",
        "\tbase_params = filter(lambda p: id(p) not in BU_params, model.parameters())\n",
        "\toptimizer = torch.optim.Adam([\n",
        "\t\t{'params': base_params},\n",
        "\t\t{'params': model.BUrumorGCN.conv1.parameters(), 'lr': args.lr / 5},\n",
        "\t\t{'params': model.BUrumorGCN.conv2.parameters(), 'lr': args.lr / 5}\n",
        "\t], lr=args.lr, weight_decay=args.weight_decay)\n",
        "else:\n",
        "\tBU_params = list(map(id, model.module.BUrumorGCN.conv1.parameters()))\n",
        "\tBU_params += list(map(id, model.module.BUrumorGCN.conv2.parameters()))\n",
        "\tbase_params = filter(lambda p: id(p) not in BU_params, model.parameters())\n",
        "\toptimizer = torch.optim.Adam([\n",
        "\t\t{'params': base_params},\n",
        "\t\t{'params': model.module.BUrumorGCN.conv1.parameters(), 'lr': args.lr / 5},\n",
        "\t\t{'params': model.module.BUrumorGCN.conv2.parameters(), 'lr': args.lr / 5}\n",
        "\t], lr=args.lr, weight_decay=args.weight_decay)\n",
        "\n"
      ],
      "metadata": {
        "id": "z6odF2GaXwpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b708c357-0825-41ea-cf75-1bdd1138bf66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "Done!\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bi_GCN Run Model**"
      ],
      "metadata": {
        "id": "cymzBHdHX0k8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "\tmodel.train()\n",
        "\tfor epoch in tqdm(range(args.epochs)):\n",
        "\t\tout_log = []\n",
        "\t\tloss_train = 0.0\n",
        "\t\tfor i, data in enumerate(train_loader):\n",
        "\t\t\toptimizer.zero_grad()\n",
        "\t\t\tif not args.multi_gpu:\n",
        "\t\t\t\tdata = data.to(args.device)\n",
        "\t\t\tout = model(data)\n",
        "\t\t\tif args.multi_gpu:\n",
        "\t\t\t\ty = torch.cat([d.y for d in data]).to(out.device)\n",
        "\t\t\telse:\n",
        "\t\t\t\ty = data.y\n",
        "\t\t\tloss = F.nll_loss(out, y)\n",
        "\t\t\tloss.backward()\n",
        "\t\t\toptimizer.step()\n",
        "\t\t\tloss_train += loss.item()\n",
        "\t\t\tout_log.append([F.softmax(out, dim=1), y])\n",
        "\t\tacc_train, _, _, _, recall_train, auc_train, _ = eval_deep(out_log, train_loader)\n",
        "\t\t[acc_val, _, _, _, recall_val, auc_val, _], loss_val = compute_test(val_loader)\n",
        "\t\tprint(f'loss_train: {loss_train:.4f}, acc_train: {acc_train:.4f},'\n",
        "\t\t\t  f' recall_train: {recall_train:.4f}, auc_train: {auc_train:.4f},'\n",
        "\t\t\t  f' loss_val: {loss_val:.4f}, acc_val: {acc_val:.4f},'\n",
        "\t\t\t  f' recall_val: {recall_val:.4f}, auc_val: {auc_val:.4f}')\n",
        "\n",
        "\t[acc, f1_macro, f1_micro, precision, recall, auc, ap], test_loss = compute_test(test_loader, verbose=False)\n",
        "\tprint(f'Test set results: acc: {acc:.4f}, f1_macro: {f1_macro:.4f}, f1_micro: {f1_micro:.4f},'\n",
        "\t\t  f'precision: {precision:.4f}, recall: {recall:.4f}, auc: {auc:.4f}, ap: {ap:.4f}')\n",
        "acc_BiGCN = acc\n",
        "f1_BiGCN = f1_macro\n",
        "auc_BiGCN = auc"
      ],
      "metadata": {
        "id": "hoAXXBBvXz4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b26f368-7e18-4076-9c32-bf0a834378ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 1/50 [00:02<02:22,  2.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.7047, acc_train: 0.5161, recall_train: 0.5000, auc_train: 0.4915, loss_val: 1.3378, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.3889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [00:04<01:44,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.9370, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.5032, loss_val: 0.8809, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.4530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [00:06<01:35,  2.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6984, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.6635, loss_val: 0.6645, acc_val: 0.5806, recall_val: 0.8333, auc_val: 0.6026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [00:11<02:31,  3.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6862, acc_train: 0.5323, recall_train: 0.8846, auc_train: 0.6859, loss_val: 0.6802, acc_val: 0.6129, recall_val: 0.9444, auc_val: 0.6325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [00:15<02:29,  3.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.7555, acc_train: 0.4516, recall_train: 1.0000, auc_train: 0.6880, loss_val: 0.6571, acc_val: 0.5806, recall_val: 0.8333, auc_val: 0.6239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [00:18<02:23,  3.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6725, acc_train: 0.5968, recall_train: 1.0000, auc_train: 0.7585, loss_val: 0.6876, acc_val: 0.5806, recall_val: 0.3333, auc_val: 0.6410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [00:22<02:32,  3.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.5983, acc_train: 0.6935, recall_train: 0.3077, auc_train: 0.9177, loss_val: 0.8242, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.6966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [00:26<02:40,  3.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6211, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.9306, loss_val: 0.9032, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.6154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [00:30<02:40,  3.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6420, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.9038, loss_val: 0.8374, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.7350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [00:34<02:32,  3.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6035, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.9487, loss_val: 0.7109, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.7692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [00:38<02:36,  4.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.5486, acc_train: 0.6613, recall_train: 0.1923, auc_train: 0.9818, loss_val: 0.6313, acc_val: 0.6774, recall_val: 0.7222, auc_val: 0.7179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [00:42<02:32,  4.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.5321, acc_train: 0.8710, recall_train: 0.9231, auc_train: 0.9669, loss_val: 0.6182, acc_val: 0.6774, recall_val: 0.8889, auc_val: 0.6752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [00:47<02:32,  4.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.5443, acc_train: 0.7742, recall_train: 1.0000, auc_train: 0.9434, loss_val: 0.6085, acc_val: 0.6774, recall_val: 0.8889, auc_val: 0.7051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [00:49<02:11,  3.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.5235, acc_train: 0.7903, recall_train: 1.0000, auc_train: 0.9562, loss_val: 0.6058, acc_val: 0.6774, recall_val: 0.7222, auc_val: 0.7393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [00:52<01:53,  3.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.4777, acc_train: 0.9355, recall_train: 1.0000, auc_train: 0.9829, loss_val: 0.6536, acc_val: 0.6452, recall_val: 0.4444, auc_val: 0.7692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [00:54<01:39,  2.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.4513, acc_train: 0.8548, recall_train: 0.6538, auc_train: 0.9936, loss_val: 0.7150, acc_val: 0.5806, recall_val: 0.2778, auc_val: 0.7863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [00:55<01:22,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.4538, acc_train: 0.7097, recall_train: 0.3077, auc_train: 0.9925, loss_val: 0.7125, acc_val: 0.5806, recall_val: 0.2778, auc_val: 0.8077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [00:57<01:10,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.4369, acc_train: 0.7097, recall_train: 0.3077, auc_train: 0.9968, loss_val: 0.6548, acc_val: 0.6774, recall_val: 0.5000, auc_val: 0.7991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [00:58<01:02,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.3994, acc_train: 0.9032, recall_train: 0.7692, auc_train: 0.9957, loss_val: 0.5950, acc_val: 0.7419, recall_val: 0.7222, auc_val: 0.7863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [01:00<00:57,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.3726, acc_train: 0.9677, recall_train: 1.0000, auc_train: 0.9968, loss_val: 0.5728, acc_val: 0.7097, recall_val: 0.8333, auc_val: 0.7821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [01:02<00:51,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.3648, acc_train: 0.9355, recall_train: 1.0000, auc_train: 0.9968, loss_val: 0.5651, acc_val: 0.7097, recall_val: 0.8333, auc_val: 0.7906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [01:03<00:48,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.3476, acc_train: 0.9355, recall_train: 1.0000, auc_train: 0.9968, loss_val: 0.5737, acc_val: 0.7097, recall_val: 0.7222, auc_val: 0.7949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [01:06<00:53,  1.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.3138, acc_train: 0.9516, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.6008, acc_val: 0.7419, recall_val: 0.6667, auc_val: 0.8248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [01:08<00:51,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.2937, acc_train: 0.9839, recall_train: 0.9615, auc_train: 1.0000, loss_val: 0.6264, acc_val: 0.7419, recall_val: 0.6111, auc_val: 0.8376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [01:09<00:46,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.2838, acc_train: 0.9355, recall_train: 0.8462, auc_train: 1.0000, loss_val: 0.6113, acc_val: 0.7419, recall_val: 0.6111, auc_val: 0.8504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [01:11<00:42,  1.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.2634, acc_train: 0.9677, recall_train: 0.9231, auc_train: 1.0000, loss_val: 0.5699, acc_val: 0.7742, recall_val: 0.7222, auc_val: 0.8376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [01:13<00:40,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.2361, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5448, acc_val: 0.7419, recall_val: 0.7222, auc_val: 0.8462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [01:14<00:36,  1.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.2226, acc_train: 0.9677, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5380, acc_val: 0.7419, recall_val: 0.7222, auc_val: 0.8504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [01:16<00:35,  1.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.2112, acc_train: 0.9516, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5361, acc_val: 0.7419, recall_val: 0.7222, auc_val: 0.8590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [01:18<00:34,  1.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1883, acc_train: 0.9839, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5649, acc_val: 0.7742, recall_val: 0.7222, auc_val: 0.8547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [01:20<00:36,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1711, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5847, acc_val: 0.7742, recall_val: 0.6667, auc_val: 0.8632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [01:22<00:34,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1623, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5760, acc_val: 0.7419, recall_val: 0.6667, auc_val: 0.8675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [01:23<00:30,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1482, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5410, acc_val: 0.7742, recall_val: 0.7222, auc_val: 0.8889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [01:25<00:26,  1.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1328, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5248, acc_val: 0.7742, recall_val: 0.7778, auc_val: 0.8846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [01:26<00:24,  1.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1216, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5205, acc_val: 0.7742, recall_val: 0.7778, auc_val: 0.8846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 36/50 [01:28<00:22,  1.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1117, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5402, acc_val: 0.7742, recall_val: 0.7222, auc_val: 0.8846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 37/50 [01:30<00:21,  1.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1000, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5564, acc_val: 0.7742, recall_val: 0.7222, auc_val: 0.8932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 38/50 [01:32<00:21,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0879, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5777, acc_val: 0.7742, recall_val: 0.6667, auc_val: 0.8889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 39/50 [01:34<00:21,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0826, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5760, acc_val: 0.7742, recall_val: 0.6667, auc_val: 0.8889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 40/50 [01:36<00:18,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0745, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5509, acc_val: 0.8065, recall_val: 0.7778, auc_val: 0.8889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 41/50 [01:37<00:15,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0643, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5513, acc_val: 0.8065, recall_val: 0.7778, auc_val: 0.8974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 42/50 [01:39<00:13,  1.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0601, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5501, acc_val: 0.8065, recall_val: 0.7778, auc_val: 0.8974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 43/50 [01:40<00:11,  1.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0540, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5657, acc_val: 0.8065, recall_val: 0.7778, auc_val: 0.9060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 44/50 [01:42<00:10,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0471, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5949, acc_val: 0.7742, recall_val: 0.6667, auc_val: 0.9017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 45/50 [01:44<00:08,  1.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0432, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5925, acc_val: 0.7742, recall_val: 0.6667, auc_val: 0.9060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 46/50 [01:46<00:07,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0390, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5965, acc_val: 0.8387, recall_val: 0.7778, auc_val: 0.9103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 47/50 [01:48<00:05,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0341, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5845, acc_val: 0.8387, recall_val: 0.7778, auc_val: 0.9103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 48/50 [01:50<00:03,  1.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0310, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5746, acc_val: 0.8387, recall_val: 0.7778, auc_val: 0.9103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 49/50 [01:51<00:01,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0297, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5812, acc_val: 0.8710, recall_val: 0.8333, auc_val: 0.9103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [01:53<00:00,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0268, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5962, acc_val: 0.8387, recall_val: 0.7778, auc_val: 0.9103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set results: acc: 0.8326, f1_macro: 0.8318, f1_micro: 0.8326,precision: 0.8715, recall: 0.7867, auc: 0.8782, ap: 0.8828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GraphSAGE**"
      ],
      "metadata": {
        "id": "-EqAH6kK4-k8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GNN Architecture**"
      ],
      "metadata": {
        "id": "-1-EseOx-VeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import copy as cp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import global_max_pool as gmp\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, DataParallel\n",
        "from torch.utils.data import random_split\n",
        "from torch_geometric.data import DataLoader, DataListLoader\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "The GCN, GAT, and GraphSAGE implementation\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "\tdef __init__(self, args, concat=False):\n",
        "\t\tsuper(Model, self).__init__()\n",
        "\t\tself.args = args\n",
        "\t\tself.num_features = args.num_features\n",
        "\t\tself.nhid = args.nhid\n",
        "\t\tself.num_classes = args.num_classes\n",
        "\t\tself.dropout_ratio = args.dropout_ratio\n",
        "\t\tself.model = args.model\n",
        "\t\tself.concat = concat\n",
        "\n",
        "\t\tif self.model == 'gcn':\n",
        "\t\t\tself.conv1 = GCNConv(self.num_features, self.nhid)\n",
        "\t\telif self.model == 'sage':\n",
        "\t\t\tself.conv1 = SAGEConv(self.num_features, self.nhid)\n",
        "\t\telif self.model == 'gat':\n",
        "\t\t\tself.conv1 = GATConv(self.num_features, self.nhid)\n",
        "\n",
        "\t\tif self.concat:\n",
        "\t\t\tself.lin0 = torch.nn.Linear(self.num_features, self.nhid)\n",
        "\t\t\tself.lin1 = torch.nn.Linear(self.nhid * 2, self.nhid)\n",
        "\n",
        "\t\tself.lin2 = torch.nn.Linear(self.nhid, self.num_classes)\n",
        "\n",
        "\tdef forward(self, data):\n",
        "\n",
        "\t\tx, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "\t\tedge_attr = None\n",
        "\n",
        "\t\tx = F.relu(self.conv1(x, edge_index, edge_attr))\n",
        "\t\tx = gmp(x, batch)\n",
        "\n",
        "\t\tif self.concat:\n",
        "\t\t\tnews = torch.stack([data.x[(data.batch == idx).nonzero().squeeze()[0]] for idx in range(data.num_graphs)])\n",
        "\t\t\tnews = F.relu(self.lin0(news))\n",
        "\t\t\tx = torch.cat([x, news], dim=1)\n",
        "\t\t\tx = F.relu(self.lin1(x))\n",
        "\n",
        "\t\tx = F.log_softmax(self.lin2(x), dim=-1)\n",
        "\n",
        "\t\treturn x"
      ],
      "metadata": {
        "id": "_xrOic-kn50c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *GNN Model Performance*"
      ],
      "metadata": {
        "id": "_Eb_hgBV-xI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def compute_test(loader, verbose=False):\n",
        "\tmodel.eval()\n",
        "\tloss_test = 0.0\n",
        "\tout_log = []\n",
        "\tfor data in loader:\n",
        "\t\tif not args.multi_gpu:\n",
        "\t\t\tdata = data.to(args.device)\n",
        "\t\tout = model(data)\n",
        "\t\tif args.multi_gpu:\n",
        "\t\t\ty = torch.cat([d.y.unsqueeze(0) for d in data]).squeeze().to(out.device)\n",
        "\t\telse:\n",
        "\t\t\ty = data.y\n",
        "\t\tif verbose:\n",
        "\t\t\tprint(F.softmax(out, dim=1).cpu().numpy())\n",
        "\t\tout_log.append([F.softmax(out, dim=1), y])\n",
        "\t\tloss_test += F.nll_loss(out, y).item()\n",
        "\treturn eval_deep(out_log, loader), loss_test"
      ],
      "metadata": {
        "id": "25_V2saz-cIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GNN Run Model**"
      ],
      "metadata": {
        "id": "8JNcfsS2-o8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument('--seed', type=int, default=777, help='random seed')\n",
        "parser.add_argument('--device', type=str, default='cpu', help='specify cuda devices')\n",
        "\n",
        "# hyper-parameters\n",
        "parser.add_argument('--dataset', type=str, default='politifact', help='[politifact, gossipcop]')\n",
        "parser.add_argument('--batch_size', type=int, default=128, help='batch size')\n",
        "parser.add_argument('--lr', type=float, default=0.01, help='learning rate')\n",
        "parser.add_argument('--weight_decay', type=float, default=0.01, help='weight decay')\n",
        "parser.add_argument('--nhid', type=int, default=128, help='hidden size')\n",
        "parser.add_argument('--dropout_ratio', type=float, default=0.0, help='dropout ratio')\n",
        "parser.add_argument('--epochs', type=int, default=45, help='maximum number of epochs')\n",
        "parser.add_argument('--concat', type=bool, default=True, help='whether concat news embedding and graph embedding')\n",
        "parser.add_argument('--multi_gpu', type=bool, default=False, help='multi-gpu mode')\n",
        "parser.add_argument('--feature', type=str, default='spacy', help='feature type, [profile, spacy, bert, content]')\n",
        "parser.add_argument('--model', type=str, default='sage', help='model type, [gcn, gat, sage]')\n",
        "\n",
        "# args = parser.parse_args()\n",
        "args, _ = parser.parse_known_args()\n",
        "torch.manual_seed(args.seed)\n",
        "if torch.cuda.is_available():\n",
        "\ttorch.cuda.manual_seed(args.seed)\n",
        "\n",
        "dataset = FNNDataset(root='/content/drive/MyDrive', feature=args.feature, empty=False, name=args.dataset, transform=ToUndirected())\n",
        "\n",
        "args.num_classes = dataset.num_classes\n",
        "args.num_features = dataset.num_features\n",
        "\n",
        "print(args)\n",
        "\n",
        "num_training = int(len(dataset) * 0.2)\n",
        "num_val = int(len(dataset) * 0.1)\n",
        "num_test = len(dataset) - (num_training + num_val)\n",
        "training_set, validation_set, test_set = random_split(dataset, [num_training, num_val, num_test])\n",
        "\n",
        "if args.multi_gpu:\n",
        "\tloader = DataListLoader\n",
        "else:\n",
        "\tloader = DataLoader\n",
        "\n",
        "train_loader = loader(training_set, batch_size=args.batch_size, shuffle=True)\n",
        "val_loader = loader(validation_set, batch_size=args.batch_size, shuffle=False)\n",
        "test_loader = loader(test_set, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "model = Model(args, concat=args.concat)\n",
        "if args.multi_gpu:\n",
        "\tmodel = DataParallel(model)\n",
        "model = model.to(args.device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVe9jkBr-cD4",
        "outputId": "6ad95cd0-3a70-4ebe-aa06-fe9c37c4e910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(seed=777, device='cpu', dataset='politifact', batch_size=128, lr=0.01, weight_decay=0.01, nhid=128, dropout_ratio=0.0, epochs=45, concat=True, multi_gpu=False, feature='spacy', model='sage', num_classes=2, num_features=300)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "min_loss = 1e10\n",
        "val_loss_values = []\n",
        "best_epoch = 0\n",
        "\n",
        "t = time.time()\n",
        "model.train()\n",
        "for epoch in tqdm(range(args.epochs)):\n",
        "\tloss_train = 0.0\n",
        "\tout_log = []\n",
        "\tfor i, data in enumerate(train_loader):\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\tif not args.multi_gpu:\n",
        "\t\t\tdata = data.to(args.device)\n",
        "\t\tout = model(data)\n",
        "\t\tif args.multi_gpu:\n",
        "\t\t\ty = torch.cat([d.y.unsqueeze(0) for d in data]).squeeze().to(out.device)\n",
        "\t\telse:\n",
        "\t\t\ty = data.y\n",
        "\t\tloss = F.nll_loss(out, y)\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n",
        "\t\tloss_train += loss.item()\n",
        "\t\tout_log.append([F.softmax(out, dim=1), y])\n",
        "\tacc_train, _, _, _, recall_train, auc_train, _ = eval_deep(out_log, train_loader)\n",
        "\t[acc_val, _, _, _, recall_val, auc_val, _], loss_val = compute_test(val_loader)\n",
        "\tprint(f'loss_train: {loss_train:.4f}, acc_train: {acc_train:.4f},'\n",
        "\t\t\t  f' recall_train: {recall_train:.4f}, auc_train: {auc_train:.4f},'\n",
        "\t\t\t  f' loss_val: {loss_val:.4f}, acc_val: {acc_val:.4f},'\n",
        "\t\t\t  f' recall_val: {recall_val:.4f}, auc_val: {auc_val:.4f}')\n",
        "\n",
        "[acc, f1_macro, f1_micro, precision, recall, auc, ap], test_loss = compute_test(test_loader, verbose=False)\n",
        "print(f'Test set results: acc: {acc:.4f}, f1_macro: {f1_macro:.4f}, f1_micro: {f1_micro:.4f}, '\n",
        "\t\t  f'precision: {precision:.4f}, recall: {recall:.4f}, auc: {auc:.4f}, ap: {ap:.4f}')\n",
        "acc_GraphSAGE = acc\n",
        "f1_GraphSAGE = f1_macro\n",
        "auc_GraphSAGE = auc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_5hN8e1-b_j",
        "outputId": "060eb1fc-cf61-45c9-ec6f-eac5ffafa79c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 2/45 [00:00<00:08,  4.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6896, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.5459, loss_val: 0.7806, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.6667\n",
            "loss_train: 0.6808, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.7350, loss_val: 0.7113, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.8675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 4/45 [00:00<00:07,  5.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6681, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.9017, loss_val: 0.6998, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.8547\n",
            "loss_train: 0.6599, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.9391, loss_val: 0.7115, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.8462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 6/45 [00:01<00:07,  5.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6384, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.9338, loss_val: 0.7134, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.8462\n",
            "loss_train: 0.6068, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.9423, loss_val: 0.6433, acc_val: 0.5484, recall_val: 0.3333, auc_val: 0.8205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 8/45 [00:01<00:06,  5.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.5599, acc_train: 0.7903, recall_train: 0.5385, auc_train: 0.9573, loss_val: 0.7346, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.8376\n",
            "loss_train: 0.5290, acc_train: 0.5968, recall_train: 0.0385, auc_train: 0.9562, loss_val: 0.5803, acc_val: 0.7742, recall_val: 0.8333, auc_val: 0.8291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 10/45 [00:01<00:06,  5.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.4803, acc_train: 0.9032, recall_train: 0.9615, auc_train: 0.9701, loss_val: 0.5923, acc_val: 0.6452, recall_val: 0.5000, auc_val: 0.8291\n",
            "loss_train: 0.3936, acc_train: 0.9032, recall_train: 0.8077, auc_train: 0.9733, loss_val: 0.6725, acc_val: 0.5806, recall_val: 0.3333, auc_val: 0.8504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 12/45 [00:02<00:06,  5.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.3677, acc_train: 0.8065, recall_train: 0.5769, auc_train: 0.9690, loss_val: 0.4968, acc_val: 0.8387, recall_val: 0.9444, auc_val: 0.8034\n",
            "loss_train: 0.3716, acc_train: 0.8548, recall_train: 1.0000, auc_train: 0.9904, loss_val: 0.5337, acc_val: 0.7097, recall_val: 0.6111, auc_val: 0.8462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 14/45 [00:02<00:05,  5.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.2408, acc_train: 0.9516, recall_train: 0.9615, auc_train: 0.9840, loss_val: 0.7551, acc_val: 0.6129, recall_val: 0.3889, auc_val: 0.8504\n",
            "loss_train: 0.2746, acc_train: 0.8065, recall_train: 0.5769, auc_train: 0.9818, loss_val: 0.4670, acc_val: 0.8065, recall_val: 0.8889, auc_val: 0.8162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 16/45 [00:03<00:05,  5.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.2337, acc_train: 0.9194, recall_train: 1.0000, auc_train: 0.9957, loss_val: 0.4641, acc_val: 0.7742, recall_val: 0.7778, auc_val: 0.8632\n",
            "loss_train: 0.1573, acc_train: 0.9677, recall_train: 1.0000, auc_train: 0.9936, loss_val: 0.7832, acc_val: 0.6129, recall_val: 0.3889, auc_val: 0.8761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 18/45 [00:03<00:04,  5.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1861, acc_train: 0.9194, recall_train: 0.8462, auc_train: 0.9872, loss_val: 0.5034, acc_val: 0.7419, recall_val: 0.7222, auc_val: 0.8803\n",
            "loss_train: 0.1103, acc_train: 0.9839, recall_train: 1.0000, auc_train: 0.9904, loss_val: 0.4546, acc_val: 0.8065, recall_val: 0.8333, auc_val: 0.8632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 20/45 [00:03<00:04,  5.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1396, acc_train: 0.9839, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5128, acc_val: 0.7742, recall_val: 0.7222, auc_val: 0.8803\n",
            "loss_train: 0.0854, acc_train: 0.9839, recall_train: 1.0000, auc_train: 0.9957, loss_val: 0.8429, acc_val: 0.6129, recall_val: 0.3889, auc_val: 0.8846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 22/45 [00:04<00:04,  5.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1284, acc_train: 0.9677, recall_train: 0.9615, auc_train: 0.9989, loss_val: 0.4627, acc_val: 0.7742, recall_val: 0.7778, auc_val: 0.8803\n",
            "loss_train: 0.0761, acc_train: 0.9839, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.4475, acc_val: 0.8065, recall_val: 0.8333, auc_val: 0.8675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 24/45 [00:04<00:04,  5.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1018, acc_train: 0.9839, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.6221, acc_val: 0.7097, recall_val: 0.5556, auc_val: 0.8803\n",
            "loss_train: 0.0594, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.7884, acc_val: 0.6774, recall_val: 0.5000, auc_val: 0.8889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 26/45 [00:04<00:03,  5.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0855, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.4313, acc_val: 0.8065, recall_val: 0.8333, auc_val: 0.8803\n",
            "loss_train: 0.0718, acc_train: 0.9839, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.4273, acc_val: 0.8065, recall_val: 0.8333, auc_val: 0.8761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 28/45 [00:05<00:03,  5.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0642, acc_train: 0.9839, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.7299, acc_val: 0.6774, recall_val: 0.5000, auc_val: 0.8889\n",
            "loss_train: 0.0619, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.6148, acc_val: 0.7097, recall_val: 0.5556, auc_val: 0.8803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 30/45 [00:05<00:02,  5.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0418, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.4251, acc_val: 0.8065, recall_val: 0.8333, auc_val: 0.8803\n",
            "loss_train: 0.0533, acc_train: 0.9839, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.4486, acc_val: 0.8065, recall_val: 0.7778, auc_val: 0.8803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 32/45 [00:06<00:02,  5.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0369, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.6986, acc_val: 0.6452, recall_val: 0.4444, auc_val: 0.8761\n",
            "loss_train: 0.0485, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5292, acc_val: 0.7419, recall_val: 0.6667, auc_val: 0.8761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 34/45 [00:06<00:02,  5.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0310, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.4272, acc_val: 0.7742, recall_val: 0.7778, auc_val: 0.8761\n",
            "loss_train: 0.0462, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5232, acc_val: 0.7419, recall_val: 0.6667, auc_val: 0.8803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 36/45 [00:06<00:01,  5.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0309, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.6560, acc_val: 0.6774, recall_val: 0.5000, auc_val: 0.8803\n",
            "loss_train: 0.0433, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.4333, acc_val: 0.8065, recall_val: 0.7778, auc_val: 0.8846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 38/45 [00:07<00:01,  5.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0381, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.4435, acc_val: 0.8065, recall_val: 0.7778, auc_val: 0.8846\n",
            "loss_train: 0.0350, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.6389, acc_val: 0.7097, recall_val: 0.5556, auc_val: 0.8846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 40/45 [00:07<00:00,  5.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0443, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.4511, acc_val: 0.7742, recall_val: 0.7222, auc_val: 0.8846\n",
            "loss_train: 0.0337, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.4277, acc_val: 0.8065, recall_val: 0.7778, auc_val: 0.8889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 42/45 [00:07<00:00,  5.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0379, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.6127, acc_val: 0.7097, recall_val: 0.5556, auc_val: 0.8846\n",
            "loss_train: 0.0425, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.4543, acc_val: 0.7742, recall_val: 0.7222, auc_val: 0.8889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 44/45 [00:08<00:00,  5.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0333, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.4334, acc_val: 0.8065, recall_val: 0.7778, auc_val: 0.8846\n",
            "loss_train: 0.0364, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.6054, acc_val: 0.7419, recall_val: 0.6111, auc_val: 0.8889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0402, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.4541, acc_val: 0.7742, recall_val: 0.7222, auc_val: 0.8846\n",
            "Test set results: acc: 0.8054, f1_macro: 0.8041, f1_micro: 0.8054, precision: 0.8154, recall: 0.7928, auc: 0.8743, ap: 0.8762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GAT**"
      ],
      "metadata": {
        "id": "PHVdqU7wnBPH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GAT Architecture**"
      ],
      "metadata": {
        "id": "hSgD4ymXYWOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import copy as cp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import global_max_pool as gmp\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, DataParallel\n",
        "from torch.utils.data import random_split\n",
        "from torch_geometric.data import DataLoader, DataListLoader\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "The GCN, GAT, and GraphSAGE implementation\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "\tdef __init__(self, args, concat=False):\n",
        "\t\tsuper(Model, self).__init__()\n",
        "\t\tself.args = args\n",
        "\t\tself.num_features = args.num_features\n",
        "\t\tself.nhid = args.nhid\n",
        "\t\tself.num_classes = args.num_classes\n",
        "\t\tself.dropout_ratio = args.dropout_ratio\n",
        "\t\tself.model = args.model\n",
        "\t\tself.concat = concat\n",
        "\n",
        "\t\tif self.model == 'gcn':\n",
        "\t\t\tself.conv1 = GCNConv(self.num_features, self.nhid)\n",
        "\t\telif self.model == 'sage':\n",
        "\t\t\tself.conv1 = SAGEConv(self.num_features, self.nhid)\n",
        "\t\telif self.model == 'gat':\n",
        "\t\t\tself.conv1 = GATConv(self.num_features, self.nhid)\n",
        "\n",
        "\t\tif self.concat:\n",
        "\t\t\tself.lin0 = torch.nn.Linear(self.num_features, self.nhid)\n",
        "\t\t\tself.lin1 = torch.nn.Linear(self.nhid * 2, self.nhid)\n",
        "\n",
        "\t\tself.lin2 = torch.nn.Linear(self.nhid, self.num_classes)\n",
        "\n",
        "\tdef forward(self, data):\n",
        "\n",
        "\t\tx, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "\t\tedge_attr = None\n",
        "\n",
        "\t\tx = F.relu(self.conv1(x, edge_index, edge_attr))\n",
        "\t\tx = gmp(x, batch)\n",
        "\n",
        "\t\tif self.concat:\n",
        "\t\t\tnews = torch.stack([data.x[(data.batch == idx).nonzero().squeeze()[0]] for idx in range(data.num_graphs)])\n",
        "\t\t\tnews = F.relu(self.lin0(news))\n",
        "\t\t\tx = torch.cat([x, news], dim=1)\n",
        "\t\t\tx = F.relu(self.lin1(x))\n",
        "\n",
        "\t\tx = F.log_softmax(self.lin2(x), dim=-1)\n",
        "\n",
        "\t\treturn x"
      ],
      "metadata": {
        "id": "ULCw62GLnGJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def compute_test(loader, verbose=False):\n",
        "\tmodel.eval()\n",
        "\tloss_test = 0.0\n",
        "\tout_log = []\n",
        "\tfor data in loader:\n",
        "\t\tif not args.multi_gpu:\n",
        "\t\t\tdata = data.to(args.device)\n",
        "\t\tout = model(data)\n",
        "\t\tif args.multi_gpu:\n",
        "\t\t\ty = torch.cat([d.y.unsqueeze(0) for d in data]).squeeze().to(out.device)\n",
        "\t\telse:\n",
        "\t\t\ty = data.y\n",
        "\t\tif verbose:\n",
        "\t\t\tprint(F.softmax(out, dim=1).cpu().numpy())\n",
        "\t\tout_log.append([F.softmax(out, dim=1), y])\n",
        "\t\tloss_test += F.nll_loss(out, y).item()\n",
        "\treturn eval_deep(out_log, loader), loss_test"
      ],
      "metadata": {
        "id": "GERCiKmno_kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GAT Model Performance**"
      ],
      "metadata": {
        "id": "dpq2S187Yaow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument('--seed', type=int, default=777, help='random seed')\n",
        "parser.add_argument('--device', type=str, default='cpu', help='specify cuda devices')\n",
        "\n",
        "# hyper-parameters\n",
        "parser.add_argument('--dataset', type=str, default='politifact', help='[politifact, gossipcop]')\n",
        "parser.add_argument('--batch_size', type=int, default=128, help='batch size')\n",
        "parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
        "parser.add_argument('--weight_decay', type=float, default=0.01, help='weight decay')\n",
        "parser.add_argument('--nhid', type=int, default=128, help='hidden size')\n",
        "parser.add_argument('--dropout_ratio', type=float, default=0.0, help='dropout ratio')\n",
        "parser.add_argument('--epochs', type=int, default=50, help='maximum number of epochs')\n",
        "parser.add_argument('--concat', type=bool, default=True, help='whether concat news embedding and graph embedding')\n",
        "parser.add_argument('--multi_gpu', type=bool, default=False, help='multi-gpu mode')\n",
        "parser.add_argument('--feature', type=str, default='bert', help='feature type, [profile, spacy, bert, content]')\n",
        "parser.add_argument('--model', type=str, default='gat', help='model type, [gcn, gat, sage]')\n",
        "\n",
        "# args = parser.parse_args()\n",
        "args, _ = parser.parse_known_args()\n",
        "torch.manual_seed(args.seed)\n",
        "if torch.cuda.is_available():\n",
        "\ttorch.cuda.manual_seed(args.seed)\n",
        "\n",
        "dataset = FNNDataset(root='/content/drive/MyDrive', feature=args.feature, empty=False, name=args.dataset, transform=ToUndirected())\n",
        "\n",
        "args.num_classes = dataset.num_classes\n",
        "args.num_features = dataset.num_features\n",
        "\n",
        "print(args)\n",
        "\n",
        "num_training = int(len(dataset) * 0.2)\n",
        "num_val = int(len(dataset) * 0.1)\n",
        "num_test = len(dataset) - (num_training + num_val)\n",
        "training_set, validation_set, test_set = random_split(dataset, [num_training, num_val, num_test])\n",
        "\n",
        "if args.multi_gpu:\n",
        "\tloader = DataListLoader\n",
        "else:\n",
        "\tloader = DataLoader\n",
        "\n",
        "train_loader = loader(training_set, batch_size=args.batch_size, shuffle=True)\n",
        "val_loader = loader(validation_set, batch_size=args.batch_size, shuffle=False)\n",
        "test_loader = loader(test_set, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "model = Model(args, concat=args.concat)\n",
        "if args.multi_gpu:\n",
        "\tmodel = DataParallel(model)\n",
        "model = model.to(args.device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcBS74TCnkyn",
        "outputId": "320e40f4-5192-4704-e975-9787672e121e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(seed=777, device='cpu', dataset='politifact', batch_size=128, lr=0.001, weight_decay=0.01, nhid=128, dropout_ratio=0.0, epochs=50, concat=True, multi_gpu=False, feature='bert', model='gat', num_classes=2, num_features=768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GAT Run Model**"
      ],
      "metadata": {
        "id": "uzcI0ZleYeZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "min_loss = 1e10\n",
        "val_loss_values = []\n",
        "best_epoch = 0\n",
        "\n",
        "t = time.time()\n",
        "model.train()\n",
        "for epoch in tqdm(range(args.epochs)):\n",
        "\tloss_train = 0.0\n",
        "\tout_log = []\n",
        "\tfor i, data in enumerate(train_loader):\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\tif not args.multi_gpu:\n",
        "\t\t\tdata = data.to(args.device)\n",
        "\t\tout = model(data)\n",
        "\t\tif args.multi_gpu:\n",
        "\t\t\ty = torch.cat([d.y.unsqueeze(0) for d in data]).squeeze().to(out.device)\n",
        "\t\telse:\n",
        "\t\t\ty = data.y\n",
        "\t\tloss = F.nll_loss(out, y)\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n",
        "\t\tloss_train += loss.item()\n",
        "\t\tout_log.append([F.softmax(out, dim=1), y])\n",
        "\tacc_train, _, _, _, recall_train, auc_train, _ = eval_deep(out_log, train_loader)\n",
        "\t[acc_val, _, _, _, recall_val, auc_val, _], loss_val = compute_test(val_loader)\n",
        "\tprint(f'loss_train: {loss_train:.4f}, acc_train: {acc_train:.4f},'\n",
        "\t\t\t  f' recall_train: {recall_train:.4f}, auc_train: {auc_train:.4f},'\n",
        "\t\t\t  f' loss_val: {loss_val:.4f}, acc_val: {acc_val:.4f},'\n",
        "\t\t\t  f' recall_val: {recall_val:.4f}, auc_val: {auc_val:.4f}')\n",
        "\n",
        "[acc, f1_macro, f1_micro, precision, recall, auc, ap], test_loss = compute_test(test_loader, verbose=False)\n",
        "print(f'Test set results: acc: {acc:.4f}, f1_macro: {f1_macro:.4f}, f1_micro: {f1_micro:.4f}, '\n",
        "\t\t  f'precision: {precision:.4f}, recall: {recall:.4f}, auc: {auc:.4f}, ap: {ap:.4f}')\n",
        "acc_GAT = acc\n",
        "f1_GAT = f1_macro\n",
        "auc_GAT = auc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MVtlTAQnr0i",
        "outputId": "a5535b51-8123-463e-ba32-063d96e2eea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 1/50 [00:00<00:12,  3.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6845, acc_train: 0.5645, recall_train: 0.0000, auc_train: 0.5737, loss_val: 0.7791, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.7350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [00:00<00:14,  3.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6788, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.8472, loss_val: 0.7559, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.8162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [00:00<00:15,  3.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6653, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.9615, loss_val: 0.7151, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.7863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [00:01<00:14,  3.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6519, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.9850, loss_val: 0.6903, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.7778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [00:01<00:14,  3.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6448, acc_train: 0.5968, recall_train: 0.0385, auc_train: 0.9829, loss_val: 0.6829, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.7863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [00:01<00:14,  3.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6334, acc_train: 0.6613, recall_train: 0.1923, auc_train: 0.9840, loss_val: 0.6875, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.7991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [00:02<00:13,  3.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6173, acc_train: 0.6129, recall_train: 0.0769, auc_train: 0.9882, loss_val: 0.6983, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.8205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [00:02<00:13,  3.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6017, acc_train: 0.5968, recall_train: 0.0385, auc_train: 0.9882, loss_val: 0.7015, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.8205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [00:02<00:12,  3.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.5855, acc_train: 0.5968, recall_train: 0.0385, auc_train: 0.9882, loss_val: 0.6869, acc_val: 0.4516, recall_val: 0.0556, auc_val: 0.8205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [00:03<00:12,  3.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.5643, acc_train: 0.6613, recall_train: 0.1923, auc_train: 0.9882, loss_val: 0.6599, acc_val: 0.6129, recall_val: 0.3333, auc_val: 0.8120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [00:03<00:12,  3.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.5400, acc_train: 0.7903, recall_train: 0.5000, auc_train: 0.9840, loss_val: 0.6352, acc_val: 0.7419, recall_val: 0.6111, auc_val: 0.8120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [00:03<00:12,  3.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.5149, acc_train: 0.9032, recall_train: 0.8077, auc_train: 0.9840, loss_val: 0.6214, acc_val: 0.7097, recall_val: 0.6111, auc_val: 0.8162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [00:04<00:11,  3.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.4870, acc_train: 0.9194, recall_train: 0.8462, auc_train: 0.9893, loss_val: 0.6169, acc_val: 0.7419, recall_val: 0.6111, auc_val: 0.8205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [00:04<00:10,  3.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.4565, acc_train: 0.9032, recall_train: 0.8077, auc_train: 0.9893, loss_val: 0.6130, acc_val: 0.7419, recall_val: 0.6111, auc_val: 0.8248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [00:04<00:09,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.4256, acc_train: 0.8871, recall_train: 0.7692, auc_train: 0.9925, loss_val: 0.5968, acc_val: 0.7419, recall_val: 0.6111, auc_val: 0.8248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [00:04<00:08,  3.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.3924, acc_train: 0.9194, recall_train: 0.8462, auc_train: 0.9936, loss_val: 0.5714, acc_val: 0.7419, recall_val: 0.6667, auc_val: 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [00:04<00:08,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.3581, acc_train: 0.9677, recall_train: 0.9615, auc_train: 0.9957, loss_val: 0.5526, acc_val: 0.7742, recall_val: 0.7222, auc_val: 0.8419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [00:05<00:07,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.3242, acc_train: 0.9839, recall_train: 1.0000, auc_train: 0.9968, loss_val: 0.5461, acc_val: 0.7419, recall_val: 0.6667, auc_val: 0.8462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [00:05<00:07,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.2895, acc_train: 0.9839, recall_train: 1.0000, auc_train: 0.9979, loss_val: 0.5429, acc_val: 0.7419, recall_val: 0.6667, auc_val: 0.8590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [00:05<00:06,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.2567, acc_train: 0.9839, recall_train: 1.0000, auc_train: 0.9989, loss_val: 0.5282, acc_val: 0.7742, recall_val: 0.7222, auc_val: 0.8632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [00:05<00:06,  4.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.2244, acc_train: 0.9839, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5108, acc_val: 0.7742, recall_val: 0.7222, auc_val: 0.8632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [00:06<00:06,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1946, acc_train: 0.9839, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5070, acc_val: 0.7742, recall_val: 0.7222, auc_val: 0.8718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [00:06<00:06,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1668, acc_train: 0.9839, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5137, acc_val: 0.8065, recall_val: 0.7222, auc_val: 0.8718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [00:06<00:06,  4.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1420, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5116, acc_val: 0.8387, recall_val: 0.7778, auc_val: 0.8761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [00:06<00:06,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1197, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5026, acc_val: 0.8387, recall_val: 0.7778, auc_val: 0.8803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [00:07<00:05,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1002, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5052, acc_val: 0.8387, recall_val: 0.7778, auc_val: 0.8889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [00:07<00:05,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0833, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5188, acc_val: 0.8387, recall_val: 0.7778, auc_val: 0.8889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [00:07<00:05,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0687, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5257, acc_val: 0.8387, recall_val: 0.7778, auc_val: 0.8932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [00:07<00:04,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0565, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5234, acc_val: 0.8387, recall_val: 0.7778, auc_val: 0.8974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [00:07<00:04,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0462, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5271, acc_val: 0.8387, recall_val: 0.7778, auc_val: 0.8974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [00:08<00:04,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0379, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5408, acc_val: 0.8387, recall_val: 0.7778, auc_val: 0.8974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [00:08<00:04,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0310, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5555, acc_val: 0.8387, recall_val: 0.7778, auc_val: 0.8974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [00:08<00:03,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0257, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5618, acc_val: 0.8387, recall_val: 0.7778, auc_val: 0.8974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [00:08<00:03,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0215, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5629, acc_val: 0.8710, recall_val: 0.8333, auc_val: 0.9017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [00:09<00:03,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0182, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5667, acc_val: 0.8710, recall_val: 0.8333, auc_val: 0.8932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 36/50 [00:09<00:03,  4.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0157, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5755, acc_val: 0.8710, recall_val: 0.8333, auc_val: 0.8889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 37/50 [00:09<00:02,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0137, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5865, acc_val: 0.8710, recall_val: 0.8333, auc_val: 0.8889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 38/50 [00:09<00:02,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0122, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5939, acc_val: 0.8710, recall_val: 0.8333, auc_val: 0.8889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 39/50 [00:10<00:02,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0111, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5948, acc_val: 0.8710, recall_val: 0.8333, auc_val: 0.8889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 40/50 [00:10<00:02,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0102, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5918, acc_val: 0.8710, recall_val: 0.8333, auc_val: 0.8889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 41/50 [00:10<00:02,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0096, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5893, acc_val: 0.8710, recall_val: 0.8333, auc_val: 0.8889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 42/50 [00:10<00:01,  4.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0091, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5898, acc_val: 0.8710, recall_val: 0.8333, auc_val: 0.8889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 43/50 [00:10<00:01,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0088, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5928, acc_val: 0.8710, recall_val: 0.8333, auc_val: 0.8932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 44/50 [00:11<00:01,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0086, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5947, acc_val: 0.8710, recall_val: 0.8333, auc_val: 0.8932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 45/50 [00:11<00:01,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0086, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5917, acc_val: 0.8710, recall_val: 0.8333, auc_val: 0.8932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 46/50 [00:11<00:00,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0086, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5845, acc_val: 0.8710, recall_val: 0.8333, auc_val: 0.8889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 47/50 [00:11<00:00,  4.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0087, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5770, acc_val: 0.8710, recall_val: 0.8333, auc_val: 0.8889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 48/50 [00:12<00:00,  3.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0089, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5729, acc_val: 0.8710, recall_val: 0.8333, auc_val: 0.8932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 49/50 [00:12<00:00,  3.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0092, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5722, acc_val: 0.8710, recall_val: 0.8333, auc_val: 0.8932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:12<00:00,  3.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0096, acc_train: 1.0000, recall_train: 1.0000, auc_train: 1.0000, loss_val: 0.5709, acc_val: 0.8710, recall_val: 0.8333, auc_val: 0.8974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set results: acc: 0.8281, f1_macro: 0.8269, f1_micro: 0.8281, precision: 0.8852, recall: 0.7598, auc: 0.8912, ap: 0.8906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GCN**"
      ],
      "metadata": {
        "id": "0t2RkbuVuDOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GCN Architecture**"
      ],
      "metadata": {
        "id": "7O2eGYyvYjCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import copy as cp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import global_max_pool as gmp\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, DataParallel\n",
        "from torch.utils.data import random_split\n",
        "from torch_geometric.data import DataLoader, DataListLoader\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "The GCN, GAT, and GraphSAGE implementation\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "\tdef __init__(self, args, concat=False):\n",
        "\t\tsuper(Model, self).__init__()\n",
        "\t\tself.args = args\n",
        "\t\tself.num_features = args.num_features\n",
        "\t\tself.nhid = args.nhid\n",
        "\t\tself.num_classes = args.num_classes\n",
        "\t\tself.dropout_ratio = args.dropout_ratio\n",
        "\t\tself.model = args.model\n",
        "\t\tself.concat = concat\n",
        "\n",
        "\t\tif self.model == 'gcn':\n",
        "\t\t\tself.conv1 = GCNConv(self.num_features, self.nhid)\n",
        "\t\telif self.model == 'sage':\n",
        "\t\t\tself.conv1 = SAGEConv(self.num_features, self.nhid)\n",
        "\t\telif self.model == 'gat':\n",
        "\t\t\tself.conv1 = GATConv(self.num_features, self.nhid)\n",
        "\n",
        "\t\tif self.concat:\n",
        "\t\t\tself.lin0 = torch.nn.Linear(self.num_features, self.nhid)\n",
        "\t\t\tself.lin1 = torch.nn.Linear(self.nhid * 2, self.nhid)\n",
        "\n",
        "\t\tself.lin2 = torch.nn.Linear(self.nhid, self.num_classes)\n",
        "\n",
        "\tdef forward(self, data):\n",
        "\n",
        "\t\tx, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "\t\tedge_attr = None\n",
        "\n",
        "\t\tx = F.relu(self.conv1(x, edge_index, edge_attr))\n",
        "\t\tx = gmp(x, batch)\n",
        "\n",
        "\t\tif self.concat:\n",
        "\t\t\tnews = torch.stack([data.x[(data.batch == idx).nonzero().squeeze()[0]] for idx in range(data.num_graphs)])\n",
        "\t\t\tnews = F.relu(self.lin0(news))\n",
        "\t\t\tx = torch.cat([x, news], dim=1)\n",
        "\t\t\tx = F.relu(self.lin1(x))\n",
        "\n",
        "\t\tx = F.log_softmax(self.lin2(x), dim=-1)\n",
        "\n",
        "\t\treturn x"
      ],
      "metadata": {
        "id": "rTV27xvmuF2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def compute_test(loader, verbose=False):\n",
        "\tmodel.eval()\n",
        "\tloss_test = 0.0\n",
        "\tout_log = []\n",
        "\tfor data in loader:\n",
        "\t\tif not args.multi_gpu:\n",
        "\t\t\tdata = data.to(args.device)\n",
        "\t\tout = model(data)\n",
        "\t\tif args.multi_gpu:\n",
        "\t\t\ty = torch.cat([d.y.unsqueeze(0) for d in data]).squeeze().to(out.device)\n",
        "\t\telse:\n",
        "\t\t\ty = data.y\n",
        "\t\tif verbose:\n",
        "\t\t\tprint(F.softmax(out, dim=1).cpu().numpy())\n",
        "\t\tout_log.append([F.softmax(out, dim=1), y])\n",
        "\t\tloss_test += F.nll_loss(out, y).item()\n",
        "\treturn eval_deep(out_log, loader), loss_test"
      ],
      "metadata": {
        "id": "Tsu6MnaEuLRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GCN Model Performance**"
      ],
      "metadata": {
        "id": "cmwpv755YmmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument('--seed', type=int, default=777, help='random seed')\n",
        "parser.add_argument('--device', type=str, default='cpu', help='specify cuda devices')\n",
        "\n",
        "# hyper-parameters\n",
        "parser.add_argument('--dataset', type=str, default='politifact', help='[politifact, gossipcop]')\n",
        "parser.add_argument('--batch_size', type=int, default=128, help='batch size')\n",
        "parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
        "parser.add_argument('--weight_decay', type=float, default=0.01, help='weight decay')\n",
        "parser.add_argument('--nhid', type=int, default=128, help='hidden size')\n",
        "parser.add_argument('--dropout_ratio', type=float, default=0.0, help='dropout ratio')\n",
        "parser.add_argument('--epochs', type=int, default=60, help='maximum number of epochs')\n",
        "parser.add_argument('--concat', type=bool, default=True, help='whether concat news embedding and graph embedding')\n",
        "parser.add_argument('--multi_gpu', type=bool, default=False, help='multi-gpu mode')\n",
        "parser.add_argument('--feature', type=str, default='spacy', help='feature type, [profile, spacy, bert, content]')\n",
        "parser.add_argument('--model', type=str, default='gcn', help='model type, [gcn, gat, sage]')\n",
        "\n",
        "# args = parser.parse_args()\n",
        "args, _ = parser.parse_known_args()\n",
        "torch.manual_seed(args.seed)\n",
        "if torch.cuda.is_available():\n",
        "\ttorch.cuda.manual_seed(args.seed)\n",
        "\n",
        "dataset = FNNDataset(root='/content/drive/MyDrive', feature=args.feature, empty=False, name=args.dataset, transform=ToUndirected())\n",
        "\n",
        "args.num_classes = dataset.num_classes\n",
        "args.num_features = dataset.num_features\n",
        "\n",
        "print(args)\n",
        "\n",
        "num_training = int(len(dataset) * 0.2)\n",
        "num_val = int(len(dataset) * 0.1)\n",
        "num_test = len(dataset) - (num_training + num_val)\n",
        "training_set, validation_set, test_set = random_split(dataset, [num_training, num_val, num_test])\n",
        "\n",
        "if args.multi_gpu:\n",
        "\tloader = DataListLoader\n",
        "else:\n",
        "\tloader = DataLoader\n",
        "\n",
        "train_loader = loader(training_set, batch_size=args.batch_size, shuffle=True)\n",
        "val_loader = loader(validation_set, batch_size=args.batch_size, shuffle=False)\n",
        "test_loader = loader(test_set, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "model = Model(args, concat=args.concat)\n",
        "if args.multi_gpu:\n",
        "\tmodel = DataParallel(model)\n",
        "model = model.to(args.device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UtSL6O-uOcE",
        "outputId": "6508ce11-3b79-47a9-ba5c-05e78b58ace9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(seed=777, device='cpu', dataset='politifact', batch_size=128, lr=0.001, weight_decay=0.01, nhid=128, dropout_ratio=0.0, epochs=60, concat=True, multi_gpu=False, feature='spacy', model='gcn', num_classes=2, num_features=300)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GCN Run Model**"
      ],
      "metadata": {
        "id": "CGcpKy4ZYqEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "min_loss = 1e10\n",
        "val_loss_values = []\n",
        "best_epoch = 0\n",
        "\n",
        "t = time.time()\n",
        "model.train()\n",
        "for epoch in tqdm(range(args.epochs)):\n",
        "\tloss_train = 0.0\n",
        "\tout_log = []\n",
        "\tfor i, data in enumerate(train_loader):\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\tif not args.multi_gpu:\n",
        "\t\t\tdata = data.to(args.device)\n",
        "\t\tout = model(data)\n",
        "\t\tif args.multi_gpu:\n",
        "\t\t\ty = torch.cat([d.y.unsqueeze(0) for d in data]).squeeze().to(out.device)\n",
        "\t\telse:\n",
        "\t\t\ty = data.y\n",
        "\t\tloss = F.nll_loss(out, y)\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n",
        "\t\tloss_train += loss.item()\n",
        "\t\tout_log.append([F.softmax(out, dim=1), y])\n",
        "\tacc_train, _, _, _, recall_train, auc_train, _ = eval_deep(out_log, train_loader)\n",
        "\t[acc_val, _, _, _, recall_val, auc_val, _], loss_val = compute_test(val_loader)\n",
        "\tprint(f'loss_train: {loss_train:.4f}, acc_train: {acc_train:.4f},'\n",
        "\t\t\t  f' recall_train: {recall_train:.4f}, auc_train: {auc_train:.4f},'\n",
        "\t\t\t  f' loss_val: {loss_val:.4f}, acc_val: {acc_val:.4f},'\n",
        "\t\t\t  f' recall_val: {recall_val:.4f}, auc_val: {auc_val:.4f}')\n",
        "\n",
        "[acc, f1_macro, f1_micro, precision, recall, auc, ap], test_loss = compute_test(test_loader, verbose=False)\n",
        "print(f'Test set results: acc: {acc:.4f}, f1_macro: {f1_macro:.4f}, f1_micro: {f1_micro:.4f}, '\n",
        "\t\t  f'precision: {precision:.4f}, recall: {recall:.4f}, auc: {auc:.4f}, ap: {ap:.4f}')\n",
        "acc_GCN = acc\n",
        "f1_GCN = f1_macro\n",
        "auc_GCN = auc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ck8dpLiBuORr",
        "outputId": "db0ce8d2-2b72-4d56-9aad-f4dbf471abcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 1/60 [00:00<00:15,  3.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6917, acc_train: 0.5323, recall_train: 0.1923, auc_train: 0.4808, loss_val: 0.7294, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.3803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/60 [00:00<00:16,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6823, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.5160, loss_val: 0.7564, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.3718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 3/60 [00:00<00:14,  3.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6792, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.5246, loss_val: 0.7726, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.3718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 4/60 [00:01<00:14,  3.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6781, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.5342, loss_val: 0.7735, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.3846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 5/60 [00:01<00:14,  3.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6763, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.5524, loss_val: 0.7644, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.3932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 6/60 [00:01<00:14,  3.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6737, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.5726, loss_val: 0.7514, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.4060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 7/60 [00:01<00:13,  3.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6712, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.5983, loss_val: 0.7388, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.4231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 8/60 [00:02<00:12,  4.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6689, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.6335, loss_val: 0.7285, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.4444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 9/60 [00:02<00:14,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6669, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.6763, loss_val: 0.7214, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.4744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 10/60 [00:03<00:25,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6649, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.7030, loss_val: 0.7179, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.4915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 11/60 [00:03<00:23,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6626, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.7297, loss_val: 0.7176, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.5043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 12/60 [00:04<00:24,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6598, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.7468, loss_val: 0.7193, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.5299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 14/60 [00:05<00:18,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6566, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.7553, loss_val: 0.7223, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.5470\n",
            "loss_train: 0.6532, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.7596, loss_val: 0.7245, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.5684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 15/60 [00:05<00:15,  2.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6495, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.7735, loss_val: 0.7238, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.5812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 16/60 [00:05<00:13,  3.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6454, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.7895, loss_val: 0.7193, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.6111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 17/60 [00:06<00:16,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6406, acc_train: 0.5968, recall_train: 0.0385, auc_train: 0.8194, loss_val: 0.7114, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.6795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 19/60 [00:06<00:12,  3.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6354, acc_train: 0.5968, recall_train: 0.0385, auc_train: 0.8515, loss_val: 0.7013, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.7436\n",
            "loss_train: 0.6295, acc_train: 0.5968, recall_train: 0.0385, auc_train: 0.8793, loss_val: 0.6912, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.7821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 21/60 [00:06<00:08,  4.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6231, acc_train: 0.5968, recall_train: 0.0385, auc_train: 0.9135, loss_val: 0.6828, acc_val: 0.4516, recall_val: 0.0556, auc_val: 0.8162\n",
            "loss_train: 0.6159, acc_train: 0.6129, recall_train: 0.0769, auc_train: 0.9306, loss_val: 0.6774, acc_val: 0.4516, recall_val: 0.0556, auc_val: 0.8291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 23/60 [00:07<00:07,  5.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6078, acc_train: 0.6613, recall_train: 0.1923, auc_train: 0.9359, loss_val: 0.6743, acc_val: 0.4516, recall_val: 0.0556, auc_val: 0.8291\n",
            "loss_train: 0.5989, acc_train: 0.7097, recall_train: 0.3077, auc_train: 0.9391, loss_val: 0.6710, acc_val: 0.4839, recall_val: 0.1111, auc_val: 0.8248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 25/60 [00:07<00:06,  5.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.5891, acc_train: 0.7097, recall_train: 0.3077, auc_train: 0.9402, loss_val: 0.6643, acc_val: 0.5161, recall_val: 0.1667, auc_val: 0.8333\n",
            "loss_train: 0.5785, acc_train: 0.7419, recall_train: 0.3846, auc_train: 0.9487, loss_val: 0.6523, acc_val: 0.5806, recall_val: 0.2778, auc_val: 0.8419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 27/60 [00:07<00:05,  6.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.5668, acc_train: 0.8065, recall_train: 0.5385, auc_train: 0.9573, loss_val: 0.6370, acc_val: 0.5806, recall_val: 0.3333, auc_val: 0.8462\n",
            "loss_train: 0.5540, acc_train: 0.8065, recall_train: 0.5769, auc_train: 0.9626, loss_val: 0.6231, acc_val: 0.5806, recall_val: 0.3333, auc_val: 0.8462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 29/60 [00:08<00:05,  6.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.5404, acc_train: 0.8548, recall_train: 0.6923, auc_train: 0.9637, loss_val: 0.6137, acc_val: 0.6452, recall_val: 0.4444, auc_val: 0.8462\n",
            "loss_train: 0.5258, acc_train: 0.8710, recall_train: 0.7308, auc_train: 0.9647, loss_val: 0.6071, acc_val: 0.6774, recall_val: 0.5000, auc_val: 0.8419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 31/60 [00:08<00:04,  6.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.5103, acc_train: 0.8710, recall_train: 0.7308, auc_train: 0.9647, loss_val: 0.5964, acc_val: 0.6452, recall_val: 0.5000, auc_val: 0.8419\n",
            "loss_train: 0.4941, acc_train: 0.8710, recall_train: 0.7308, auc_train: 0.9658, loss_val: 0.5792, acc_val: 0.7097, recall_val: 0.6667, auc_val: 0.8419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 33/60 [00:08<00:04,  6.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.4771, acc_train: 0.9032, recall_train: 0.8077, auc_train: 0.9701, loss_val: 0.5626, acc_val: 0.7419, recall_val: 0.7222, auc_val: 0.8504\n",
            "loss_train: 0.4598, acc_train: 0.9194, recall_train: 0.8846, auc_train: 0.9690, loss_val: 0.5529, acc_val: 0.7419, recall_val: 0.7222, auc_val: 0.8504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 35/60 [00:09<00:04,  6.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.4419, acc_train: 0.9194, recall_train: 0.8846, auc_train: 0.9712, loss_val: 0.5433, acc_val: 0.7419, recall_val: 0.7222, auc_val: 0.8547\n",
            "loss_train: 0.4241, acc_train: 0.9194, recall_train: 0.8846, auc_train: 0.9733, loss_val: 0.5256, acc_val: 0.7419, recall_val: 0.7222, auc_val: 0.8547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 37/60 [00:09<00:03,  6.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.4061, acc_train: 0.9194, recall_train: 0.8846, auc_train: 0.9722, loss_val: 0.5092, acc_val: 0.7419, recall_val: 0.7222, auc_val: 0.8590\n",
            "loss_train: 0.3882, acc_train: 0.9194, recall_train: 0.8846, auc_train: 0.9733, loss_val: 0.5014, acc_val: 0.7419, recall_val: 0.7222, auc_val: 0.8632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 39/60 [00:09<00:03,  6.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.3706, acc_train: 0.9194, recall_train: 0.8846, auc_train: 0.9733, loss_val: 0.4895, acc_val: 0.7419, recall_val: 0.7222, auc_val: 0.8590\n",
            "loss_train: 0.3533, acc_train: 0.9194, recall_train: 0.8846, auc_train: 0.9744, loss_val: 0.4733, acc_val: 0.7742, recall_val: 0.7778, auc_val: 0.8504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 41/60 [00:10<00:03,  5.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.3366, acc_train: 0.9194, recall_train: 0.8846, auc_train: 0.9754, loss_val: 0.4670, acc_val: 0.7742, recall_val: 0.7778, auc_val: 0.8547\n",
            "loss_train: 0.3204, acc_train: 0.9194, recall_train: 0.8846, auc_train: 0.9765, loss_val: 0.4569, acc_val: 0.7742, recall_val: 0.7778, auc_val: 0.8547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 43/60 [00:10<00:02,  5.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.3048, acc_train: 0.9355, recall_train: 0.9231, auc_train: 0.9765, loss_val: 0.4451, acc_val: 0.8065, recall_val: 0.8333, auc_val: 0.8590\n",
            "loss_train: 0.2899, acc_train: 0.9355, recall_train: 0.9231, auc_train: 0.9797, loss_val: 0.4419, acc_val: 0.8387, recall_val: 0.8333, auc_val: 0.8590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 45/60 [00:10<00:02,  5.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.2756, acc_train: 0.9355, recall_train: 0.9231, auc_train: 0.9797, loss_val: 0.4308, acc_val: 0.8387, recall_val: 0.8333, auc_val: 0.8632\n",
            "loss_train: 0.2619, acc_train: 0.9355, recall_train: 0.9231, auc_train: 0.9808, loss_val: 0.4270, acc_val: 0.8387, recall_val: 0.8333, auc_val: 0.8632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 47/60 [00:11<00:02,  5.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.2490, acc_train: 0.9355, recall_train: 0.9231, auc_train: 0.9829, loss_val: 0.4211, acc_val: 0.8387, recall_val: 0.8333, auc_val: 0.8632\n",
            "loss_train: 0.2366, acc_train: 0.9677, recall_train: 0.9615, auc_train: 0.9840, loss_val: 0.4151, acc_val: 0.8387, recall_val: 0.8333, auc_val: 0.8675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 49/60 [00:11<00:01,  5.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.2250, acc_train: 0.9677, recall_train: 0.9615, auc_train: 0.9840, loss_val: 0.4139, acc_val: 0.8387, recall_val: 0.8333, auc_val: 0.8675\n",
            "loss_train: 0.2139, acc_train: 0.9677, recall_train: 0.9615, auc_train: 0.9850, loss_val: 0.4051, acc_val: 0.8387, recall_val: 0.8333, auc_val: 0.8632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 51/60 [00:11<00:01,  5.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.2037, acc_train: 0.9839, recall_train: 1.0000, auc_train: 0.9882, loss_val: 0.4115, acc_val: 0.8387, recall_val: 0.8333, auc_val: 0.8675\n",
            "loss_train: 0.1945, acc_train: 0.9677, recall_train: 0.9615, auc_train: 0.9904, loss_val: 0.3974, acc_val: 0.8387, recall_val: 0.8333, auc_val: 0.8590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 53/60 [00:12<00:01,  5.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1860, acc_train: 0.9677, recall_train: 1.0000, auc_train: 0.9915, loss_val: 0.4052, acc_val: 0.8387, recall_val: 0.8333, auc_val: 0.8675\n",
            "loss_train: 0.1769, acc_train: 0.9839, recall_train: 1.0000, auc_train: 0.9915, loss_val: 0.3965, acc_val: 0.8387, recall_val: 0.8333, auc_val: 0.8718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 55/60 [00:12<00:00,  5.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1682, acc_train: 0.9839, recall_train: 1.0000, auc_train: 0.9925, loss_val: 0.3910, acc_val: 0.8387, recall_val: 0.8333, auc_val: 0.8632\n",
            "loss_train: 0.1616, acc_train: 0.9839, recall_train: 1.0000, auc_train: 0.9936, loss_val: 0.3992, acc_val: 0.8387, recall_val: 0.8333, auc_val: 0.8803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 57/60 [00:12<00:00,  5.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1549, acc_train: 0.9839, recall_train: 1.0000, auc_train: 0.9936, loss_val: 0.3894, acc_val: 0.8387, recall_val: 0.8333, auc_val: 0.8761\n",
            "loss_train: 0.1477, acc_train: 0.9839, recall_train: 1.0000, auc_train: 0.9936, loss_val: 0.3860, acc_val: 0.8387, recall_val: 0.8333, auc_val: 0.8718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 59/60 [00:13<00:00,  5.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1422, acc_train: 0.9839, recall_train: 1.0000, auc_train: 0.9957, loss_val: 0.3936, acc_val: 0.8387, recall_val: 0.8333, auc_val: 0.8803\n",
            "loss_train: 0.1371, acc_train: 0.9839, recall_train: 1.0000, auc_train: 0.9947, loss_val: 0.3845, acc_val: 0.8387, recall_val: 0.8333, auc_val: 0.8761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60/60 [00:13<00:00,  4.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1313, acc_train: 0.9839, recall_train: 1.0000, auc_train: 0.9968, loss_val: 0.3817, acc_val: 0.8387, recall_val: 0.8333, auc_val: 0.8761\n",
            "Test set results: acc: 0.8326, f1_macro: 0.8319, f1_micro: 0.8326, precision: 0.8491, recall: 0.8115, auc: 0.8931, ap: 0.9133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GCN_FN**"
      ],
      "metadata": {
        "id": "UQ07bQbY5DTF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GCN_FN Architecture**"
      ],
      "metadata": {
        "id": "SZPK58TK-673"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import copy as cp\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import random_split\n",
        "from torch_geometric.data import DataLoader, DataListLoader\n",
        "from torch_geometric.nn import DataParallel\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.nn import global_mean_pool, GATConv\n",
        "\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "\tdef __init__(self, concat=False):\n",
        "\t\tsuper(Net, self).__init__()\n",
        "\n",
        "\t\tself.num_features = dataset.num_features\n",
        "\t\tself.num_classes = args.num_classes\n",
        "\t\tself.nhid = args.nhid\n",
        "\t\tself.concat = concat\n",
        "\n",
        "\t\tself.conv1 = GATConv(self.num_features, self.nhid * 2)\n",
        "\t\tself.conv2 = GATConv(self.nhid * 2, self.nhid * 2)\n",
        "\n",
        "\t\tself.fc1 = Linear(self.nhid * 2, self.nhid)\n",
        "\n",
        "\t\tif self.concat:\n",
        "\t\t\tself.fc0 = Linear(self.num_features, self.nhid)\n",
        "\t\t\tself.fc1 = Linear(self.nhid * 2, self.nhid)\n",
        "\n",
        "\t\tself.fc2 = Linear(self.nhid, self.num_classes)\n",
        "\n",
        "\n",
        "\tdef forward(self, data):\n",
        "\t\tx, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "\t\tx = F.selu(self.conv1(x, edge_index))\n",
        "\t\tx = F.selu(self.conv2(x, edge_index))\n",
        "\t\tx = F.selu(global_mean_pool(x, batch))\n",
        "\t\tx = F.selu(self.fc1(x))\n",
        "\t\tx = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "\t\tif self.concat:\n",
        "\t\t\tnews = torch.stack([data.x[(data.batch == idx).nonzero().squeeze()[0]] for idx in range(data.num_graphs)])\n",
        "\t\t\tnews = F.relu(self.fc0(news))\n",
        "\t\t\tx = torch.cat([x, news], dim=1)\n",
        "\t\t\tx = F.relu(self.fc1(x))\n",
        "\n",
        "\t\tx = F.log_softmax(self.fc2(x), dim=-1)\n",
        "\n",
        "\t\treturn x"
      ],
      "metadata": {
        "id": "2cj1wxE3pdbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GCN_FN Model Performance**"
      ],
      "metadata": {
        "id": "EJox7a2O_VN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def compute_test(loader, verbose=False):\n",
        "\tmodel.eval()\n",
        "\tloss_test = 0.0\n",
        "\tout_log = []\n",
        "\tfor data in loader:\n",
        "\t\tif not args.multi_gpu:\n",
        "\t\t\tdata = data.to(args.device)\n",
        "\t\tout = model(data)\n",
        "\t\tif args.multi_gpu:\n",
        "\t\t\ty = torch.cat([d.y.unsqueeze(0) for d in data]).squeeze().to(out.device)\n",
        "\t\telse:\n",
        "\t\t\ty = data.y\n",
        "\t\tif verbose:\n",
        "\t\t\tprint(F.softmax(out, dim=1).cpu().numpy())\n",
        "\t\tout_log.append([F.softmax(out, dim=1), y])\n",
        "\t\tloss_test += F.nll_loss(out, y).item()\n",
        "\treturn eval_deep(out_log, loader), loss_test"
      ],
      "metadata": {
        "id": "wU58z-dJ_Dl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GCN_FN Run Model**"
      ],
      "metadata": {
        "id": "ZlgtR9Uo_JZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "# original model parameters\n",
        "parser.add_argument('--seed', type=int, default=777, help='random seed')\n",
        "parser.add_argument('--device', type=str, default='cpu', help='specify cuda devices')\n",
        "\n",
        "# hyper-parameters\n",
        "parser.add_argument('--dataset', type=str, default='politifact', help='[politifact, gossipcop]')\n",
        "parser.add_argument('--batch_size', type=int, default=128, help='batch size')\n",
        "parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
        "parser.add_argument('--weight_decay', type=float, default=0.01, help='weight decay')\n",
        "parser.add_argument('--nhid', type=int, default=128, help='hidden size')\n",
        "parser.add_argument('--epochs', type=int, default=50, help='maximum number of epochs')\n",
        "parser.add_argument('--concat', type=bool, default=False, help='whether concat news embedding and graph embedding')\n",
        "parser.add_argument('--multi_gpu', type=bool, default=False, help='multi-gpu mode')\n",
        "parser.add_argument('--feature', type=str, default='spacy', help='feature type, [profile, spacy, bert, content]')\n",
        "\n",
        "args, _ = parser.parse_known_args()\n",
        "torch.manual_seed(args.seed)\n",
        "if torch.cuda.is_available():\n",
        "\ttorch.cuda.manual_seed(args.seed)\n",
        "\n",
        "dataset = FNNDataset(root='/content/drive/MyDrive', feature=args.feature, empty=False, name=args.dataset, transform=ToUndirected())\n",
        "\n",
        "args.num_classes = dataset.num_classes\n",
        "args.num_features = dataset.num_features\n",
        "\n",
        "print(args)\n",
        "\n",
        "num_training = int(len(dataset) * 0.2)\n",
        "num_val = int(len(dataset) * 0.1)\n",
        "num_test = len(dataset) - (num_training + num_val)\n",
        "training_set, validation_set, test_set = random_split(dataset, [num_training, num_val, num_test])\n",
        "\n",
        "if args.multi_gpu:\n",
        "\tloader = DataListLoader\n",
        "else:\n",
        "\tloader = DataLoader\n",
        "\n",
        "train_loader = loader(training_set, batch_size=args.batch_size, shuffle=True)\n",
        "val_loader = loader(validation_set, batch_size=args.batch_size, shuffle=False)\n",
        "test_loader = loader(test_set, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "model = Net(concat=args.concat).to(args.device)\n",
        "if args.multi_gpu:\n",
        "\tmodel = DataParallel(model)\n",
        "model = model.to(args.device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiPiEiIl_DcN",
        "outputId": "09ab4db3-59fd-411e-d3b6-43f45188e2d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(seed=777, device='cpu', dataset='politifact', batch_size=128, lr=0.001, weight_decay=0.01, nhid=128, epochs=50, concat=False, multi_gpu=False, feature='spacy', num_classes=2, num_features=300)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "t = time.time()\n",
        "model.train()\n",
        "for epoch in tqdm(range(args.epochs)):\n",
        "\tout_log = []\n",
        "\tloss_train = 0.0\n",
        "\tfor i, data in enumerate(train_loader):\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\tif not args.multi_gpu:\n",
        "\t\t\tdata = data.to(args.device)\n",
        "\t\tout = model(data)\n",
        "\t\tif args.multi_gpu:\n",
        "\t\t\ty = torch.cat([d.y.unsqueeze(0) for d in data]).squeeze().to(out.device)\n",
        "\t\telse:\n",
        "\t\t\ty = data.y\n",
        "\t\tloss = F.nll_loss(out, y)\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n",
        "\t\tloss_train += loss.item()\n",
        "\t\tout_log.append([F.softmax(out, dim=1), y])\n",
        "\tacc_train, _, _, _, recall_train, auc_train, _ = eval_deep(out_log, train_loader)\n",
        "\t[acc_val, _, _, _, recall_val, auc_val, _], loss_val = compute_test(val_loader)\n",
        "\tprint(f'loss_train: {loss_train:.4f}, acc_train: {acc_train:.4f},'\n",
        "\t\t\t  f' recall_train: {recall_train:.4f}, auc_train: {auc_train:.4f},'\n",
        "\t\t\t  f' loss_val: {loss_val:.4f}, acc_val: {acc_val:.4f},'\n",
        "\t\t\t  f' recall_val: {recall_val:.4f}, auc_val: {auc_val:.4f}')\n",
        "\n",
        "[acc, f1_macro, f1_micro, precision, recall, auc, ap], test_loss = compute_test(test_loader, verbose=False)\n",
        "print(f'Test set results: acc: {acc:.4f}, f1_macro: {f1_macro:.4f}, f1_micro: {f1_micro:.4f}, '\n",
        "\t\t  f'precision: {precision:.4f}, recall: {recall:.4f}, auc: {auc:.4f}, ap: {ap:.4f}')\n",
        "acc_GCN_FN = acc\n",
        "f1_GCN_FN = f1_micro\n",
        "auc_GCN_FN = auc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0TPttex_DXp",
        "outputId": "754b2b9f-e59b-4b7d-823e-71606e5e1c1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 1/50 [00:00<00:26,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6980, acc_train: 0.4355, recall_train: 0.2308, auc_train: 0.4263, loss_val: 0.8374, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.5641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [00:01<00:25,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.7037, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.6271, loss_val: 0.7363, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.7607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [00:01<00:24,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6684, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.7778, loss_val: 0.6763, acc_val: 0.5484, recall_val: 0.3333, auc_val: 0.8419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [00:02<00:25,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6701, acc_train: 0.8065, recall_train: 0.5385, auc_train: 0.9145, loss_val: 0.6719, acc_val: 0.4839, recall_val: 0.1111, auc_val: 0.8590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [00:02<00:24,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6609, acc_train: 0.6935, recall_train: 0.2692, auc_train: 0.9220, loss_val: 0.6993, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.8462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [00:03<00:23,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6466, acc_train: 0.5968, recall_train: 0.0385, auc_train: 0.9081, loss_val: 0.7298, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.8462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [00:03<00:22,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6456, acc_train: 0.5806, recall_train: 0.0000, auc_train: 0.9028, loss_val: 0.7155, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.8718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [00:04<00:19,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6358, acc_train: 0.5968, recall_train: 0.0385, auc_train: 0.9156, loss_val: 0.6691, acc_val: 0.4194, recall_val: 0.0000, auc_val: 0.8803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [00:04<00:18,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6222, acc_train: 0.5968, recall_train: 0.0385, auc_train: 0.9209, loss_val: 0.6356, acc_val: 0.7097, recall_val: 0.5556, auc_val: 0.8932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [00:04<00:17,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6176, acc_train: 0.8226, recall_train: 0.6538, auc_train: 0.9231, loss_val: 0.6287, acc_val: 0.6452, recall_val: 0.4444, auc_val: 0.8932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [00:05<00:16,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.6042, acc_train: 0.8065, recall_train: 0.6154, auc_train: 0.9231, loss_val: 0.6481, acc_val: 0.4516, recall_val: 0.0556, auc_val: 0.8932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [00:05<00:15,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.5899, acc_train: 0.6129, recall_train: 0.0769, auc_train: 0.9188, loss_val: 0.6550, acc_val: 0.4516, recall_val: 0.0556, auc_val: 0.8932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [00:06<00:15,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.5798, acc_train: 0.5968, recall_train: 0.0385, auc_train: 0.9199, loss_val: 0.6145, acc_val: 0.6452, recall_val: 0.3889, auc_val: 0.8974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [00:06<00:15,  2.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.5616, acc_train: 0.7581, recall_train: 0.4615, auc_train: 0.9199, loss_val: 0.5738, acc_val: 0.7742, recall_val: 0.7222, auc_val: 0.8932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [00:06<00:14,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.5490, acc_train: 0.8710, recall_train: 0.8846, auc_train: 0.9263, loss_val: 0.5686, acc_val: 0.7419, recall_val: 0.6111, auc_val: 0.8974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [00:07<00:14,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.5280, acc_train: 0.8548, recall_train: 0.7308, auc_train: 0.9284, loss_val: 0.5850, acc_val: 0.6129, recall_val: 0.3889, auc_val: 0.8932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [00:07<00:14,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.5110, acc_train: 0.8065, recall_train: 0.5769, auc_train: 0.9263, loss_val: 0.5420, acc_val: 0.7419, recall_val: 0.6111, auc_val: 0.8932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [00:08<00:13,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.4875, acc_train: 0.8387, recall_train: 0.7308, auc_train: 0.9295, loss_val: 0.5027, acc_val: 0.7742, recall_val: 0.7778, auc_val: 0.8889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [00:08<00:13,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.4708, acc_train: 0.8548, recall_train: 0.8846, auc_train: 0.9295, loss_val: 0.5222, acc_val: 0.7419, recall_val: 0.6111, auc_val: 0.8889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [00:09<00:13,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.4488, acc_train: 0.8548, recall_train: 0.7308, auc_train: 0.9316, loss_val: 0.5029, acc_val: 0.7419, recall_val: 0.6111, auc_val: 0.8974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [00:09<00:15,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.4283, acc_train: 0.8548, recall_train: 0.7692, auc_train: 0.9327, loss_val: 0.4551, acc_val: 0.7742, recall_val: 0.7778, auc_val: 0.8974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [00:10<00:14,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.4116, acc_train: 0.8548, recall_train: 0.8846, auc_train: 0.9391, loss_val: 0.4912, acc_val: 0.7419, recall_val: 0.6111, auc_val: 0.8974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [00:10<00:12,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.3915, acc_train: 0.8387, recall_train: 0.7308, auc_train: 0.9402, loss_val: 0.4412, acc_val: 0.8065, recall_val: 0.7222, auc_val: 0.9017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [00:11<00:11,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.3698, acc_train: 0.8710, recall_train: 0.8462, auc_train: 0.9423, loss_val: 0.4371, acc_val: 0.8065, recall_val: 0.7222, auc_val: 0.9017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [00:11<00:11,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.3510, acc_train: 0.8710, recall_train: 0.8462, auc_train: 0.9444, loss_val: 0.4556, acc_val: 0.8065, recall_val: 0.7222, auc_val: 0.9060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [00:11<00:10,  2.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.3357, acc_train: 0.8871, recall_train: 0.8077, auc_train: 0.9476, loss_val: 0.3918, acc_val: 0.8065, recall_val: 0.8333, auc_val: 0.9103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [00:12<00:10,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.3275, acc_train: 0.8387, recall_train: 0.8846, auc_train: 0.9487, loss_val: 0.5162, acc_val: 0.7097, recall_val: 0.5556, auc_val: 0.9103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [00:12<00:10,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.3275, acc_train: 0.8871, recall_train: 0.7308, auc_train: 0.9530, loss_val: 0.3740, acc_val: 0.8387, recall_val: 0.8889, auc_val: 0.9103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [00:13<00:09,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.3089, acc_train: 0.8226, recall_train: 0.8846, auc_train: 0.9541, loss_val: 0.4109, acc_val: 0.8065, recall_val: 0.7222, auc_val: 0.9145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [00:13<00:09,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.2759, acc_train: 0.9032, recall_train: 0.8462, auc_train: 0.9573, loss_val: 0.4794, acc_val: 0.7419, recall_val: 0.6111, auc_val: 0.9145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [00:14<00:09,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.2807, acc_train: 0.8548, recall_train: 0.7308, auc_train: 0.9605, loss_val: 0.3626, acc_val: 0.8387, recall_val: 0.8889, auc_val: 0.9145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [00:15<00:09,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.2707, acc_train: 0.8710, recall_train: 0.9231, auc_train: 0.9669, loss_val: 0.3989, acc_val: 0.8065, recall_val: 0.7778, auc_val: 0.9145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [00:15<00:08,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.2397, acc_train: 0.9032, recall_train: 0.8462, auc_train: 0.9712, loss_val: 0.4557, acc_val: 0.8065, recall_val: 0.7222, auc_val: 0.9145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [00:16<00:08,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.2424, acc_train: 0.9032, recall_train: 0.8077, auc_train: 0.9722, loss_val: 0.3526, acc_val: 0.8387, recall_val: 0.8889, auc_val: 0.9231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [00:16<00:07,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.2314, acc_train: 0.9194, recall_train: 0.9231, auc_train: 0.9776, loss_val: 0.3817, acc_val: 0.8065, recall_val: 0.7778, auc_val: 0.9231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 36/50 [00:17<00:07,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.2056, acc_train: 0.9194, recall_train: 0.8846, auc_train: 0.9797, loss_val: 0.4310, acc_val: 0.8065, recall_val: 0.7222, auc_val: 0.9231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 37/50 [00:17<00:05,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.2059, acc_train: 0.9032, recall_train: 0.8077, auc_train: 0.9861, loss_val: 0.3387, acc_val: 0.8710, recall_val: 0.8889, auc_val: 0.9231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 38/50 [00:17<00:05,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1966, acc_train: 0.9355, recall_train: 0.9615, auc_train: 0.9893, loss_val: 0.3733, acc_val: 0.8065, recall_val: 0.7778, auc_val: 0.9274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 39/50 [00:18<00:04,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1740, acc_train: 0.9516, recall_train: 0.9231, auc_train: 0.9904, loss_val: 0.3988, acc_val: 0.8065, recall_val: 0.7222, auc_val: 0.9316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 40/50 [00:18<00:03,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1698, acc_train: 0.9355, recall_train: 0.8846, auc_train: 0.9925, loss_val: 0.3225, acc_val: 0.8710, recall_val: 0.8889, auc_val: 0.9402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 41/50 [00:18<00:03,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1669, acc_train: 0.9355, recall_train: 0.9615, auc_train: 0.9925, loss_val: 0.3791, acc_val: 0.8065, recall_val: 0.7222, auc_val: 0.9402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 42/50 [00:19<00:03,  2.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1492, acc_train: 0.9516, recall_train: 0.9231, auc_train: 0.9925, loss_val: 0.3575, acc_val: 0.8065, recall_val: 0.7778, auc_val: 0.9402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 43/50 [00:19<00:02,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1382, acc_train: 0.9677, recall_train: 0.9615, auc_train: 0.9936, loss_val: 0.3097, acc_val: 0.8710, recall_val: 0.8889, auc_val: 0.9402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 44/50 [00:20<00:02,  2.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1389, acc_train: 0.9516, recall_train: 0.9615, auc_train: 0.9947, loss_val: 0.3930, acc_val: 0.8065, recall_val: 0.7222, auc_val: 0.9402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 45/50 [00:20<00:01,  2.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1320, acc_train: 0.9516, recall_train: 0.9231, auc_train: 0.9968, loss_val: 0.3184, acc_val: 0.8387, recall_val: 0.8333, auc_val: 0.9359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 46/50 [00:20<00:01,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1174, acc_train: 0.9677, recall_train: 0.9615, auc_train: 0.9968, loss_val: 0.3106, acc_val: 0.8710, recall_val: 0.8889, auc_val: 0.9359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 47/50 [00:21<00:01,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1124, acc_train: 0.9677, recall_train: 0.9615, auc_train: 0.9979, loss_val: 0.3865, acc_val: 0.8065, recall_val: 0.7222, auc_val: 0.9402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 48/50 [00:21<00:00,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1130, acc_train: 0.9516, recall_train: 0.9231, auc_train: 0.9979, loss_val: 0.2976, acc_val: 0.8710, recall_val: 0.8889, auc_val: 0.9444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 49/50 [00:21<00:00,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.1053, acc_train: 0.9839, recall_train: 1.0000, auc_train: 0.9979, loss_val: 0.3351, acc_val: 0.8387, recall_val: 0.8333, auc_val: 0.9444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:22<00:00,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_train: 0.0943, acc_train: 0.9516, recall_train: 0.9231, auc_train: 0.9979, loss_val: 0.3584, acc_val: 0.7742, recall_val: 0.7222, auc_val: 0.9444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set results: acc: 0.8371, f1_macro: 0.8347, f1_micro: 0.8371, precision: 0.9002, recall: 0.7658, auc: 0.9081, ap: 0.9284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hypergraph Neural Networks**"
      ],
      "metadata": {
        "id": "uftUzDtwAgEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **HGFND Architecture**"
      ],
      "metadata": {
        "id": "ALCHdmAiVZm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "class HyperGraphAttentionLayerSparse(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout, alpha, transfer, concat=True, bias=False):\n",
        "        super(HyperGraphAttentionLayerSparse, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.alpha = alpha\n",
        "        self.concat = concat\n",
        "\n",
        "        self.transfer = transfer\n",
        "\n",
        "        if self.transfer:\n",
        "            self.weight = Parameter(torch.Tensor(self.in_features, self.out_features))\n",
        "        else:\n",
        "            self.register_parameter('weight', None)\n",
        "\n",
        "        self.weight2 = Parameter(torch.Tensor(self.in_features, self.out_features))\n",
        "        self.weight3 = Parameter(torch.Tensor(self.out_features, self.out_features))\n",
        "\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.Tensor(self.out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "        self.word_context = nn.Embedding(1, self.out_features)\n",
        "\n",
        "        self.a = nn.Parameter(torch.zeros(size=(2 * out_features, 1)))\n",
        "        self.a2 = nn.Parameter(torch.zeros(size=(2 * out_features, 1)))\n",
        "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.out_features)\n",
        "        if self.weight is not None:\n",
        "            self.weight.data.uniform_(-stdv, stdv)\n",
        "        self.weight2.data.uniform_(-stdv, stdv)\n",
        "        self.weight3.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "        nn.init.uniform_(self.a.data, -stdv, stdv)\n",
        "        nn.init.uniform_(self.a2.data, -stdv, stdv)\n",
        "        nn.init.uniform_(self.word_context.weight.data, -stdv, stdv)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x_4att = x.matmul(self.weight2)\n",
        "\n",
        "        if self.transfer:\n",
        "            x = x.matmul(self.weight)\n",
        "            if self.bias is not None:\n",
        "                x = x + self.bias\n",
        "\n",
        "        N1 = adj.shape[1]  # number of edge\n",
        "        N2 = adj.shape[2]  # number of node\n",
        "\n",
        "        pair = adj.nonzero().t()\n",
        "\n",
        "        get = lambda i: x_4att[i][adj[i].nonzero().t()[1]]\n",
        "        x1 = torch.cat([get(i) for i in torch.arange(x.shape[0]).long()])\n",
        "\n",
        "        q1 = self.word_context.weight[0:].view(1, -1).repeat(x1.shape[0], 1).view(x1.shape[0], self.out_features)\n",
        "\n",
        "        pair_h = torch.cat((q1, x1), dim=-1)\n",
        "        pair_e = self.leakyrelu(torch.matmul(pair_h, self.a).squeeze()).t()\n",
        "        assert not torch.isnan(pair_e).any()\n",
        "        pair_e = F.dropout(pair_e, self.dropout, training=self.training)\n",
        "\n",
        "        e = torch.sparse_coo_tensor(pair, pair_e, torch.Size([x.shape[0], N1, N2])).to_dense()\n",
        "\n",
        "        zero_vec = -9e15 * torch.ones_like(e)\n",
        "        attention = torch.where(adj > 0, e, zero_vec)\n",
        "\n",
        "        attention_edge = F.softmax(attention, dim=2)\n",
        "\n",
        "        edge = torch.matmul(attention_edge, x)\n",
        "\n",
        "        edge = F.dropout(edge, self.dropout, training=self.training)\n",
        "\n",
        "        edge_4att = edge.matmul(self.weight3)\n",
        "\n",
        "        get = lambda i: edge_4att[i][adj[i].nonzero().t()[0]]\n",
        "        y1 = torch.cat([get(i) for i in torch.arange(x.shape[0]).long()])\n",
        "\n",
        "        get = lambda i: x_4att[i][adj[i].nonzero().t()[1]]\n",
        "        q1 = torch.cat([get(i) for i in torch.arange(x.shape[0]).long()])\n",
        "\n",
        "        pair_h = torch.cat((q1, y1), dim=-1)\n",
        "        pair_e = self.leakyrelu(torch.matmul(pair_h, self.a2).squeeze()).t()\n",
        "        assert not torch.isnan(pair_e).any()\n",
        "        pair_e = F.dropout(pair_e, self.dropout, training=self.training)\n",
        "\n",
        "        e = torch.sparse_coo_tensor(pair, pair_e, torch.Size([x.shape[0], N1, N2])).to_dense()\n",
        "\n",
        "        zero_vec = -9e15 * torch.ones_like(e)\n",
        "        attention = torch.where(adj > 0, e, zero_vec)\n",
        "\n",
        "        attention_node = F.softmax(attention.transpose(1, 2), dim=2)\n",
        "\n",
        "        node = torch.matmul(attention_node, edge)\n",
        "\n",
        "        if self.concat:\n",
        "            node = F.elu(node)\n",
        "\n",
        "        return node, edge  # edge_4att\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' + str(self.in_features) + ' -> ' + str(self.out_features) + ')'"
      ],
      "metadata": {
        "id": "wnQGUv8LA5dT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.nn import Module\n",
        "from torch_geometric.nn import SAGEConv, global_max_pool\n",
        "# from gnn_model.layers import HyperGraphAttentionLayerSparse\n",
        "import math\n",
        "\n",
        "\n",
        "class PropagationEncoder(nn.Module):\n",
        "    def __init__(self, args, hypergraph_model):\n",
        "        super().__init__()\n",
        "        self.out_channels = args.num_classes\n",
        "        self.hidden_channels = args.hiddenSize\n",
        "        self.in_channels = args.num_features\n",
        "        self.hypergraph_model = hypergraph_model\n",
        "        self.conv1 = SAGEConv(self.in_channels, self.hidden_channels)\n",
        "        self.lin0 = nn.Linear(self.in_channels, self.hidden_channels)\n",
        "        self.lin1 = nn.Linear(2 * self.hidden_channels, self.hidden_channels)\n",
        "        self.cls = nn.Linear(self.hidden_channels, self.out_channels, bias=True)\n",
        "\n",
        "    def forward(self, x, edge_index, HT, batch, slices):\n",
        "        # Get the root node (tweet) features of each graph:\n",
        "        root = (batch[1:] - batch[:-1]).nonzero(as_tuple=False).view(-1)\n",
        "        root = torch.cat([root.new_zeros(1), root + 1], dim=0)\n",
        "        news = x[root]\n",
        "        news = self.lin0(news).relu()\n",
        "\n",
        "        p = self.conv1(x, edge_index).relu()\n",
        "        p = global_max_pool(p, batch)\n",
        "        p = self.lin1(torch.cat([news, p], dim=-1)).relu()\n",
        "\n",
        "        v = p.unsqueeze(0)\n",
        "        v, e = self.hypergraph_model(v, HT)\n",
        "        result = v.squeeze(0)[slices]\n",
        "        return result, e\n",
        "\n",
        "    def compute_scores(self, target):\n",
        "        pred = self.cls(target)\n",
        "        return F.log_softmax(pred, dim=-1)\n",
        "\n",
        "\n",
        "class HGFND(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(HGFND, self).__init__()\n",
        "        self.hidden_size = args.hiddenSize\n",
        "        self.out_channels = args.num_classes\n",
        "        self.hypergraph_embedding = NewsHypergraph(args, self.hidden_size, self.out_channels)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def forward(self, nodes_embedding, HT):\n",
        "        hypergraph_embedding, edge_att = self.hypergraph_embedding(nodes_embedding, HT)\n",
        "        return hypergraph_embedding, edge_att\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for weight in self.parameters():\n",
        "            weight.data.uniform_(-stdv, stdv)\n",
        "\n",
        "\n",
        "class NewsHypergraph(Module):\n",
        "    def __init__(self, args, initialFeatureSize, n_categories):\n",
        "        super(NewsHypergraph, self).__init__()\n",
        "        self.initial_feature = initialFeatureSize\n",
        "        self.hidden_size = args.hiddenSize\n",
        "        self.n_categories = n_categories\n",
        "        self.dropout = args.dropout\n",
        "\n",
        "        self.cls = nn.Linear(self.hidden_size, self.n_categories, bias=True)\n",
        "        self.hgnn = HGNN_ATT(self.initial_feature, self.initial_feature, self.hidden_size, dropout=self.dropout)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for weight in self.parameters():\n",
        "            weight.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, nodes, HT):\n",
        "        hypergraph, edge_att = self.hgnn(nodes, HT)  # documents are nodes and inputs\n",
        "        return hypergraph, edge_att\n",
        "\n",
        "class HGNN_ATT(nn.Module):\n",
        "    def __init__(self, input_size, n_hid, output_size, dropout=0.3):\n",
        "        super(HGNN_ATT, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.gat1 = HyperGraphAttentionLayerSparse(input_size, n_hid, dropout=self.dropout, alpha=0.2, transfer=False,\n",
        "                                                   concat=True)\n",
        "        self.gat2 = HyperGraphAttentionLayerSparse(n_hid, output_size, dropout=self.dropout, alpha=0.2, transfer=True,\n",
        "                                                   concat=False)\n",
        "\n",
        "    def forward(self, x, H):\n",
        "        x, e = self.gat1(x, H)\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "\n",
        "        x, e = self.gat2(x, H)\n",
        "\n",
        "        return x, e"
      ],
      "metadata": {
        "id": "sJutFkbPA9aF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "\n",
        "class Hypergraph:\n",
        "    def __init__(self, opt):\n",
        "        self.dataset = opt.dataset\n",
        "\n",
        "\n",
        "    def get_hyperedges(self):\n",
        "        dirname = \"/content/drive/MyDrive/\"\n",
        "        if self.dataset == \"politifact\":\n",
        "            filename = \"hypergraph_politifact.pkl\"\n",
        "        elif self.dataset == \"gossipcop\":\n",
        "            filename = \"hypergraph_gossipcop.pkl\"\n",
        "\n",
        "        with open(dirname + filename, 'rb') as handle:\n",
        "            result = pickle.load(handle)\n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "\n",
        "    def get_adj_matrix(self, hyperedges, nodes_seq):\n",
        "        items, n_node, HT, alias_inputs, node_masks, node_dic = [], [], [], [], [], []\n",
        "\n",
        "        node_list = nodes_seq\n",
        "        node_set = list(set(node_list))\n",
        "        node_dic = {node_set[i]: i for i in range(len(node_set))}\n",
        "\n",
        "        rows = []\n",
        "        cols = []\n",
        "        vals = []\n",
        "        max_n_node = len(node_set)\n",
        "        max_n_edge = len(hyperedges)\n",
        "        total_num_node = len(node_set)\n",
        "\n",
        "        # num_hypergraphs can be used for batching different size of hypergraphs for training\n",
        "        num_hypergraphs = 1\n",
        "        for idx in range(num_hypergraphs):\n",
        "            for hyperedge_seq, hyperedge in enumerate(hyperedges):\n",
        "                for node_id in hyperedge:\n",
        "                    rows.append(node_dic[node_id])\n",
        "                    cols.append(hyperedge_seq)\n",
        "                    vals.append(1)\n",
        "            u_H = sp.coo_matrix((vals, (rows, cols)), shape=(max_n_node, max_n_edge))\n",
        "            HT.append(np.asarray(u_H.T.todense()))\n",
        "            alias_inputs.append([j for j in range(max_n_node)])\n",
        "            node_masks.append([1 for j in range(total_num_node)] + (max_n_node - total_num_node) * [0])\n",
        "\n",
        "        return alias_inputs, HT, node_masks"
      ],
      "metadata": {
        "id": "F_keg8b9ZjqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **HGFND Run Model**"
      ],
      "metadata": {
        "id": "oHiQaxeDVMuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import copy\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "from sklearn import metrics\n",
        "# from utils.hypergraph import Hypergraph\n",
        "# from gnn_model.model import HGFND, PropagationEncoder\n",
        "# from utils.data_loader import *\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--dataset', type=str, default='politifact',\n",
        "                    choices=['politifact', 'gossipcop'])\n",
        "parser.add_argument('--hiddenSize', type=int, default=128, help='hidden state size for propagation encoding')\n",
        "parser.add_argument('--dropout', type=float, default=0.3, help='dropout rate')\n",
        "parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
        "parser.add_argument('--weight_decay', type=float, default=0.01, help='weight_decay penalty')\n",
        "parser.add_argument('--batchSize', type=int, default=128, help='input batch size')\n",
        "parser.add_argument('--epoch', type=int, default=200, help='epoch size')\n",
        "parser.add_argument('--shuffle', type=bool, default=True, help='shuffling training index')\n",
        "parser.add_argument('--seed', type=int, default=777, help='random seed')\n",
        "\n",
        "# args = parser.parse_args()\n",
        "args, _ = parser.parse_known_args()\n",
        "print(args)\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(args.seed)\n",
        "\n",
        "dataset = FNNDataset(root='/content/drive/MyDrive', feature=\"bert\", empty=False, name=args.dataset, transform=ToUndirected())\n",
        "\n",
        "args.num_classes = dataset.num_classes\n",
        "args.num_features = dataset.num_features\n",
        "\n",
        "num_train = int(len(dataset) * 0.2)\n",
        "num_val = int(len(dataset) * 0.1)\n",
        "num_test = len(dataset) - (num_train + num_val)\n",
        "training_set, validation_set, test_set = random_split(dataset, [num_train, num_val, num_test])\n",
        "\n",
        "loader = DataLoader\n",
        "\n",
        "all_loader = loader(dataset, batch_size=len(dataset), shuffle=False)\n",
        "train_loader = loader(training_set, batch_size=args.batchSize, shuffle=True)\n",
        "val_loader = loader(validation_set, batch_size=args.batchSize, shuffle=False)\n",
        "test_loader = loader(test_set, batch_size=args.batchSize, shuffle=False)\n",
        "\n",
        "all_dataset = all_loader.dataset\n",
        "train_dataset = train_loader.dataset\n",
        "val_dataset = val_loader.dataset\n",
        "test_dataset = test_loader.dataset\n",
        "\n",
        "for data in all_loader:\n",
        "    data = data.to(device)\n",
        "    data_batch = data.batch\n",
        "    data_edge_index = data.edge_index\n",
        "    data_nodes = data.x\n",
        "    data_labels = data.y\n",
        "\n",
        "train_idx = train_dataset.indices\n",
        "num_train = len(train_idx)\n",
        "val_idx = val_dataset.indices\n",
        "test_idx = test_dataset.indices\n",
        "nodes_seq = np.arange(len(data_labels))\n",
        "\n",
        "builder = Hypergraph(args)\n",
        "hypergraph = builder.get_hyperedges()\n",
        "alias_inputs, HT, node_masks = builder.get_adj_matrix(hypergraph, nodes_seq)\n",
        "\n",
        "HT = torch.Tensor(np.array(HT)).float().to(device)\n",
        "\n",
        "hypergraph_model = HGFND(args)\n",
        "model = PropagationEncoder(args, hypergraph_model).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "\n",
        "\n",
        "def train(train_idx):\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    for idx in range(0, num_train, args.batchSize):\n",
        "        slices = train_idx[idx:min(idx + args.batchSize, num_train)]\n",
        "        optimizer.zero_grad()\n",
        "        out, _ = model(data_nodes, data_edge_index, HT, data_batch, slices)\n",
        "        scores = model.compute_scores(out)\n",
        "        labels = data_labels[slices]\n",
        "        loss = F.nll_loss(scores, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * len(slices)\n",
        "\n",
        "    return total_loss / num_train\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(test_idx, verbose=False):\n",
        "    model.eval()\n",
        "\n",
        "    num_samples = len(test_idx)\n",
        "    test_preds = []\n",
        "    out_log = []\n",
        "    for idx in range(0, num_samples, args.batchSize):\n",
        "        slices = test_idx[idx:min(idx + args.batchSize, num_samples)]\n",
        "        output, _ = model(data_nodes, data_edge_index, HT, data_batch, slices)\n",
        "        scores = model.compute_scores(output)\n",
        "        pred = scores.argmax(dim=-1)\n",
        "        test_preds += list(pred.detach().cpu().numpy())\n",
        "        temp_labels = data_labels[slices]\n",
        "        out_log.append([scores, temp_labels.view(-1, 1)])\n",
        "\n",
        "    test_labels = data_labels[test_idx]\n",
        "    test_labels = list(test_labels.detach().cpu().numpy())\n",
        "    acc = metrics.accuracy_score(test_labels, test_preds)\n",
        "    details = []\n",
        "    if verbose:\n",
        "        f1_macro, f1_micro, precision, recall = 0, 0, 0, 0\n",
        "        f1_macro += metrics.f1_score(test_labels, test_preds, average='macro')\n",
        "        f1_micro += metrics.f1_score(test_labels, test_preds, average='micro')\n",
        "        precision += metrics.precision_score(test_labels, test_preds, zero_division=0)\n",
        "        recall += metrics.recall_score(test_labels, test_preds, zero_division=0)\n",
        "        details = [f1_macro, f1_micro, precision, recall]\n",
        "    return acc, details\n",
        "\n",
        "\n",
        "best_val_acc = 0\n",
        "for epoch in range(1, args.epoch):\n",
        "    loss = train(train_idx)\n",
        "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')\n",
        "\n",
        "    val_acc, _ = test(val_idx, verbose=False)\n",
        "    print(f'Val Accuracy: {val_acc:.4f}')\n",
        "    if best_val_acc < val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        state_dict = copy.deepcopy(model.state_dict())\n",
        "\n",
        "print(\"**Loading The Best model on Validation Dataset: \")\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "acc, [f1_macro, f1_micro, precision, recall] = test(test_idx, verbose=True)\n",
        "print(\"Test result: \", acc, f1_macro, f1_micro, precision, recall)\n",
        "acc_HGFND = acc\n",
        "f1_HGFND = f1_macro"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4DF30uoBC3h",
        "outputId": "95b6e002-97a6-45b0-d71f-a4d564de887f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(dataset='politifact', hiddenSize=128, dropout=0.3, lr=0.001, weight_decay=0.01, batchSize=128, epoch=200, shuffle=True, seed=777)\n",
            "Epoch: 01, Loss: 0.6905\n",
            "Val Accuracy: 0.4194\n",
            "Epoch: 02, Loss: 0.6801\n",
            "Val Accuracy: 0.4194\n",
            "Epoch: 03, Loss: 0.6773\n",
            "Val Accuracy: 0.4194\n",
            "Epoch: 04, Loss: 0.6803\n",
            "Val Accuracy: 0.4194\n",
            "Epoch: 05, Loss: 0.6788\n",
            "Val Accuracy: 0.4194\n",
            "Epoch: 06, Loss: 0.6779\n",
            "Val Accuracy: 0.4194\n",
            "Epoch: 07, Loss: 0.6751\n",
            "Val Accuracy: 0.4194\n",
            "Epoch: 08, Loss: 0.6746\n",
            "Val Accuracy: 0.4194\n",
            "Epoch: 09, Loss: 0.6741\n",
            "Val Accuracy: 0.4194\n",
            "Epoch: 10, Loss: 0.6746\n",
            "Val Accuracy: 0.4194\n",
            "Epoch: 11, Loss: 0.6729\n",
            "Val Accuracy: 0.4194\n",
            "Epoch: 12, Loss: 0.6703\n",
            "Val Accuracy: 0.4194\n",
            "Epoch: 13, Loss: 0.6675\n",
            "Val Accuracy: 0.4194\n",
            "Epoch: 14, Loss: 0.6666\n",
            "Val Accuracy: 0.4194\n",
            "Epoch: 15, Loss: 0.6648\n",
            "Val Accuracy: 0.4194\n",
            "Epoch: 16, Loss: 0.6586\n",
            "Val Accuracy: 0.4194\n",
            "Epoch: 17, Loss: 0.6554\n",
            "Val Accuracy: 0.4194\n",
            "Epoch: 18, Loss: 0.6491\n",
            "Val Accuracy: 0.4194\n",
            "Epoch: 19, Loss: 0.6444\n",
            "Val Accuracy: 0.4194\n",
            "Epoch: 20, Loss: 0.6365\n",
            "Val Accuracy: 0.4194\n",
            "Epoch: 21, Loss: 0.6307\n",
            "Val Accuracy: 0.4194\n",
            "Epoch: 22, Loss: 0.6144\n",
            "Val Accuracy: 0.4194\n",
            "Epoch: 23, Loss: 0.6030\n",
            "Val Accuracy: 0.4516\n",
            "Epoch: 24, Loss: 0.5851\n",
            "Val Accuracy: 0.4516\n",
            "Epoch: 25, Loss: 0.5631\n",
            "Val Accuracy: 0.7097\n",
            "Epoch: 26, Loss: 0.5460\n",
            "Val Accuracy: 0.6129\n",
            "Epoch: 27, Loss: 0.5200\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 28, Loss: 0.4884\n",
            "Val Accuracy: 0.6129\n",
            "Epoch: 29, Loss: 0.4792\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 30, Loss: 0.4758\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 31, Loss: 0.4210\n",
            "Val Accuracy: 0.7419\n",
            "Epoch: 32, Loss: 0.3991\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 33, Loss: 0.4025\n",
            "Val Accuracy: 0.9032\n",
            "Epoch: 34, Loss: 0.3409\n",
            "Val Accuracy: 0.9032\n",
            "Epoch: 35, Loss: 0.3299\n",
            "Val Accuracy: 0.9032\n",
            "Epoch: 36, Loss: 0.3122\n",
            "Val Accuracy: 0.9032\n",
            "Epoch: 37, Loss: 0.2914\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 38, Loss: 0.2773\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 39, Loss: 0.2899\n",
            "Val Accuracy: 0.6452\n",
            "Epoch: 40, Loss: 0.4995\n",
            "Val Accuracy: 0.8065\n",
            "Epoch: 41, Loss: 0.3103\n",
            "Val Accuracy: 0.8065\n",
            "Epoch: 42, Loss: 0.3119\n",
            "Val Accuracy: 0.8065\n",
            "Epoch: 43, Loss: 0.2533\n",
            "Val Accuracy: 0.7742\n",
            "Epoch: 44, Loss: 0.2824\n",
            "Val Accuracy: 0.9032\n",
            "Epoch: 45, Loss: 0.1965\n",
            "Val Accuracy: 0.8065\n",
            "Epoch: 46, Loss: 0.3048\n",
            "Val Accuracy: 0.9032\n",
            "Epoch: 47, Loss: 0.2231\n",
            "Val Accuracy: 0.8065\n",
            "Epoch: 48, Loss: 0.2393\n",
            "Val Accuracy: 0.8065\n",
            "Epoch: 49, Loss: 0.2162\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 50, Loss: 0.2039\n",
            "Val Accuracy: 0.9032\n",
            "Epoch: 51, Loss: 0.2093\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 52, Loss: 0.1725\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 53, Loss: 0.2455\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 54, Loss: 0.1731\n",
            "Val Accuracy: 0.9032\n",
            "Epoch: 55, Loss: 0.1748\n",
            "Val Accuracy: 0.9032\n",
            "Epoch: 56, Loss: 0.1994\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 57, Loss: 0.2006\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 58, Loss: 0.1623\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 59, Loss: 0.1487\n",
            "Val Accuracy: 0.9032\n",
            "Epoch: 60, Loss: 0.1400\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 61, Loss: 0.1493\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 62, Loss: 0.1564\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 63, Loss: 0.1556\n",
            "Val Accuracy: 0.9032\n",
            "Epoch: 64, Loss: 0.1300\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 65, Loss: 0.1443\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 66, Loss: 0.0735\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 67, Loss: 0.1477\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 68, Loss: 0.0865\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 69, Loss: 0.1295\n",
            "Val Accuracy: 0.9032\n",
            "Epoch: 70, Loss: 0.1058\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 71, Loss: 0.1737\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 72, Loss: 0.2491\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 73, Loss: 0.0580\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 74, Loss: 0.2016\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 75, Loss: 0.0923\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 76, Loss: 0.1042\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 77, Loss: 0.1061\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 78, Loss: 0.0888\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 79, Loss: 0.0413\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 80, Loss: 0.0956\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 81, Loss: 0.0456\n",
            "Val Accuracy: 0.9032\n",
            "Epoch: 82, Loss: 0.0397\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 83, Loss: 0.0401\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 84, Loss: 0.0283\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 85, Loss: 0.0667\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 86, Loss: 0.0335\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 87, Loss: 0.0146\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 88, Loss: 0.0233\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 89, Loss: 0.0355\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 90, Loss: 0.0382\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 91, Loss: 0.0177\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 92, Loss: 0.1717\n",
            "Val Accuracy: 0.8065\n",
            "Epoch: 93, Loss: 0.1392\n",
            "Val Accuracy: 0.7742\n",
            "Epoch: 94, Loss: 0.5163\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 95, Loss: 0.0942\n",
            "Val Accuracy: 0.4839\n",
            "Epoch: 96, Loss: 2.2143\n",
            "Val Accuracy: 0.9032\n",
            "Epoch: 97, Loss: 0.0493\n",
            "Val Accuracy: 0.7097\n",
            "Epoch: 98, Loss: 0.4600\n",
            "Val Accuracy: 0.6774\n",
            "Epoch: 99, Loss: 0.8586\n",
            "Val Accuracy: 0.7419\n",
            "Epoch: 100, Loss: 0.2237\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 101, Loss: 0.0536\n",
            "Val Accuracy: 0.8065\n",
            "Epoch: 102, Loss: 0.2404\n",
            "Val Accuracy: 0.7097\n",
            "Epoch: 103, Loss: 0.3919\n",
            "Val Accuracy: 0.7097\n",
            "Epoch: 104, Loss: 0.4126\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 105, Loss: 0.1571\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 106, Loss: 0.1012\n",
            "Val Accuracy: 0.8065\n",
            "Epoch: 107, Loss: 0.1325\n",
            "Val Accuracy: 0.7419\n",
            "Epoch: 108, Loss: 0.2983\n",
            "Val Accuracy: 0.7419\n",
            "Epoch: 109, Loss: 0.3007\n",
            "Val Accuracy: 0.7742\n",
            "Epoch: 110, Loss: 0.2298\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 111, Loss: 0.0988\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 112, Loss: 0.0804\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 113, Loss: 0.1247\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 114, Loss: 0.1722\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 115, Loss: 0.1650\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 116, Loss: 0.1508\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 117, Loss: 0.0644\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 118, Loss: 0.0559\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 119, Loss: 0.0596\n",
            "Val Accuracy: 0.8065\n",
            "Epoch: 120, Loss: 0.0802\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 121, Loss: 0.0919\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 122, Loss: 0.0728\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 123, Loss: 0.0291\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 124, Loss: 0.0253\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 125, Loss: 0.0113\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 126, Loss: 0.0762\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 127, Loss: 0.0640\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 128, Loss: 0.0303\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 129, Loss: 0.0178\n",
            "Val Accuracy: 0.8065\n",
            "Epoch: 130, Loss: 0.0226\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 131, Loss: 0.0056\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 132, Loss: 0.0069\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 133, Loss: 0.0055\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 134, Loss: 0.0121\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 135, Loss: 0.0056\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 136, Loss: 0.0025\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 137, Loss: 0.0153\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 138, Loss: 0.0325\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 139, Loss: 0.0026\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 140, Loss: 0.0069\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 141, Loss: 0.0025\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 142, Loss: 0.0090\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 143, Loss: 0.0029\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 144, Loss: 0.0292\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 145, Loss: 0.0070\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 146, Loss: 0.0027\n",
            "Val Accuracy: 0.8065\n",
            "Epoch: 147, Loss: 0.0054\n",
            "Val Accuracy: 0.8065\n",
            "Epoch: 148, Loss: 0.0036\n",
            "Val Accuracy: 0.8065\n",
            "Epoch: 149, Loss: 0.0039\n",
            "Val Accuracy: 0.8065\n",
            "Epoch: 150, Loss: 0.0037\n",
            "Val Accuracy: 0.8065\n",
            "Epoch: 151, Loss: 0.0097\n",
            "Val Accuracy: 0.8065\n",
            "Epoch: 152, Loss: 0.0077\n",
            "Val Accuracy: 0.8065\n",
            "Epoch: 153, Loss: 0.0058\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 154, Loss: 0.0208\n",
            "Val Accuracy: 0.8065\n",
            "Epoch: 155, Loss: 0.0425\n",
            "Val Accuracy: 0.8065\n",
            "Epoch: 156, Loss: 0.0315\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 157, Loss: 0.0035\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 158, Loss: 0.0052\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 159, Loss: 0.0067\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 160, Loss: 0.0070\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 161, Loss: 0.0026\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 162, Loss: 0.0061\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 163, Loss: 0.0095\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 164, Loss: 0.0041\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 165, Loss: 0.0043\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 166, Loss: 0.0045\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 167, Loss: 0.0046\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 168, Loss: 0.0043\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 169, Loss: 0.0283\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 170, Loss: 0.0033\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 171, Loss: 0.0037\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 172, Loss: 0.0033\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 173, Loss: 0.0329\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 174, Loss: 0.0035\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 175, Loss: 0.0179\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 176, Loss: 0.0043\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 177, Loss: 0.0038\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 178, Loss: 0.0027\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 179, Loss: 0.0392\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 180, Loss: 0.0075\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 181, Loss: 0.0350\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 182, Loss: 0.0057\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 183, Loss: 0.0169\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 184, Loss: 0.0078\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 185, Loss: 0.0033\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 186, Loss: 0.0050\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 187, Loss: 0.0203\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 188, Loss: 0.0041\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 189, Loss: 0.0368\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 190, Loss: 0.0768\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 191, Loss: 0.0038\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 192, Loss: 0.0115\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 193, Loss: 0.0081\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 194, Loss: 0.0048\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 195, Loss: 0.0162\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 196, Loss: 0.0062\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 197, Loss: 0.0039\n",
            "Val Accuracy: 0.8387\n",
            "Epoch: 198, Loss: 0.0043\n",
            "Val Accuracy: 0.8710\n",
            "Epoch: 199, Loss: 0.0058\n",
            "Val Accuracy: 0.8710\n",
            "**Loading The Best model on Validation Dataset: \n",
            "Test result:  0.9276018099547512 0.9275884665792923 0.9276018099547512 0.9619047619047619 0.8938053097345132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hdeD3_xYgcBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualization**"
      ],
      "metadata": {
        "id": "MXAvzUkrSRgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dữ liệu\n",
        "categories = ['GCN', 'GraphSAGE','GAT', 'GCN_FN', 'BiGCN','HGFND']\n",
        "values = [acc_GCN, acc_GraphSAGE, acc_GAT, acc_GCN_FN, acc_BiGCN, acc_HGFND]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.bar(categories, values, color=['blue', 'green', 'red','purple', 'yellow','pink'])\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Values')\n",
        "plt.title('Accuracy')\n",
        "\n",
        "# Hiển thị giá trị trên cột\n",
        "for i in range(len(categories)):\n",
        "     plt.text(i, values[i], '{:.2}'.format(values[i]), ha='center', va='bottom')\n",
        "\n",
        "# Hiển thị biểu đồ\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Di8jaA0Qb4s",
        "outputId": "dfcfcf1e-a946-45d5-9503-7c5ac89e0b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAGGCAYAAACNCg6xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA7LklEQVR4nO3deViU9f7/8deALCqKJoqpGCkuaYm5EZplhaGZaamZSyh6qEyKolNpmpQdRVs8mhtmknbCoNzylF9NOVKWC26YJe5rJiqnUkQFhfv3hz/mODHqjQIzyPNxXXNdzH1/7nven5tZXnMvn7EYhmEIAAAA1+Ti6AIAAADKCoITAACASQQnAAAAkwhOAAAAJhGcAAAATCI4AQAAmERwAgAAMIngBAAAYBLBCQAAwCSCEwAAgEkEJwAOMWPGDFksFgUFBTm6FAAwzcJv1QFwhA4dOui3337TwYMHtWfPHgUEBDi6JAC4JvY4ASh1Bw4c0Nq1azVp0iTVrFlTCQkJji7JruzsbEeXAMDJEJwAlLqEhARVr15d3bp1U+/eve0Gpz///FMvv/yy/P395eHhoXr16iksLEyZmZnWNufPn9dbb72lxo0by9PTU7feequeeOIJ7du3T5KUkpIii8WilJQUm3UfPHhQFotFc+fOtU4bPHiwvLy8tG/fPj3yyCOqUqWKBgwYIElas2aN+vTpo/r168vDw0N+fn56+eWXde7cuUJ179y5U08++aRq1qypihUrqkmTJho1apQkafXq1bJYLFq8eHGh5ebPny+LxaJ169YVeXsCKD0VHF0AgPInISFBTzzxhNzd3dWvXz/NnDlTGzduVNu2bSVJZ86cUceOHZWenq4hQ4aoVatWyszM1NKlS/Xrr7/Kx8dHeXl5evTRR5WcnKynnnpKUVFRysrK0sqVK/Xzzz+rYcOGRa7r4sWLCg0N1b333qv3339flSpVkiR9+eWXOnv2rIYNG6YaNWooNTVVU6dO1a+//qovv/zSuvxPP/2kjh07ys3NTc8884z8/f21b98+/fvf/9a4cePUqVMn+fn5KSEhQY8//nihbdKwYUMFBwffwJYFUOIMAChFmzZtMiQZK1euNAzDMPLz84169eoZUVFR1jZjxowxJBmLFi0qtHx+fr5hGIYRHx9vSDImTZp0xTarV682JBmrV6+2mX/gwAFDkvHJJ59Ypw0aNMiQZIwYMaLQ+s6ePVtoWmxsrGGxWIxDhw5Zp913331GlSpVbKZdXo9hGMbIkSMNDw8P488//7ROO3HihFGhQgUjJiam0OMAcC4cqgNQqhISEuTr66sHHnhAkmSxWNS3b18lJiYqLy9PkrRw4UIFBgYW2itT0L6gjY+Pj1544YUrtrkew4YNKzStYsWK1r+zs7OVmZmp9u3byzAMbd26VZJ08uRJff/99xoyZIjq169/xXrCwsKUk5OjBQsWWKclJSXp4sWLGjhw4HXXDaB0EJwAlJq8vDwlJibqgQce0IEDB7R3717t3btXQUFBOn78uJKTkyVJ+/bt05133nnVde3bt09NmjRRhQrFd8ZBhQoVVK9evULTDx8+rMGDB+uWW26Rl5eXatasqfvvv1+SdOrUKUnS/v37JemadTdt2lRt27a1Oa8rISFB99xzD1cWAmUA5zgBKDX/+c9/dOzYMSUmJioxMbHQ/ISEBD388MPF9nhX2vNUsGfrrzw8POTi4lKobefOnfX777/r9ddfV9OmTVW5cmUdPXpUgwcPVn5+fpHrCgsLU1RUlH799Vfl5ORo/fr1mjZtWpHXA6D0EZwAlJqEhATVqlVL06dPLzRv0aJFWrx4seLi4tSwYUP9/PPPV11Xw4YNtWHDBl24cEFubm5221SvXl3SpSv0Lnfo0CHTNW/fvl27d+/WvHnzFBYWZp2+cuVKm3YNGjSQpGvWLUlPPfWUoqOj9fnnn+vcuXNyc3NT3759TdcEwHE4VAegVJw7d06LFi3So48+qt69exe6RUZGKisrS0uXLlWvXr20bds2u5ftG/9/zN5evXopMzPT7p6agja33XabXF1d9f3339vMnzFjhum6XV1dbdZZ8PeUKVNs2tWsWVP33Xef4uPjdfjwYbv1FPDx8VHXrl312WefKSEhQV26dJGPj4/pmgA4DnucAJSKpUuXKisrS4899pjd+ffcc491MMz58+drwYIF6tOnj4YMGaLWrVvr999/19KlSxUXF6fAwECFhYXp008/VXR0tFJTU9WxY0dlZ2dr1apVev7559WjRw95e3urT58+mjp1qiwWixo2bKivv/5aJ06cMF1306ZN1bBhQ/3973/X0aNHVbVqVS1cuFB//PFHobYffvih7r33XrVq1UrPPPOMbr/9dh08eFDffPON0tLSbNqGhYWpd+/ekqR33nnH/IYE4FiOvKQPQPnRvXt3w9PT08jOzr5im8GDBxtubm5GZmam8d///teIjIw06tata7i7uxv16tUzBg0aZGRmZlrbnz171hg1apRx++23G25ubkbt2rWN3r17G/v27bO2OXnypNGrVy+jUqVKRvXq1Y1nn33W+Pnnn+0OR1C5cmW7de3YscMICQkxvLy8DB8fHyMiIsLYtm1boXUYhmH8/PPPxuOPP25Uq1bN8PT0NJo0aWK8+eabhdaZk5NjVK9e3fD29jbOnTtncisCcDR+qw4AHODixYuqU6eOunfvrjlz5ji6HAAmcY4TADjAkiVLdPLkSZsTzgE4P/Y4AUAp2rBhg3766Se988478vHx0ZYtWxxdEoAiYI8TAJSimTNnatiwYapVq5Y+/fRTR5cDoIjY4wQAAGASe5wAAABMIjgBAACYVO4GwMzPz9dvv/2mKlWq3NAvqAMAgJuDYRjKyspSnTp1Cv1e5V+Vu+D022+/yc/Pz9FlAAAAJ3PkyBHVq1fvqm3KXXCqUqWKpEsbp2rVqg6uBgAAONrp06fl5+dnzQhXU+6CU8HhuapVqxKcAADl0vTp0/Xee+8pIyNDgYGBmjp1qtq1a2e37YULFxQbG6t58+bp6NGjatKkiSZOnKguXbpY28ycOVMzZ87UwYMHJUnNmzfXmDFj1LVr19LoTrExcwoPJ4cDAFCOJCUlKTo6WjExMdqyZYsCAwMVGhp6xR+/Hj16tGbNmqWpU6dqx44deu655/T4449r69at1jb16tXThAkTtHnzZm3atEkPPvigevTooV9++aW0ulVqyt04TqdPn5a3t7dOnTrFHicAQLkTFBSktm3batq0aZIuXTTl5+enF154QSNGjCjUvk6dOho1apSGDx9undarVy9VrFhRn3322RUf55ZbbtF7772noUOHFn8nillRsgF7nAAAKCdyc3O1efNmhYSEWKe5uLgoJCRE69ats7tMTk6OPD09baZVrFhRP/zwg932eXl5SkxMVHZ2toKDg4uveCdBcAIAoJzIzMxUXl6efH19bab7+voqIyPD7jKhoaGaNGmS9uzZo/z8fK1cuVKLFi3SsWPHbNpt375dXl5e8vDw0HPPPafFixerWbNmJdYXRyE4AQCAK5oyZYoaNWqkpk2byt3dXZGRkQoPDy803lGTJk2UlpamDRs2aNiwYRo0aJB27NjhoKpLDsEJAIBywsfHR66urjp+/LjN9OPHj6t27dp2l6lZs6aWLFmi7OxsHTp0SDt37pSXl5caNGhg087d3V0BAQFq3bq1YmNjFRgYqClTppRYXxyF4AQAQDnh7u6u1q1bKzk52TotPz9fycnJ1zwfydPTU3Xr1tXFixe1cOFC9ejR46rt8/PzlZOTUyx1O5NyN44TAADlWXR0tAYNGqQ2bdqoXbt2mjx5srKzsxUeHi5JCgsLU926dRUbGytJ2rBhg44ePaqWLVvq6NGjeuutt5Sfn6/XXnvNus6RI0eqa9euql+/vrKysjR//nylpKRoxYoVDuljSSI4AQBQjvTt21cnT57UmDFjlJGRoZYtW2r58uXWE8YPHz5sc/7S+fPnNXr0aO3fv19eXl565JFH9K9//UvVqlWztjlx4oTCwsJ07NgxeXt7q0WLFlqxYoU6d+5c2t0rcYzjBAAAyjXGcQIAACgBBCcAAACTOMcJAABn990mR1fgePe3cXQFktjjBAAAYBrBCQAAwCSCEwAAgEkEJwAAAJMITgAAACYRnAAAAEwiOAEAAJhEcAIAADCJ4AQAAGASwQkAAMAkghMAAIBJBCcAAACTCE4AAAAmEZwAAABMIjgBQCmaPn26/P395enpqaCgIKWmpl61/eTJk9WkSRNVrFhRfn5+evnll3X+/Hm7bSdMmCCLxaKXXnqpBCoHIBGcAKDUJCUlKTo6WjExMdqyZYsCAwMVGhqqEydO2G0/f/58jRgxQjExMUpPT9ecOXOUlJSkN954o1DbjRs3atasWWrRokVJdwMo1whOZUBxf0OdOXOmWrRooapVq6pq1aoKDg7W//3f/5V0N4Byb9KkSYqIiFB4eLiaNWumuLg4VapUSfHx8Xbbr127Vh06dFD//v3l7++vhx9+WP369Sv0HnDmzBkNGDBAs2fPVvXq1UujKw7FeyIcieDk5EriG2q9evU0YcIEbd68WZs2bdKDDz6oHj166JdffimtbqEM4sPqxuTm5mrz5s0KCQmxTnNxcVFISIjWrVtnd5n27dtr8+bN1m29f/9+LVu2TI888ohNu+HDh6tbt242675Z8Z4IR6vg6AJwdZd/Q5WkuLg4ffPNN4qPj9eIESMKtb/8G6ok+fv7q1+/ftqwYYO1Tffu3W2WGTdunGbOnKn169erefPmJdgblFUFH1ZxcXEKCgrS5MmTFRoaql27dqlWrVqF2hd8WMXHx6t9+/bavXu3Bg8eLIvFokmTJkn634dVo0aNZBiG5s2bpx49emjr1q035fMwMzNTeXl58vX1tZnu6+urnTt32l2mf//+yszM1L333ivDMHTx4kU999xzNh/6iYmJ2rJlizZu3Fii9TsL3hPhaOxxcmIl+Q21QF5enhITE5Wdna3g4ODi7wRuCiVxiKl79+565JFH1KhRIzVu3Fjjxo2Tl5eX1q9fX1rdcnopKSkaP368ZsyYoS1btmjRokX65ptv9M4770iSjhw5oqioKCUkJMjT09PB1ZY83hPhDNjj5MRK6huqJG3fvl3BwcE6f/68vLy8tHjxYjVr1qzE+oKyq+DDauTIkdZpZj6sPvvsM6Wmpqpdu3bWD6unn37abvu8vDx9+eWXN/WHlY+Pj1xdXXX8+HGb6cePH1ft2rXtLvPmm2/q6aef1t/+9jdJ0l133aXs7Gw988wzGjVqlDZv3qwTJ06oVatW1mXy8vL0/fffa9q0acrJyZGrq2vJdaqU8Z4IZ8Aep5vMtb6hFmjSpInS0tK0YcMGDRs2TIMGDdKOHTscVDWc2dU+rDIyMuwu079/f40dO1b33nuv3Nzc1LBhQ3Xq1Mnuh5WXl5c8PDz03HPP3dQfVu7u7mrdurWSk5Ot0/Lz85WcnHzFsHj27Fm5uNi+TRcEIcMw9NBDD2n79u1KS0uz3tq0aaMBAwYoLS3tpgpN14v3RBQ39jg5sZL4hlrwJuzu7q6AgABJUuvWrbVx40ZNmTJFs2bNKsEeoby4/MMqKChIe/fuVVRUlN555x29+eab1nYFH1anTp3SggULNGjQIH333Xc3bXiKjo7WoEGD1KZNG7Vr106TJ09Wdna29XydsLAw1a1bV7GxsZIuHc6cNGmS7r77but2fPPNN9W9e3e5urqqSpUquvPOO20eo3LlyqpRo0ah6TcD3hPhDAhOTuzyb6g9e/aU9L9vqJGRkXaXudY31CvJz89XTk5O8RSOmwofVsWnb9++OnnypMaMGaOMjAy1bNlSy5cvt+7NO3z4sM3rd/To0bJYLBo9erSOHj2qmjVrqnv37ho3bpyjuuBQvCfCGXCozslFR0dr9uzZmjdvntLT0zVs2LBC31AvP/eke/fumjlzphITE3XgwAGtXLnS5huqJI0cOVLff/+9Dh48qO3bt2vkyJFKSUnRgAEDHNLH0lDcl9J///336t69u+rUqSOLxaIlS5aUcA8cpyQOMV1JefiwioyM1KFDh5STk6MNGzYoKCjIOi8lJUVz58613q9QoYJiYmK0d+9enTt3TocPH9b06dNVrVq1K64/JSVFkydPLrkOOBjviXA09jg5uZL4hnrixAmFhYXp2LFj8vb2VosWLbRixQp17ty51PtXGkriUvrs7GwFBgZqyJAheuKJJ0q7S6WuuA8xSZc+rLp27ar69esrKytL8+fPV0pKilasWOGwfsL58Z4IR7MYV/v6dxM6ffq0vL29derUKVWtWtXR5aAUBAUFqW3btpo2bZqkS3s1/Pz89MILL9gd9yUyMlLp6ek2e1heeeUVbdiwQT/88EOh9haLRYsXL7YeOrhZTZs2Te+99571w+rDDz+07i3p1KmT/P39rXtLLl68qHHjxulf//pXoQ+rgr0lQ4cOVXJyss2H1euvv86HFWDPd5scXYHj3d+mxFZdlGxAcMJNLTc3V5UqVdKCBQtsgs2gQYP0559/6quvviq0zPz58/X888/r22+/tV5K361bNz399NN2fyOsvASn8upty9uOLsHhYowYR5cAgpPTBCcO1eGmVpLjvgAAyh9ODi8BFgu3sszsuC8AzLJww02DPU64qZXkpfROr6wn2OJSvs5GAFDCysgnAHB9SvNSegDAzY89TrjplcSl9GfOnNHevXutj3HgwAGlpaXplltuUf369Uu/kwCAUkFwwk2vJMZ92bRpkx544AHr/ejoaEmXrta7fABDAMDNxeHDEUyfPt06NkxgYKCmTp2qdu3aXbH95MmTNXPmTB0+fFg+Pj7q3bu3YmNj5enpaerxSmM4Ak4t4bQSp8AT8ZIbfDIyHEFxDEfAc1G6wTdFhiNwmuEIHHqOU8GIzjExMdqyZYsCAwMVGhqqEydO2G1fMKJzTEyM0tPTNWfOHCUlJXGZOAAAKBUODU6TJk1SRESEwsPD1axZM8XFxalSpUqKj4+3237t2rXq0KGD+vfvL39/fz388MPq16/fNX93DAAAoDg47Byn3Nxcbd682ebHGF1cXBQSEqJ169bZXaZ9+/b67LPPlJqaah3RedmyZXr66adLq2yUEsvb7No3YjjeCQDOxmHBqbRGdM7JybH5tfXTp08XTwcAAEC5U6bGcbqeEZ1jY2Pl7e1tvfn5+ZVixQAA4GbisD1OpTWi88iRI62XikuX9jgRngAAwPVw2B6n0hrR2cPDQ1WrVrW5AQAAXA+HDoBZEiM6AwAAlBSHBqeSGNEZAACgpDh85PDSxsjhpeNGn1UMR1AMwxHwRLyEkcNvGCOHFwdGDr9hjBwOAABQthCcAAAATCI4AQAAmERwAgAAMIngBAAAYBLBCQAAwCSCEwAAgEkEJwAAAJMITgAAACYRnAAAAEwiOAEAAJhEcAIAADCJ4AQAAGASwQkAAMAkghMAAIBJBCcAAACTCE4AAAAmEZwAAABMIjgBAACYRHACAAAwieAEAABgEsEJAADAJIITAACASQQnAAAAkwhOAAAAJhGcAAAATCI4AQAAmERwAgAAMIngBAAAYBLBCQAAwCSCEwAAgEkEJwAAAJMITgAAACYRnAAAAEwiOAEAAJhEcAIAADCJ4AQAAGASwQkAAMAkghMAAIBJBCcAAACTCE4AAAAmEZwAAABMIjgBAACYRHACAAAwieAEAABgEsEJAADAJIITAACASQQnAAAAkwhOAAAAJhGcAAAATCI4AQAAmERwAgAAMMnhwWn69Ony9/eXp6engoKClJqaetX2f/75p4YPH65bb71VHh4eaty4sZYtW1ZK1QIAgPKsgiMfPCkpSdHR0YqLi1NQUJAmT56s0NBQ7dq1S7Vq1SrUPjc3V507d1atWrW0YMEC1a1bV4cOHVK1atVKv3gAAFDuODQ4TZo0SREREQoPD5ckxcXF6ZtvvlF8fLxGjBhRqH18fLx+//13rV27Vm5ubpIkf3//0iwZAACUYw47VJebm6vNmzcrJCTkf8W4uCgkJETr1q2zu8zSpUsVHBys4cOHy9fXV3feeafGjx+vvLy8Kz5OTk6OTp8+bXMDAAC4Hg4LTpmZmcrLy5Ovr6/NdF9fX2VkZNhdZv/+/VqwYIHy8vK0bNkyvfnmm/rggw/0j3/844qPExsbK29vb+vNz8+vWPsBAADKD4efHF4U+fn5qlWrlj766CO1bt1affv21ahRoxQXF3fFZUaOHKlTp05Zb0eOHCnFigEAwM3EYec4+fj4yNXVVcePH7eZfvz4cdWuXdvuMrfeeqvc3Nzk6upqnXbHHXcoIyNDubm5cnd3L7SMh4eHPDw8ird4AABQLjlsj5O7u7tat26t5ORk67T8/HwlJycrODjY7jIdOnTQ3r17lZ+fb522e/du3XrrrXZDEwAAQHFy6KG66OhozZ49W/PmzVN6erqGDRum7Oxs61V2YWFhGjlypLX9sGHD9PvvvysqKkq7d+/WN998o/Hjx2v48OGO6gIAAChHHDocQd++fXXy5EmNGTNGGRkZatmypZYvX249Yfzw4cNycflftvPz89OKFSv08ssvq0WLFqpbt66ioqL0+uuvO6oLAACgHHFocJKkyMhIRUZG2p2XkpJSaFpwcLDWr19fwlUBAAAUVqauqgMAAHAkghMAAIBJBCcAAACTCE4AAAAmEZwAAABMIjgBAACYRHACAAAwieAEAABgUpGD05EjR/Trr79a76empuqll17SRx99VKyFAQAAOJsiB6f+/ftr9erVkqSMjAx17txZqampGjVqlMaOHVvsBQIAADiLIgenn3/+We3atZMkffHFF7rzzju1du1aJSQkaO7cucVdHwAAgNMocnC6cOGCPDw8JEmrVq3SY489Jklq2rSpjh07VrzVAQAAOJEiB6fmzZsrLi5Oa9as0cqVK9WlSxdJ0m+//aYaNWoUe4EAAADOosjBaeLEiZo1a5Y6deqkfv36KTAwUJK0dOlS6yE8AACAm1GFoi7QqVMnZWZm6vTp06pevbp1+jPPPKNKlSoVa3EAAADO5LrGcTIMQ5s3b9asWbOUlZUlSXJ3dyc4AQCAm1qR9zgdOnRIXbp00eHDh5WTk6POnTurSpUqmjhxonJychQXF1cSdQIAADhckfc4RUVFqU2bNvrjjz9UsWJF6/THH39cycnJxVocAACAMynyHqc1a9Zo7dq1cnd3t5nu7++vo0ePFlthAAAAzqbIe5zy8/OVl5dXaPqvv/6qKlWqFEtRAAAAzqjIwenhhx/W5MmTrfctFovOnDmjmJgYPfLII8VZGwAAgFMp8qG6Dz74QKGhoWrWrJnOnz+v/v37a8+ePfLx8dHnn39eEjUCAAA4hSIHp3r16mnbtm1KTEzUTz/9pDNnzmjo0KEaMGCAzcniAAAAN5siBydJqlChggYOHFjctQAAADi1IgenTz/99Krzw8LCrrsYAAAAZ1bk4BQVFWVz/8KFCzp79qx15HCCEwAAuFkV+aq6P/74w+Z25swZ7dq1S/feey8nhwMAgJvadf1W3V81atRIEyZMKLQ3CgAA4GZSLMFJunTC+G+//VZcqwMAAHA6RT7HaenSpTb3DcPQsWPHNG3aNHXo0KHYCgMAAHA2RQ5OPXv2tLlvsVhUs2ZNPfjgg/rggw+Kqy4AAACnU+TglJ+fXxJ1AAAAOL1iO8cJAADgZmdqj1N0dLTpFU6aNOm6iwEAAHBmpoLT1q1bTa3MYrHcUDEAAADOzFRwWr16dUnXAQAA4PQ4xwkAAMCkIl9VJ0mbNm3SF198ocOHDys3N9dm3qJFi4qlMAAAAGdT5D1OiYmJat++vdLT07V48WJduHBBv/zyi/7zn//I29u7JGoEAABwCkUOTuPHj9c///lP/fvf/5a7u7umTJminTt36sknn1T9+vVLokYAAACnUOTgtG/fPnXr1k2S5O7uruzsbFksFr388sv66KOPir1AAAAAZ1Hk4FS9enVlZWVJkurWrauff/5ZkvTnn3/q7NmzxVsdAACAEzEdnAoC0n333aeVK1dKkvr06aOoqChFRESoX79+euihh0qmSgAAACdg+qq6Fi1aqG3bturZs6f69OkjSRo1apTc3Ny0du1a9erVS6NHjy6xQgEAABzNdHD67rvv9Mknnyg2Nlbjxo1Tr1699Le//U0jRowoyfoAAACchulDdR07dlR8fLyOHTumqVOn6uDBg7r//vvVuHFjTZw4URkZGSVZJwAAgMMV+eTwypUrKzw8XN999512796tPn36aPr06apfv74ee+yxkqgRAADAKdzQT64EBATojTfe0OjRo1WlShV98803xVUXAACA07mun1yRpO+//17x8fFauHChXFxc9OSTT2ro0KHFWRsAAIBTKVJw+u233zR37lzNnTtXe/fuVfv27fXhhx/qySefVOXKlUuqRgAAAKdgOjh17dpVq1atko+Pj8LCwjRkyBA1adKkJGsDAABwKqbPcXJzc9OCBQv066+/auLEicUamqZPny5/f395enoqKChIqampppZLTEyUxWJRz549i60WAACAKzEdnJYuXaoePXrI1dW1WAtISkpSdHS0YmJitGXLFgUGBio0NFQnTpy46nIHDx7U3//+d3Xs2LFY6wEAALiSG7qqrjhMmjRJERERCg8PV7NmzRQXF6dKlSopPj7+isvk5eVpwIABevvtt9WgQYNSrBYAAJRnDg1Oubm52rx5s0JCQqzTXFxcFBISonXr1l1xubFjx6pWrVpcxQcAAErVdQ9HUBwyMzOVl5cnX19fm+m+vr7auXOn3WV++OEHzZkzR2lpaaYeIycnRzk5Odb7p0+fvu56AQBA+ebwQ3VFkZWVpaefflqzZ8+Wj4+PqWViY2Pl7e1tvfn5+ZVwlQAA4Gbl0D1OPj4+cnV11fHjx22mHz9+XLVr1y7Uft++fTp48KC6d+9unZafny9JqlChgnbt2qWGDRvaLDNy5EhFR0db758+fZrwBAAArotDg5O7u7tat26t5ORk65AC+fn5Sk5OVmRkZKH2TZs21fbt222mjR49WllZWZoyZYrdQOTh4SEPD48SqR8AAJQvDg1OkhQdHa1BgwapTZs2ateunSZPnqzs7GyFh4dLksLCwlS3bl3FxsbK09NTd955p83y1apVk6RC0wEAAIqbw4NT3759dfLkSY0ZM0YZGRlq2bKlli9fbj1h/PDhw3JxKVOnYgEAgJuUw4OTJEVGRto9NCdJKSkpV1127ty5xV8QAACAHezKAQAAMIngBAAAYBLBCQAAwCSCEwAAgEkEJwAAAJMITgAAACYRnAAAAEwiOAEAAJhEcAIAADCJ4AQAAGASwQkAAMAkghMAAIBJBCcAAACTCE4AAAAmEZwAAABMIjgBAACYRHACAAAwieAEAABgEsEJAADAJIITAACASQQnAAAAkwhOAAAAJhGcAAAATCI4AQAAmERwAgAAMIngBAAAYBLBCQAAwCSCEwAAgEkEJwAAAJMITgAAACYRnAAAAEwiOAEAAJhEcAIAADCJ4AQAAGASwQkAAMAkghMAAIBJBCcAAACTCE4AAAAmEZwAAABMIjgBAACYRHACAAAwieAEAABgEsEJAADAJIITAACASQQnAAAAkwhOAAAAJhGcAAAATCI4AQAAmERwAgAAMIngBAAAYBLBCQAAwCSCEwAAgElOEZymT58uf39/eXp6KigoSKmpqVdsO3v2bHXs2FHVq1dX9erVFRISctX2AAAAxcXhwSkpKUnR0dGKiYnRli1bFBgYqNDQUJ04ccJu+5SUFPXr10+rV6/WunXr5Ofnp4cfflhHjx4t5coBAEB54/DgNGnSJEVERCg8PFzNmjVTXFycKlWqpPj4eLvtExIS9Pzzz6tly5Zq2rSpPv74Y+Xn5ys5ObmUKwcAAOWNQ4NTbm6uNm/erJCQEOs0FxcXhYSEaN26dabWcfbsWV24cEG33HKL3fk5OTk6ffq0zQ0AAOB6ODQ4ZWZmKi8vT76+vjbTfX19lZGRYWodr7/+uurUqWMTvi4XGxsrb29v683Pz++G6wYAAOWTww/V3YgJEyYoMTFRixcvlqenp902I0eO1KlTp6y3I0eOlHKVAADgZlHBkQ/u4+MjV1dXHT9+3Gb68ePHVbt27asu+/7772vChAlatWqVWrRoccV2Hh4e8vDwKJZ6AQBA+ebQPU7u7u5q3bq1zYndBSd6BwcHX3G5d999V++8846WL1+uNm3alEapAAAAjt3jJEnR0dEaNGiQ2rRpo3bt2mny5MnKzs5WeHi4JCksLEx169ZVbGysJGnixIkaM2aM5s+fL39/f+u5UF5eXvLy8nJYPwAAwM3P4cGpb9++OnnypMaMGaOMjAy1bNlSy5cvt54wfvjwYbm4/G/H2MyZM5Wbm6vevXvbrCcmJkZvvfVWaZYOAADKGYcHJ0mKjIxUZGSk3XkpKSk29w8ePFjyBQEAANhRpq+qAwAAKE0EJwAAAJMITgAAACYRnAAAAEwiOAEAAJhEcAIAADCJ4AQAAGASwQkAAMAkghMAAIBJBCcAAACTCE4AAAAmEZwAAABMIjgBAACYRHACAAAwieAEAABgEsEJAADAJIITAACASQQnAAAAkwhOAAAAJhGcAAAATCI4AQAAmERwAgAAMIngBAAAYBLBCQAAwCSCEwAAgEkEJwAAAJMITgAAACYRnAAAAEwiOAEAAJhEcAIAADCJ4AQAAGASwQkAAMAkghMAAIBJBCcAAACTCE4AAAAmEZwAAABMIjgBAACYRHACAAAwieAEAABgEsEJAADAJIITAACASQQnAAAAkwhOAAAAJhGcAAAATCI4AQAAmERwAgAAMIngBAAAYBLBCQAAwCSCEwAAgEkEJwAAAJMITgAAACY5RXCaPn26/P395enpqaCgIKWmpl61/ZdffqmmTZvK09NTd911l5YtW1ZKlQIAgPLM4cEpKSlJ0dHRiomJ0ZYtWxQYGKjQ0FCdOHHCbvu1a9eqX79+Gjp0qLZu3aqePXuqZ8+e+vnnn0u5cgAAUN44PDhNmjRJERERCg8PV7NmzRQXF6dKlSopPj7ebvspU6aoS5cuevXVV3XHHXfonXfeUatWrTRt2rRSrhwAAJQ3Dg1Oubm52rx5s0JCQqzTXFxcFBISonXr1tldZt26dTbtJSk0NPSK7QEAAIpLBUc+eGZmpvLy8uTr62sz3dfXVzt37rS7TEZGht32GRkZdtvn5OQoJyfHev/UqVOSpNOnT99I6biGG96854uljDKN52gxucHteJ4nI8/FYnGD2zD7TPGUUZaV4POw4DluGMY12zo0OJWG2NhYvf3224Wm+/n5OaCa8sPb29EVlH3eE9iIxYIn4w2b4D3B0SXcBHgelgVZWVnyvsZ7hkODk4+Pj1xdXXX8+HGb6cePH1ft2rXtLlO7du0itR85cqSio6Ot9/Pz8/X777+rRo0aslgsN9gD53P69Gn5+fnpyJEjqlq1qqPLKbPYjjeObXjj2IbFg+144272bWgYhrKyslSnTp1rtnVocHJ3d1fr1q2VnJysnj17SroUbJKTkxUZGWl3meDgYCUnJ+ull16yTlu5cqWCg4Pttvfw8JCHh4fNtGrVqhVH+U6tatWqN+WTu7SxHW8c2/DGsQ2LB9vxxt3M2/Bae5oKOPxQXXR0tAYNGqQ2bdqoXbt2mjx5srKzsxUeHi5JCgsLU926dRUbGytJioqK0v33368PPvhA3bp1U2JiojZt2qSPPvrIkd0AAADlgMODU9++fXXy5EmNGTNGGRkZatmypZYvX249Afzw4cNycfnfxX/t27fX/PnzNXr0aL3xxhtq1KiRlixZojvvvNNRXQAAAOWEw4OTJEVGRl7x0FxKSkqhaX369FGfPn1KuKqyycPDQzExMYUOT6Jo2I43jm1449iGxYPteOPYhv9jMcxcewcAAADHjxwOAABQVhCcAAAATCI4odzr1KmTzfAWAJzbwYMHZbFYlJaW5uhSUA4RnMqAjIwMRUVFKSAgQJ6envL19VWHDh00c+ZMnT171tpu69at6tOnj3x9feXp6alGjRopIiJCu3fvlvS/N5tatWopKyvL5jFatmypt956qzS7ZWW2f460bds2PfbYY6pVq5Y8PT3l7++vvn376sSJE4XaxsbGytXVVe+9957ddZntr7+/vywWS6HbhAmOHcW5KP8ve9viSv0quA0ePLiUe3T9nO212alTJ7vb9OLFizbzExMTbZabPHmy/P39r39DFLPBgwfb1F+jRg116dJFP/30k6RLv/xw7NixQldTL1y4UA8++KCqV6+uihUrqkmTJhoyZIi2bt1q0y43N1fvvvuuAgMDValSJfn4+KhDhw765JNPdOHCBZsa/vp6W7JkidMOnjx48GDrmIiXS0lJkcVi0Z9//inp0mCPs2fPVnBwsKpWrSovLy81b95cUVFR2rt3r3W5t956y+7zadWqVTbzn3vuOZvHS0tLk8Vi0cGDByX97/ldcKtSpYqaN2+u4cOHa8+ePSWyLUoSwcnJ7d+/X3fffbe+/fZbjR8/Xlu3btW6dev02muv6euvv7Y+gb/++mvdc889ysnJUUJCgtLT0/XZZ5/J29tbb775ps06s7Ky9P777zuiO4WY7d9fFby5lYaTJ0/qoYce0i233KIVK1YoPT1dn3zyierUqaPs7OxC7ePj4/Xaa68pPj6+0Lyi9nfs2LE6duyYze2FF14osb5eS1Hrt7ctNm7caO3LwoULJUm7du2yTpsyZUqp9ul6OetrMyIiotBzpkKF/11A7enpqdGjR5fqa+h6dOnSxVp/cnKyKlSooEcffVSS5Orqqtq1a9v06/XXX1ffvn3VsmVLLV26VLt27dL8+fPVoEEDjRw50touNzdXoaGhmjBhgp555hmtXbtWqampGj58uKZOnapffvnF2tbT01MTJ07UH3/8UXodL2GGYah///568cUX9cgjj+jbb7/Vjh07NGfOHHl6euof//iHTfvmzZsXej7dd9991vmenp6aM2eOqQC0atUqHTt2TNu2bdP48eOVnp6uwMBAJScnF3s/S5QBpxYaGmrUq1fPOHPmjN35+fn5RnZ2tuHj42P07NnTbps//vjDMAzDOHDggCHJePXVVw0vLy/j+PHj1jaBgYFGTExMcZd/TWb6ZxiGIcmYMWOG0b17d6NSpUpGTEyMcfHiRWPIkCGGv7+/4enpaTRu3NiYPHmyzfKDBg0yevToYbz11luGj4+PUaVKFePZZ581cnJyrG3uv/9+44UXXjBeffVVo3r16oavr6/Ntli8eLFRoUIF48KFC9fsT0pKilG3bl0jNzfXqFOnjvHjjz9eV38NwzBuu+0245///Oc1H7M0FaX+a20LwzCM1atXG5Ksz9GyxBlfm/fff78RFRV11fnh4eFGjRo1jOnTp1un//Of/zRuu+02U49RGgpet5dbs2aNIck4ceKEdXtt3brVMAzDWLdunSHJmDJlit31Xf68nDhxouHi4mJs2bKlULvc3Fzr/3PQoEHGo48+ajRt2tR49dVXrW0WL15sOOtHp73tZhi2r7PPP//ckGR89dVXdtdx+baKiYkxAgMDr/h4BfM7d+5s9OnTxzp969athiTjwIEDhmEYhf5fBfLy8oxOnToZt912m3Hx4kXT/XQ09jg5sf/+97/69ttvNXz4cFWuXNluG4vFohUrVigzM1Ovvfaa3TZ//YmZfv36KSAgQGPHji3ukovEbP8KvPXWW3r88ce1fft2DRkyRPn5+apXr56+/PJL7dixQ2PGjNEbb7yhL774wmYdycnJSk9PV0pKij7//HMtWrSo0A8/z5s3T5UrV9aGDRv07rvvauzYsVq5cqWkS7+PePHiRS1evPiav5w9Z84c9evXT25uburXr5/mzJlz3f11NkWt/2rboqwry6/NqlWratSoURo7dqzdPabO6MyZM/rss88UEBCgGjVqFJr/+eefy8vLS88//7zd5S9/XiYkJCgkJER33313oXZubm42/09XV1eNHz9eU6dO1a+//loMPXG8zz//XE2aNNFjjz1md/71vAdNmDBBCxcu1KZNm4q0nIuLi6KionTo0CFt3ry5yI/rKAQnJ7Z3714ZhqEmTZrYTPfx8ZGXl5e8vLz0+uuvW3eRNm3a1NR6C47bf/TRR9q3b1+x122W2f4V6N+/v8LDw9WgQQPVr19fbm5uevvtt9WmTRvdfvvtGjBggMLDwwsFJ3d3d8XHx6t58+bq1q2bxo4dqw8//FD5+fnWNi1atFBMTIwaNWqksLAwtWnTxrr7+J577tEbb7yh/v37y8fHR127dtV7771X6MemT58+rQULFmjgwIGSpIEDB+qLL77QmTNnrqu/0qXDDwXzCm5r1qy5ns19w4pS/7W2RVnnzK/NGTNm2DxfXnnllUJtnn/+eXl6emrSpEnX9Ril4euvv7b2oUqVKlq6dKmSkpJsfkmiwO7du9WgQQObQ3eTJk2y2Q6nTp2SJO3Zs8f0/0OSHn/8cbVs2VIxMTE33qlScPl2K7h17drVOn/37t2FnrcvvfSStW29evVs5m3fvt1mXe3atSv0mK1atdKTTz5Z6P3LjIL/RcH5UGUBwakMSk1NVVpampo3b66cnJxr7gWxJzQ0VPfee2+hcyycwV/7V6BNmzaF2k6fPl2tW7dWzZo15eXlpY8++kiHDx+2aVNwAmiB4OBgnTlzRkeOHLFOa9Gihc0yt956q82J3+PGjVNGRobi4uLUvHlzxcXFqWnTptq+fbu1zeeff66GDRsqMDBQ0qWTem+77TYlJSVdV38l6dVXX1VaWprNzd52cCR79V/vtijrnOG1OWDAAJvny+Xn9xTw8PDQ2LFj9f777yszM/O6HqekPfDAA9Y+pKamKjQ0VF27dtWhQ4dMLT9kyBClpaVp1qxZys7Otv4vrud/MnHiRM2bN0/p6elFXra0Xb7dCm4ff/zxVZcZNWqU0tLSNGbMmEJfbpo0aWKzroLzEv/qH//4h9asWaNvv/22SPUW/D+ceW/7XxGcnFhAQIAsFot27dplM71BgwYKCAhQxYoVJUmNGzeWJO3cubNI658wYYKSkpIKXXFSWsz2r8BfD4kkJibq73//u4YOHapvv/1WaWlpCg8PV25ubpFrcXNzs7lvsVhs9khJUo0aNdSnTx+9//77Sk9PV506dWxO5J0zZ45++eUXVahQwXrbsWOH9cToovZXurQHIyAgwOZmr11pKEr919oWZZ0zvza9vb1tni8+Pj522w0cOFC33XZboZOBnUXlypWtfWjbtq0+/vhjZWdna/bs2YXaNmrUSPv377c54b1atWoKCAhQ3bp1bdo2bty4yP+P++67T6GhoXZDqLO5fLsV3C7fBo0aNSr0vK1Zs6YCAgJUq1atQutzd3e3WZefn5/dx23YsKEiIiI0YsSIIoXTgjB6++23m17G0QhOTqxGjRrq3Lmzpk2bdtVzER5++GH5+Pjo3XfftTu/4BLUv2rXrp2eeOIJjRgxojjKLTKz/buSH3/8Ue3bt9fzzz+vu+++WwEBAXYPb2zbtk3nzp2z3l+/fr28vLyu+AZghru7uxo2bGite/v27dq0aZNSUlJsvp2lpKRo3bp12rlz5w3319HM1m9mW5R1N8Nr08XFRbGxsZo5c2aZOExisVjk4uJi81ou0K9fP505c0YzZsy45nr69++vVatW2Q2lFy5cuOL/c8KECfr3v/+tdevWFb14J9KvXz/t2rVLX331VbGve8yYMdq9e3eh4S6uJD8/Xx9++KFuv/12u+ecOSuCk5ObMWOGLl68qDZt2igpKUnp6enatWuXPvvsM+3cuVOurq6qXLmyPv74Y33zzTd67LHHtGrVKh08eFCbNm3Sa6+9VmiMjcuNGzdO//nPfwp9AyktZvp3JY0aNdKmTZu0YsUK7d69W2+++aY2btxYqF1ubq6GDh2qHTt2aNmyZYqJiVFkZKTdcyXs+frrrzVw4EB9/fXX2r17t3bt2qX3339fy5YtU48ePSRd2sPSrl073Xfffbrzzjutt/vuu09t27a1nhhd1P5mZWUpIyPD5nb69Gmzm7fYmanf7LYo626G12a3bt0UFBSkWbNmldhjXK+cnBzrcz49PV0vvPCCzpw5o+7duxdqGxwcrFdeeUWvvPKKoqOj9cMPP+jQoUNav3695syZYw1d0qXzeTp06KCHHnpI06dP17Zt27R//3598cUXuueee654Wf1dd92lAQMG6MMPPyzRfpe0p556Sr1799ZTTz2lsWPHasOGDTp48KC+++47JSUlXfU991p8fX0VHR19xW303//+VxkZGdq/f7+WLl2qkJAQpaamas6cOTf0uKXOMRfzoSh+++03IzIy0rj99tsNNzc3w8vLy2jXrp3x3nvvGdnZ2dZ2GzduNJ544gmjZs2ahoeHhxEQEGA888wzxp49ewzDuPIloc8884whySHDERiGuf5JMhYvXmyz3Pnz543Bgwcb3t7eRrVq1Yxhw4YZI0aMsLl8tuDy3DFjxhg1atQwvLy8jIiICOP8+fPWNvYu4e7Ro4cxaNAgwzAMY9++fUZERITRuHFjo2LFika1atWMtm3bGp988olhGIaRk5Nj1KhRw3j33Xft9m/ixIlGrVq1jNzcXNP9NYxLwxFIKnR79tlnr2MrF5+r1X/q1KkibYuyPByBYTjfa9PMcAR/nb927VpDktMNR3D5c75KlSpG27ZtjQULFhiGceXtlZSUZHTq1Mnw9vY23NzcjHr16hn9+/c31q9fb9Pu/PnzRmxsrHHXXXcZnp6exi233GJ06NDBmDt3rnXYEXuX9h84cMBwd3cv08MRGMalYQDi4uKMoKAgo3Llyoa7u7vRoEEDIyIiwtixY4d1ObPDEVzu1KlTho+Pj93hCApulSpVMu644w7j+eeft74GyhKLYVzHmXJAGTF48GD9+eefWrJkiaNLAQDcBDhUBwAAYBLBCQDKgDVr1hQan+fyG4DSwaE6ACgDzp07p6NHj15xfkBAQClWA5RfBCcAAACTOFQHAABgEsEJAADAJIITAACASQQnAAAAkwhOAHCZlJQUWSyWK/6OnD3+/v6aPHlyidUEwHkQnACUKYMHD5bFYrH7O2/Dhw+XxWLR4MGDS78wAOUCwQlAmePn56fExESdO3fOOu38+fOaP3++6tev78DKANzsCE4AypxWrVrJz89PixYtsk5btGiR6tevr7vvvts6LScnRy+++KJq1aolT09P3Xvvvdq4caPNupYtW6bGjRurYsWKeuCBB3Tw4MFCj/fDDz+oY8eOqlixovz8/PTiiy8qOzu7xPoHwHkRnACUSUOGDNEnn3xivR8fH6/w8HCbNq+99poWLlyoefPmacuWLQoICFBoaKh+//13SdKRI0f0xBNPqHv37kpLS9Pf/vY3jRgxwmYd+/btU5cuXdSrVy/99NNPSkpK0g8//KDIyMiS7yQAp0NwAlAmDRw4UD/88IMOHTqkQ4cO6ccff9TAgQOt87OzszVz5ky999576tq1q5o1a6bZs2erYsWKmjNnjiRp5syZatiwoT744AM1adJEAwYMKHR+VGxsrAYMGKCXXnpJjRo1Uvv27fXhhx/q008/1fnz50uzywCcQAVHFwAA16NmzZrq1q2b5s6dK8Mw1K1bN/n4+Fjn79u3TxcuXFCHDh2s09zc3NSuXTulp6dLktLT0xUUFGSz3uDgYJv727Zt008//aSEhATrNMMwlJ+frwMHDuiOO+4oie4BcFIEJwBl1pAhQ6yHzKZPn14ij3HmzBk9++yzevHFFwvN40R0oPwhOAEos7p06aLc3FxZLBaFhobazGvYsKHc3d31448/6rbbbpMkXbhwQRs3btRLL70kSbrjjju0dOlSm+XWr19vc79Vq1basWOHAgICSq4jAMoMznECUGa5uroqPT1dO3bskKurq828ypUra9iwYXr11Ve1fPly7dixQxERETp79qyGDh0qSXruuee0Z88evfrqq9q1a5fmz5+vuXPn2qzn9ddf19q1axUZGam0tDTt2bNHX331FSeHA+UUwQlAmVa1alVVrVrV7rwJEyaoV69eevrpp9WqVSvt3btXK1asUPXq1SVdOtS2cOFCLVmyRIGBgYqLi9P48eNt1tGiRQt999132r17tzp27Ki7775bY8aMUZ06dUq8bwCcj8UwDMPRRQAAAJQF7HECAAAwieAEAABgEsEJAADAJIITAACASQQnAAAAkwhOAAAAJhGcAAAATCI4AQAAmERwAgAAMIngBAAAYBLBCQAAwCSCEwAAgEn/D3U7oASoFaYUAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dữ liệu\n",
        "categories = ['GCN', 'GraphSAGE','GAT', 'GCN_FN', 'BiGCN', 'HGFND']\n",
        "values = [f1_GCN, f1_GraphSAGE, f1_GAT, f1_GCN_FN, f1_BiGCN, f1_HGFND]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.bar(categories, values, color=['blue', 'green', 'red','purple', 'yellow','pink'])\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Values')\n",
        "plt.title('F1 Score')\n",
        "\n",
        "# Hiển thị giá trị trên cột\n",
        "for i in range(len(categories)):\n",
        "     plt.text(i, values[i], '{:.2f}'.format(values[i]), ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FF70l6dsRiew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fac3dc61-3cc9-4454-88cd-b238e8541d9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAGGCAYAAACNCg6xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA5nUlEQVR4nO3deXxNZ+LH8W8SWRAJFaIIKbEUFbUktda00VCjdDpqrBEmpkirk46WWqJaYqtBqahKmUGlQ7WmjC3TKLUvUSX2WooEv7ZCVEJyfn945Y7bXJyQ5N4kn/frdV6v3HOec87znNzle895znOdDMMwBAAAgPtytncFAAAAigqCEwAAgEkEJwAAAJMITgAAACYRnAAAAEwiOAEAAJhEcAIAADCJ4AQAAGASwQkAAMAkghMAAIBJBCcAhW7hwoVycnKyOY0YMcJSbv369Ro4cKAaNWokFxcX+fv752k/165dU3R0tBo1aqSyZcuqYsWKatKkiYYNG6bz58/nc6sAlASl7F0BACXX+PHj9dhjj1nNa9SokeXvpUuXKj4+Xk2bNlXVqlXztO2bN2+qXbt2Onz4sMLCwvTqq6/q2rVrOnjwoJYuXaoXX3wxz9sEAIITALvp1KmTmjdvftflEydO1Pz58+Xq6qrf//73+v77701v+4svvtC+ffu0ZMkS9erVy2rZjRs3lJmZ+cD1zqv09HSVLVu20PYHoOBwqQ6Aw6patapcXV0faN0TJ05Iklq3bp1rmYeHh7y8vKzmHT58WC+//LIqVaqk0qVLq169eho1apRVmX379qlTp07y8vKSp6ennn32WW3fvt2qTM5lyE2bNmnIkCGqXLmyqlevbln+n//8R23btlXZsmVVrlw5de7cWQcPHnygNgIofJxxAmA3V65c0eXLl63m+fj45Mu2a9asKUn6xz/+odGjR8vJyemuZb/77ju1bdtWrq6uGjRokPz9/XXixAn9+9//1oQJEyRJBw8eVNu2beXl5aU333xTrq6umjdvntq3b69NmzYpODjYaptDhgxRpUqVNHbsWKWnp0uS/vnPfyosLEyhoaGaPHmyrl+/rrlz56pNmzbat29fnvtwAbADAwAK2SeffGJIsjndTefOnY2aNWua3sf169eNevXqGZKMmjVrGv379zcWLFhgpKam5irbrl07o1y5csbp06et5mdnZ1v+7tatm+Hm5macOHHCMu/8+fNGuXLljHbt2uVqW5s2bYxbt25Z5l+9etUoX768ERERYbWPlJQUw9vbO9d8AI6JM04A7GbOnDmqW7dugWy7dOnS2rFjhyZMmKDPPvtMCxcu1MKFC+Xs7KwhQ4Zo2rRpcnd316VLl/TNN99o2LBhqlGjhtU2cs5SZWVlaf369erWrZtq1aplWf7oo4+qV69emj9/vtLS0qwu/0VERMjFxcXyeMOGDfrll1/Us2dPq7NsLi4uCg4O1tdff10gxwFA/iI4AbCboKCge3YOf1je3t6aMmWKpkyZotOnTyshIUHTpk3T7Nmz5e3trffee08nT56UZH03329dunRJ169fV7169XIte/zxx5Wdna2zZ8+qYcOGlvm/vVvw2LFjkqRnnnnG5j5+2+cKgGMiOAEoEWrWrKkBAwboxRdfVK1atbRkyRK99957Bba/0qVLWz3Ozs6WdLufU5UqVXKVL1WKt2OgKOCVCqBEqVChgmrXrm0Z2iDn0tu9hjqoVKmSypQpoyNHjuRadvjwYTk7O8vPz++e+61du7YkqXLlygoJCXnQ6gOwM4YjAFAs7d+/P9cde5J0+vRpHTp0yHLZrVKlSmrXrp3i4uJ05swZq7KGYUi63Q/pueee05dffqlTp05Zlqempmrp0qVq06bNfS+1hYaGysvLSxMnTtTNmzdzLb906VJemwjADjjjBMBhfffdd1q1apUk6fjx47py5Yrl8lpgYKC6dOly13U3bNig6OhovfDCC3rqqafk6empkydPKi4uThkZGRo3bpyl7KxZs9SmTRs1bdpUgwYN0mOPPaZTp05p9erVSkpKkiS999572rBhg9q0aaMhQ4aoVKlSmjdvnjIyMjRlypT7tsXLy0tz585V37591bRpU/3pT39SpUqVdObMGa1evVqtW7fW7NmzH/xgASgUBCcADmvv3r0aM2aM1bycx2FhYfcMTi+99JKuXr2q9evX67///a9++uknVahQQUFBQXrjjTf0u9/9zlI2MDBQ27dv15gxYzR37lzduHFDNWvW1Msvv2wp07BhQ23evFkjR45UTEyMsrOzFRwcrMWLF+caw+luevXqpapVq2rSpEmaOnWqMjIyVK1aNbVt21bh4eF5OTQA7MTJyDkXDQAAgHuijxMAAIBJBCcAAACTCE4AAAAmEZwAAABMIjgBAACYRHACAAAwqcSN45Sdna3z58+rXLlyll8+BwAAJZdhGLp69aqqVq0qZ+d7n1MqccHp/Pnz9/1NKQAAUPKcPXtW1atXv2eZEhecypUrJ+n2wbnfb0sBAIDiLy0tTX5+fpaMcC8lLjjlXJ7z8vIiOAEASqQ5c+Zo6tSpSklJUWBgoD744AMFBQXZLHvz5k3FxMRo0aJFOnfunOrVq6fJkyerY8eOljJz587V3LlzLT+C3bBhQ40dO1adOnUqjObkGzNdeOgcDgBACRIfH6+oqChFR0dr7969CgwMVGhoqC5evGiz/OjRozVv3jx98MEHOnTokF555RW9+OKL2rdvn6VM9erVNWnSJO3Zs0e7d+/WM888o65du+rgwYOF1axCU+J+qy4tLU3e3t66cuUKZ5wAACVOcHCwWrRoodmzZ0u6fdOUn5+fXn31VY0YMSJX+apVq2rUqFEaOnSoZd5LL72k0qVLa/HixXfdzyOPPKKpU6dq4MCB+d+IfJaXbMAZJwAASojMzEzt2bNHISEhlnnOzs4KCQnRtm3bbK6TkZEhDw8Pq3mlS5fWli1bbJbPysrSsmXLlJ6erpYtW+Zf5R0EwQkAgBLi8uXLysrKkq+vr9V8X19fpaSk2FwnNDRU06dP17Fjx5Sdna0NGzbo888/14ULF6zKHThwQJ6ennJ3d9crr7yilStXqkGDBgXWFnshOAEAgLuaOXOm6tSpo/r168vNzU2RkZEKDw/PNd5RvXr1lJSUpB07dmjw4MEKCwvToUOH7FTrgkNwAgCghPDx8ZGLi4tSU1Ot5qempqpKlSo216lUqZK++OILpaen6/Tp0zp8+LA8PT1Vq1Ytq3Jubm4KCAhQs2bNFBMTo8DAQM2cObPA2mIvBCcAAEoINzc3NWvWTAkJCZZ52dnZSkhIuG9/JA8PD1WrVk23bt3SihUr1LVr13uWz87OVkZGRr7U25GUuHGcAAAoyaKiohQWFqbmzZsrKChIM2bMUHp6usLDwyVJ/fr1U7Vq1RQTEyNJ2rFjh86dO6cmTZro3LlzGjdunLKzs/Xmm29atjly5Eh16tRJNWrU0NWrV7V06VIlJiZq3bp1dmljQSI4AQBQgvTo0UOXLl3S2LFjlZKSoiZNmmjt2rWWDuNnzpyx6r9048YNjR49WidPnpSnp6eef/55/fOf/1T58uUtZS5evKh+/frpwoUL8vb2VuPGjbVu3Tp16NChsJtX4BjHCQAAlGiM4wQAAFAACE4AAAAm0ccJAABHt2m3vWtgf083t3cNJHHGCQAAwDSCEwAAgEkEJwAAAJMITgAAACYRnAAAAEwiOAEAAJhEcAIAADCJ4AQAAGASwQkAAMAkghMAAIBJBCcAAACTCE4AAAAmEZwAAABMIjgBAACYRHACgEI0Z84c+fv7y8PDQ8HBwdq5c+c9y8+YMUP16tVT6dKl5efnp7/+9a+6ceOGzbKTJk2Sk5OTXn/99QKoOQCJ4AQAhSY+Pl5RUVGKjo7W3r17FRgYqNDQUF28eNFm+aVLl2rEiBGKjo5WcnKyFixYoPj4eL399tu5yu7atUvz5s1T48aNC7oZQIlGcCoC8vsb6ty5c9W4cWN5eXnJy8tLLVu21H/+85+CbgZQ4k2fPl0REREKDw9XgwYNFBsbqzJlyiguLs5m+a1bt6p169bq1auX/P399dxzz6lnz5653gOuXbum3r17a/78+apQoUJhNMWueE+EPRGcHFxBfEOtXr26Jk2apD179mj37t165pln1LVrVx08eLCwmoUiiA+rh5OZmak9e/YoJCTEMs/Z2VkhISHatm2bzXVatWqlPXv2WI71yZMntWbNGj3//PNW5YYOHarOnTtbbbu44j0R9lbK3hXAvd35DVWSYmNjtXr1asXFxWnEiBG5yt/5DVWS/P391bNnT+3YscNSpkuXLlbrTJgwQXPnztX27dvVsGHDAmwNiqqcD6vY2FgFBwdrxowZCg0N1ZEjR1S5cuVc5XM+rOLi4tSqVSsdPXpU/fv3l5OTk6ZPny7pfx9WderUkWEYWrRokbp27ap9+/YVy+fh5cuXlZWVJV9fX6v5vr6+Onz4sM11evXqpcuXL6tNmzYyDEO3bt3SK6+8YvWhv2zZMu3du1e7du0q0Po7Ct4TYW+ccXJgBfkNNUdWVpaWLVum9PR0tWzZMv8bgWKhIC4xdenSRc8//7zq1KmjunXrasKECfL09NT27dsLq1kOLzExURMnTtSHH36ovXv36vPPP9fq1av17rvvSpLOnj2rYcOGacmSJfLw8LBzbQse74lwBJxxcmAF9Q1Vkg4cOKCWLVvqxo0b8vT01MqVK9WgQYMCawuKrpwPq5EjR1rmmfmwWrx4sXbu3KmgoCDLh1Xfvn1tls/KytK//vWvYv1h5ePjIxcXF6WmplrNT01NVZUqVWyuM2bMGPXt21d//vOfJUlPPPGE0tPTNWjQII0aNUp79uzRxYsX1bRpU8s6WVlZ+uabbzR79mxlZGTIxcWl4BpVyHhPhCPgjFMxc79vqDnq1aunpKQk7dixQ4MHD1ZYWJgOHTpkp1rDkd3rwyolJcXmOr169dL48ePVpk0bubq6qnbt2mrfvr3NDytPT0+5u7vrlVdeKdYfVm5ubmrWrJkSEhIs87Kzs5WQkHDXsHj9+nU5O1u/TecEIcMw9Oyzz+rAgQNKSkqyTM2bN1fv3r2VlJRUrELTg+I9EfmNM04OrCC+oea8Cbu5uSkgIECS1KxZM+3atUszZ87UvHnzCrBFKCnu/LAKDg7W8ePHNWzYML377rsaM2aMpVzOh9WVK1e0fPlyhYWFadOmTcU2PEVFRSksLEzNmzdXUFCQZsyYofT0dEt/nX79+qlatWqKiYmRdPty5vTp0/Xkk09ajuOYMWPUpUsXubi4qFy5cmrUqJHVPsqWLauKFSvmml8c8J4IR0BwcmB3fkPt1q2bpP99Q42MjLS5zv2+od5Ndna2MjIy8qfiKFb4sMo/PXr00KVLlzR27FilpKSoSZMmWrt2reVs3pkzZ6xev6NHj5aTk5NGjx6tc+fOqVKlSurSpYsmTJhgrybYFe+JcARcqnNwUVFRmj9/vhYtWqTk5GQNHjw41zfUO/uedOnSRXPnztWyZcv0ww8/aMOGDVbfUCVp5MiR+uabb3Tq1CkdOHBAI0eOVGJionr37m2XNhaGghitOa/bLKoK4hLT3ZSED6vIyEidPn1aGRkZ2rFjh4KDgy3LEhMTtXDhQsvjUqVKKTo6WsePH9evv/6qM2fOaM6cOSpfvvxdt5+YmKgZM2YUXAPsjPdE2BtnnBxcQXxDvXjxovr166cLFy7I29tbjRs31rp169ShQ4dCb19hKIhb6fO6zaIuvy8xSbc/rDp16qQaNWro6tWrWrp0qRITE7Vu3Tq7tROOj/dE2JuTca+vf8VQWlqavL29deXKFXl5edm7OigEwcHBatGihWbPni3p9lkNPz8/vfrqqzbHfYmMjFRycrLVGZY33nhDO3bs0JYtWx5om8XB7NmzNXXqVMuH1axZsyxnS9q3by9/f3/L2ZJbt25pwoQJ+uc//5nrwyrnbMnAgQOVkJBg9WH11ltv8WEF2LJpt71rYH9PNy+wTeclGxCcUKxlZmaqTJkyWr58uaVPhCSFhYXpl19+0ZdffplrnaVLl2rIkCFav3695Vb6zp07q2/fvnr77bcfaJsout5xesfeVbC7aCPa3lUAwclhghOX6lCsFcS4Lw+yTQBA8UDn8ALg5MRUlJkd9wWAWU5MKDY444RirSBupX+QbdpFUU+w+aVk9UYAUMA444RirSBupX+QbQIAigfOOKHYK4hb6e+3TQBA8URwQrFXEOO+3G+bAIDiye7DEcyZM8cyNkxgYKA++OADBQUF3bX8jBkzNHfuXJ05c0Y+Pj764x//qJiYGHl4eJjaX2EMR0DXErqVOASeiLc95JOR4QjyYzgCnovSQ74pMhyBwwxHYNc+TjmjL0dHR2vv3r0KDAxUaGioLl68aLN8zojO0dHRSk5O1oIFCxQfH5/rF9cBAAAKgl2D0/Tp0xUREaHw8HA1aNBAsbGxKlOmjOLi4myW37p1q1q3bq1evXrJ399fzz33nHr27FlsfyMMAAA4Frv1ccrMzNSePXusfozR2dlZISEh2rZtm811WrVqpcWLF2vnzp2WEZ3XrFmjvn37Fla1UUic3uHUvhHN9U4AcDR2C04FMaKzLRkZGVa/tp6WlpY/DQAAACVOkRrH6UFGdI6JiZG3t7dl8vPzK8QaAwCA4sRuZ5wKYkTn3w5aKEkjR45UVFSU5XFaWhrhCQAAPBC7nXEqiBGdbXF3d5eXl5fVBAAA8CDsOgBmQYzoDAAAUFDsGpwKYkRnAACAgmL3kcMLGyOHF46HfVYxHEE+DEfAE/E2Rg5/aIwcnh8YOfyhMXI4AABA0UJwAgAAMIngBAAAYBLBCQAAwCSCEwAAgEkEJwAAAJMITgAAACYRnAAAAEwiOAEAAJhEcAIAADCJ4AQAAGASwQkAAMAkghMAAIBJBCcAAACTCE4AAAAmEZwAAABMIjgBAACYRHACAAAwieAEAABgEsEJAADAJIITAACASQQnAAAAkwhOAAAAJhGcAAAATCI4AQAAmERwAgAAMIngBAAAYBLBCQAAwCSCEwAAgEkEJwAAAJMITgAAACYRnAAAAEwiOAEAAJhEcAIAADCJ4AQAAGASwQkAAMAkghMAAIBJBCcAAACTCE4AAAAmEZwAAABMIjgBAACYRHACAAAwieAEAABgEsEJAADAJIITAACASQQnAAAAkwhOAAAAJhGcAAAATCI4AQAAmERwAgAAMIngBAAAYBLBCQAAwCS7B6c5c+bI399fHh4eCg4O1s6dO+9Z/pdfftHQoUP16KOPyt3dXXXr1tWaNWsKqbYAAKAkK2XPncfHxysqKkqxsbEKDg7WjBkzFBoaqiNHjqhy5cq5ymdmZqpDhw6qXLmyli9frmrVqun06dMqX7584VceAACUOHYNTtOnT1dERITCw8MlSbGxsVq9erXi4uI0YsSIXOXj4uL0008/aevWrXJ1dZUk+fv7F2aVAQBACWa3S3WZmZnas2ePQkJC/lcZZ2eFhIRo27ZtNtdZtWqVWrZsqaFDh8rX11eNGjXSxIkTlZWVddf9ZGRkKC0tzWoCAAB4EHYLTpcvX1ZWVpZ8fX2t5vv6+iolJcXmOidPntTy5cuVlZWlNWvWaMyYMXr//ff13nvv3XU/MTEx8vb2tkx+fn752g4AAFBy2L1zeF5kZ2ercuXK+uijj9SsWTP16NFDo0aNUmxs7F3XGTlypK5cuWKZzp49W4g1BgAAxYnd+jj5+PjIxcVFqampVvNTU1NVpUoVm+s8+uijcnV1lYuLi2Xe448/rpSUFGVmZsrNzS3XOu7u7nJ3d8/fygMAgBLJbmec3Nzc1KxZMyUkJFjmZWdnKyEhQS1btrS5TuvWrXX8+HFlZ2db5h09elSPPvqozdAEAACQn+x6qS4qKkrz58/XokWLlJycrMGDBys9Pd1yl12/fv00cuRIS/nBgwfrp59+0rBhw3T06FGtXr1aEydO1NChQ+3VBAAAUILYdTiCHj166NKlSxo7dqxSUlLUpEkTrV271tJh/MyZM3J2/l+28/Pz07p16/TXv/5VjRs3VrVq1TRs2DC99dZb9moCAAAoQewanCQpMjJSkZGRNpclJibmmteyZUtt3769gGsFAACQW5G6qw4AAMCeCE4AAAAmEZwAAABMIjgBAACYRHACAAAwieAEAABgEsEJAADAJIITAACASXkOTmfPntWPP/5oebxz5069/vrr+uijj/K1YgAAAI4mz8GpV69e+vrrryVJKSkp6tChg3bu3KlRo0Zp/Pjx+V5BAAAAR5Hn4PT9998rKChIkvTZZ5+pUaNG2rp1q5YsWaKFCxfmd/0AAAAcRp6D082bN+Xu7i5J2rhxo1544QVJUv369XXhwoX8rR0AAIADyXNwatiwoWJjY7V582Zt2LBBHTt2lCSdP39eFStWzPcKAgAAOIo8B6fJkydr3rx5at++vXr27KnAwEBJ0qpVqyyX8AAAAIqjUnldoX379rp8+bLS0tJUoUIFy/xBgwapTJky+Vo5AAAAR/JA4zgZhqE9e/Zo3rx5unr1qiTJzc2N4AQAAIq1PJ9xOn36tDp27KgzZ84oIyNDHTp0ULly5TR58mRlZGQoNja2IOoJAABgd3k+4zRs2DA1b95cP//8s0qXLm2Z/+KLLyohISFfKwcAAOBI8nzGafPmzdq6davc3Nys5vv7++vcuXP5VjEAAABHk+czTtnZ2crKyso1/8cff1S5cuXypVIAAACOKM/B6bnnntOMGTMsj52cnHTt2jVFR0fr+eefz8+6AQAAOJQ8X6p7//33FRoaqgYNGujGjRvq1auXjh07Jh8fH3366acFUUcAAACHkOfgVL16de3fv1/Lli3Td999p2vXrmngwIHq3bu3VWdxAACA4ibPwUmSSpUqpT59+uR3XQAAABxanoPTP/7xj3su79ev3wNXBgAAwJHlOTgNGzbM6vHNmzd1/fp1y8jhBCcAAFBc5fmuup9//tlqunbtmo4cOaI2bdrQORwAABRrD/Rbdb9Vp04dTZo0KdfZKAAAgOIkX4KTdLvD+Pnz5/NrcwAAAA4nz32cVq1aZfXYMAxduHBBs2fPVuvWrfOtYgAAAI4mz8GpW7duVo+dnJxUqVIlPfPMM3r//ffzq14AAAAOJ8/BKTs7uyDqAQAA4PDyrY8TAABAcWfqjFNUVJTpDU6fPv2BKwMAAODITAWnffv2mdqYk5PTQ1UGAADAkZkKTl9//XVB1wMAAMDh0ccJAADApDzfVSdJu3fv1meffaYzZ84oMzPTatnnn3+eLxUDAABwNHk+47Rs2TK1atVKycnJWrlypW7evKmDBw/qv//9r7y9vQuijgAAAA4hz8Fp4sSJ+vvf/65///vfcnNz08yZM3X48GG9/PLLqlGjRkHUEQAAwCHkOTidOHFCnTt3liS5ubkpPT1dTk5O+utf/6qPPvoo3ysIAADgKPIcnCpUqKCrV69KkqpVq6bvv/9ekvTLL7/o+vXr+Vs7AAAAB2I6OOUEpHbt2mnDhg2SpO7du2vYsGGKiIhQz5499eyzzxZMLQEAAByA6bvqGjdurBYtWqhbt27q3r27JGnUqFFydXXV1q1b9dJLL2n06NEFVlEAAAB7Mx2cNm3apE8++UQxMTGaMGGCXnrpJf35z3/WiBEjCrJ+AAAADsP0pbq2bdsqLi5OFy5c0AcffKBTp07p6aefVt26dTV58mSlpKQUZD0BAADsLs+dw8uWLavw8HBt2rRJR48eVffu3TVnzhzVqFFDL7zwQkHUEQAAwCE81E+uBAQE6O2339bo0aNVrlw5rV69Or/qBQAA4HAe6CdXJOmbb75RXFycVqxYIWdnZ7388ssaOHBgftYNAADAoeQpOJ0/f14LFy7UwoULdfz4cbVq1UqzZs3Syy+/rLJlyxZUHQEAAByC6eDUqVMnbdy4UT4+PurXr58GDBigevXqFWTdAAAAHIrpPk6urq5avny5fvzxR02ePDlfQ9OcOXPk7+8vDw8PBQcHa+fOnabWW7ZsmZycnNStW7d8qwsAAMDdmA5Oq1atUteuXeXi4pKvFYiPj1dUVJSio6O1d+9eBQYGKjQ0VBcvXrzneqdOndLf/vY3tW3bNl/rAwAAcDcPdVddfpg+fboiIiIUHh6uBg0aKDY2VmXKlFFcXNxd18nKylLv3r31zjvvqFatWoVYWwAAUJLZNThlZmZqz549CgkJscxzdnZWSEiItm3bdtf1xo8fr8qVK3MXHwAAKFQPPBxBfrh8+bKysrLk6+trNd/X11eHDx+2uc6WLVu0YMECJSUlmdpHRkaGMjIyLI/T0tIeuL4AAKBks/ulury4evWq+vbtq/nz58vHx8fUOjExMfL29rZMfn5+BVxLAABQXNn1jJOPj49cXFyUmppqNT81NVVVqlTJVf7EiRM6deqUunTpYpmXnZ0tSSpVqpSOHDmi2rVrW60zcuRIRUVFWR6npaURngAAwAOxa3Byc3NTs2bNlJCQYBlSIDs7WwkJCYqMjMxVvn79+jpw4IDVvNGjR+vq1auaOXOmzUDk7u4ud3f3Aqk/AAAoWewanCQpKipKYWFhat68uYKCgjRjxgylp6crPDxcktSvXz9Vq1ZNMTEx8vDwUKNGjazWL1++vCTlmg8AAJDf7B6cevTooUuXLmns2LFKSUlRkyZNtHbtWkuH8TNnzsjZuUh1xQIAAMWU3YOTJEVGRtq8NCdJiYmJ91x34cKF+V8hAAAAGziVAwAAYBLBCQAAwCSCEwAAgEkEJwAAAJMITgAAACYRnAAAAEwiOAEAAJhEcAIAADCJ4AQAAGASwQkAAMAkghMAAIBJBCcAAACTCE4AAAAmEZwAAABMIjgBAACYRHACAAAwieAEAABgEsEJAADAJIITAACASQQnAAAAkwhOAAAAJhGcAAAATCI4AQAAmERwAgAAMIngBAAAYBLBCQAAwCSCEwAAgEkEJwAAAJMITgAAACYRnAAAAEwiOAEAAJhEcAIAADCJ4AQAAGASwQkAAMAkghMAAIBJBCcAAACTCE4AAAAmEZwAAABMIjgBAACYRHACAAAwieAEAABgEsEJAADAJIITAACASQQnAAAAkwhOAAAAJhGcAAAATCI4AQAAmERwAgAAMIngBAAAYBLBCQAAwCSCEwAAgEkEJwAAAJMcIjjNmTNH/v7+8vDwUHBwsHbu3HnXsvPnz1fbtm1VoUIFVahQQSEhIfcsDwAAkF/sHpzi4+MVFRWl6Oho7d27V4GBgQoNDdXFixdtlk9MTFTPnj319ddfa9u2bfLz89Nzzz2nc+fOFXLNAQBASWP34DR9+nRFREQoPDxcDRo0UGxsrMqUKaO4uDib5ZcsWaIhQ4aoSZMmql+/vj7++GNlZ2crISGhkGsOAABKGrsGp8zMTO3Zs0chISGWec7OzgoJCdG2bdtMbeP69eu6efOmHnnkEZvLMzIylJaWZjUBAAA8CLsGp8uXLysrK0u+vr5W8319fZWSkmJqG2+99ZaqVq1qFb7uFBMTI29vb8vk5+f30PUGAAAlk90v1T2MSZMmadmyZVq5cqU8PDxslhk5cqSuXLlimc6ePVvItQQAAMVFKXvu3MfHRy4uLkpNTbWan5qaqipVqtxz3WnTpmnSpEnauHGjGjdufNdy7u7ucnd3z5f6AgCAks2uZ5zc3NzUrFkzq47dOR29W7Zsedf1pkyZonfffVdr165V8+bNC6OqAAAA9j3jJElRUVEKCwtT8+bNFRQUpBkzZig9PV3h4eGSpH79+qlatWqKiYmRJE2ePFljx47V0qVL5e/vb+kL5enpKU9PT7u1AwAAFH92D049evTQpUuXNHbsWKWkpKhJkyZau3atpcP4mTNn5Oz8vxNjc+fOVWZmpv74xz9abSc6Olrjxo0rzKoDAIASxu7BSZIiIyMVGRlpc1liYqLV41OnThV8hQAAAGwo0nfVAQAAFCaCEwAAgEkEJwAAAJMITgAAACYRnAAAAEwiOAEAAJhEcAIAADCJ4AQAAGASwQkAAMAkghMAAIBJBCcAAACTCE4AAAAmEZwAAABMIjgBAACYRHACAAAwieAEAABgEsEJAADAJIITAACASQQnAAAAkwhOAAAAJhGcAAAATCI4AQAAmERwAgAAMIngBAAAYBLBCQAAwCSCEwAAgEkEJwAAAJMITgAAACYRnAAAAEwiOAEAAJhEcAIAADCJ4AQAAGASwQkAAMAkghMAAIBJBCcAAACTCE4AAAAmEZwAAABMIjgBAACYRHACAAAwieAEAABgEsEJAADAJIITAACASQQnAAAAkwhOAAAAJhGcAAAATCI4AQAAmERwAgAAMIngBAAAYBLBCQAAwCSCEwAAgEkEJwAAAJMcIjjNmTNH/v7+8vDwUHBwsHbu3HnP8v/6179Uv359eXh46IknntCaNWsKqaYAAKAks3twio+PV1RUlKKjo7V3714FBgYqNDRUFy9etFl+69at6tmzpwYOHKh9+/apW7du6tatm77//vtCrjkAAChp7B6cpk+froiICIWHh6tBgwaKjY1VmTJlFBcXZ7P8zJkz1bFjRw0fPlyPP/643n33XTVt2lSzZ88u5JoDAICSxq7BKTMzU3v27FFISIhlnrOzs0JCQrRt2zab62zbts2qvCSFhobetTwAAEB+KWXPnV++fFlZWVny9fW1mu/r66vDhw/bXCclJcVm+ZSUFJvlMzIylJGRYXl85coVSVJaWtrDVB338dCH90a+VKNI4zmaTx7yON7gychzMV885DFMv5Y/1SjKCvB5mPMcNwzjvmXtGpwKQ0xMjN55551c8/38/OxQm5LD29veNSj6vCdxEPMFT8aHNsl7kr2rUAzwPCwKrl69Ku/7vGfYNTj5+PjIxcVFqampVvNTU1NVpUoVm+tUqVIlT+VHjhypqKgoy+Ps7Gz99NNPqlixopycnB6yBY4nLS1Nfn5+Onv2rLy8vOxdnSKL4/jwOIYPj2OYPziOD6+4H0PDMHT16lVVrVr1vmXtGpzc3NzUrFkzJSQkqFu3bpJuB5uEhARFRkbaXKdly5ZKSEjQ66+/bpm3YcMGtWzZ0mZ5d3d3ubu7W80rX758flTfoXl5eRXLJ3dh4zg+PI7hw+MY5g+O48Mrzsfwfmeactj9Ul1UVJTCwsLUvHlzBQUFacaMGUpPT1d4eLgkqV+/fqpWrZpiYmIkScOGDdPTTz+t999/X507d9ayZcu0e/duffTRR/ZsBgAAKAHsHpx69OihS5cuaezYsUpJSVGTJk20du1aSwfwM2fOyNn5fzf/tWrVSkuXLtXo0aP19ttvq06dOvriiy/UqFEjezUBAACUEHYPTpIUGRl510tziYmJueZ1795d3bt3L+BaFU3u7u6Kjo7OdXkSecNxfHgcw4fHMcwfHMeHxzH8HyfDzL13AAAAsP/I4QAAAEUFwQkAAMAkghNKvPbt21sNbwHAsZ06dUpOTk5KSkqyd1VQAhGcioCUlBQNGzZMAQEB8vDwkK+vr1q3bq25c+fq+vXrlnL79u1T9+7d5evrKw8PD9WpU0cRERE6evSopP+92VSuXFlXr1612keTJk00bty4wmyWhdn22dP+/fv1wgsvqHLlyvLw8JC/v7969Oihixcv5iobExMjFxcXTZ061ea2zLbX399fTk5OuaZJk+w7inNe/l+2jsXd2pUz9e/fv5Bb9OAc7bXZvn17m8f01q1bVsuXLVtmtd6MGTPk7+//4Acin/Xv39+q/hUrVlTHjh313XffSbr9yw8XLlzIdTf1ihUr9Mwzz6hChQoqXbq06tWrpwEDBmjfvn1W5TIzMzVlyhQFBgaqTJky8vHxUevWrfXJJ5/o5s2bVnX47evtiy++cNjBk/v3728ZE/FOiYmJcnJy0i+//CLp9mCP8+fPV8uWLeXl5SVPT081bNhQw4YN0/Hjxy3rjRs3zubzaePGjVbLX3nlFav9JSUlycnJSadOnZL0v+d3zlSuXDk1bNhQQ4cO1bFjxwrkWBQkgpODO3nypJ588kmtX79eEydO1L59+7Rt2za9+eab+uqrryxP4K+++kpPPfWUMjIytGTJEiUnJ2vx4sXy9vbWmDFjrLZ59epVTZs2zR7NycVs+34r582tMFy6dEnPPvusHnnkEa1bt07Jycn65JNPVLVqVaWnp+cqHxcXpzfffFNxcXG5luW1vePHj9eFCxespldffbXA2no/ea2/rWOxa9cuS1tWrFghSTpy5Ihl3syZMwu1TQ/KUV+bERERuZ4zpUr97wZqDw8PjR49ulBfQw+iY8eOlvonJCSoVKlS+v3vfy9JcnFxUZUqVaza9dZbb6lHjx5q0qSJVq1apSNHjmjp0qWqVauWRo4caSmXmZmp0NBQTZo0SYMGDdLWrVu1c+dODR06VB988IEOHjxoKevh4aHJkyfr559/LryGFzDDMNSrVy+99tprev7557V+/XodOnRICxYskIeHh9577z2r8g0bNsz1fGrXrp1luYeHhxYsWGAqAG3cuFEXLlzQ/v37NXHiRCUnJyswMFAJCQn53s4CZcChhYaGGtWrVzeuXbtmc3l2draRnp5u+Pj4GN26dbNZ5ueffzYMwzB++OEHQ5IxfPhww9PT00hNTbWUCQwMNKKjo/O7+vdlpn2GYRiSjA8//NDo0qWLUaZMGSM6Otq4deuWMWDAAMPf39/w8PAw6tata8yYMcNq/bCwMKNr167GuHHjDB8fH6NcuXLGX/7yFyMjI8NS5umnnzZeffVVY/jw4UaFChUMX19fq2OxcuVKo1SpUsbNmzfv257ExESjWrVqRmZmplG1alXj22+/faD2GoZh1KxZ0/j73/9+330WprzU/37HwjAM4+uvvzYkWZ6jRYkjvjaffvppY9iwYfdcHh4eblSsWNGYM2eOZf7f//53o2bNmqb2URhyXrd32rx5syHJuHjxouV47du3zzAMw9i2bZshyZg5c6bN7d35vJw8ebLh7Oxs7N27N1e5zMxMy/8zLCzM+P3vf2/Ur1/fGD58uKXMypUrDUf96LR13AzD+nX26aefGpKML7/80uY27jxW0dHRRmBg4F33l7O8Q4cORvfu3S3z9+3bZ0gyfvjhB8MwjFz/rxxZWVlG+/btjZo1axq3bt0y3U5744yTA/u///s/rV+/XkOHDlXZsmVtlnFyctK6det0+fJlvfnmmzbL/PYnZnr27KmAgACNHz8+v6ucJ2bbl2PcuHF68cUXdeDAAQ0YMEDZ2dmqXr26/vWvf+nQoUMaO3as3n77bX322WdW20hISFBycrISExP16aef6vPPP8/1w8+LFi1S2bJltWPHDk2ZMkXjx4/Xhg0bJN3+fcRbt25p5cqV9/3l7AULFqhnz55ydXVVz549tWDBggdur6PJa/3vdSyKuqL82vTy8tKoUaM0fvx4m2dMHdG1a9e0ePFiBQQEqGLFirmWf/rpp/L09NSQIUNsrn/n83LJkiUKCQnRk08+maucq6ur1f/TxcVFEydO1AcffKAff/wxH1pif59++qnq1aunF154webyB3kPmjRpklasWKHdu3fnaT1nZ2cNGzZMp0+f1p49e/K8X3shODmw48ePyzAM1atXz2q+j4+PPD095enpqbfeestyirR+/fqmtptz3f6jjz7SiRMn8r3eZpltX45evXopPDxctWrVUo0aNeTq6qp33nlHzZs312OPPabevXsrPDw8V3Byc3NTXFycGjZsqM6dO2v8+PGaNWuWsrOzLWUaN26s6Oho1alTR/369VPz5s0tp4+feuopvf322+rVq5d8fHzUqVMnTZ06NdePTaelpWn58uXq06ePJKlPnz767LPPdO3atQdqr3T78kPOspxp8+bND3K4H1pe6n+/Y1HUOfJr88MPP7R6vrzxxhu5ygwZMkQeHh6aPn36A+2jMHz11VeWNpQrV06rVq1SfHy81S9J5Dh69Khq1apldelu+vTpVsfhypUrkqRjx46Z/n9I0osvvqgmTZooOjr64RtVCO48bjlTp06dLMuPHj2a63n7+uuvW8pWr17datmBAwesthUUFJRrn02bNtXLL7+c6/3LjJz/RU5/qKKA4FQE7dy5U0lJSWrYsKEyMjLuexbEltDQULVp0yZXHwtH8Nv25WjevHmusnPmzFGzZs1UqVIleXp66qOPPtKZM2esyuR0AM3RsmVLXbt2TWfPnrXMa9y4sdU6jz76qFXH7wkTJiglJUWxsbFq2LChYmNjVb9+fR04cMBS5tNPP1Xt2rUVGBgo6Xan3po1ayo+Pv6B2itJw4cPV1JSktVk6zjYk636P+ixKOoc4bXZu3dvq+fLnf17cri7u2v8+PGaNm2aLl++/ED7KWi/+93vLG3YuXOnQkND1alTJ50+fdrU+gMGDFBSUpLmzZun9PR0y//iQf4nkydP1qJFi5ScnJzndQvbncctZ/r444/vuc6oUaOUlJSksWPH5vpyU69ePatt5fRL/K333ntPmzdv1vr16/NU35z/hyOfbf8tgpMDCwgIkJOTk44cOWI1v1atWgoICFDp0qUlSXXr1pUkHT58OE/bnzRpkuLj43PdcVJYzLYvx28viSxbtkx/+9vfNHDgQK1fv15JSUkKDw9XZmZmnuvi6upq9djJycnqjJQkVaxYUd27d9e0adOUnJysqlWrWnXkXbBggQ4ePKhSpUpZpkOHDlk6Rue1vdLtMxgBAQFWk61yhSEv9b/fsSjqHPm16e3tbfV88fHxsVmuT58+qlmzZq7OwI6ibNmylja0aNFCH3/8sdLT0zV//vxcZevUqaOTJ09adXgvX768AgICVK1aNauydevWzfP/o127dgoNDbUZQh3NncctZ7rzGNSpUyfX87ZSpUoKCAhQ5cqVc23Pzc3Nalt+fn4291u7dm1FRERoxIgReQqnOWH0scceM72OvRGcHFjFihXVoUMHzZ49+559EZ577jn5+PhoypQpNpfn3IL6W0FBQfrDH/6gESNG5Ed188xs++7m22+/VatWrTRkyBA9+eSTCggIsHl5Y//+/fr1118tj7dv3y5PT8+7vgGY4ebmptq1a1vqfeDAAe3evVuJiYlW384SExO1bds2HT58+KHba29m62/mWBR1xeG16ezsrJiYGM2dO7dIXCZxcnKSs7Oz1Ws5R8+ePXXt2jV9+OGH991Or169tHHjRpuh9ObNm3f9f06aNEn//ve/tW3btrxX3oH07NlTR44c0Zdffpnv2x47dqyOHj2aa7iLu8nOztasWbP02GOP2exz5qgITg7uww8/1K1bt9S8eXPFx8crOTlZR44c0eLFi3X48GG5uLiobNmy+vjjj7V69Wq98MIL2rhxo06dOqXdu3frzTffzDXGxp0mTJig//73v7m+gRQWM+27mzp16mj37t1at26djh49qjFjxmjXrl25ymVmZmrgwIE6dOiQ1qxZo+joaEVGRtrsK2HLV199pT59+uirr77S0aNHdeTIEU2bNk1r1qxR165dJd0+wxIUFKR27dqpUaNGlqldu3Zq0aKFpWN0Xtt79epVpaSkWE1paWlmD2++M1N/s8eiqCsOr83OnTsrODhY8+bNK7B9PKiMjAzLcz45OVmvvvqqrl27pi5duuQq27JlS73xxht64403FBUVpS1btuj06dPavn27FixYYAld0u3+PK1bt9azzz6rOXPmaP/+/Tp58qQ+++wzPfXUU3e9rf6JJ55Q7969NWvWrAJtd0H705/+pD/+8Y/605/+pPHjx2vHjh06deqUNm3apPj4+Hu+596Pr6+voqKi7nqM/u///k8pKSk6efKkVq1apZCQEO3cuVMLFix4qP0WOvvczIe8OH/+vBEZGWk89thjhqurq+Hp6WkEBQUZU6dONdLT0y3ldu3aZfzhD38wKlWqZLi7uxsBAQHGoEGDjGPHjhmGcfdbQgcNGmRIsstwBIZhrn2SjJUrV1qtd+PGDaN///6Gt7e3Ub58eWPw4MHGiBEjrG6fzbk9d+zYsUbFihUNT09PIyIiwrhx44aljK1buLt27WqEhYUZhmEYJ06cMCIiIoy6desapUuXNsqXL2+0aNHC+OSTTwzDMIyMjAyjYsWKxpQpU2y2b/LkyUblypWNzMxM0+01jNvDEUjKNf3lL395gKOcf+5V/ytXruTpWBTl4QgMw/Fem2aGI/jt8q1btxqSHG44gjuf8+XKlTNatGhhLF++3DCMux+v+Ph4o3379oa3t7fh6upqVK9e3ejVq5exfft2q3I3btwwYmJijCeeeMLw8PAwHnnkEaN169bGwoULLcOO2Lq1/4cffjDc3NyK9HAEhnF7GIDY2FgjODjYKFu2rOHm5mbUqlXLiIiIMA4dOmRZz+xwBHe6cuWK4ePjY3M4gpypTJkyxuOPP24MGTLE8hooSpwM4wF6ygFFRP/+/fXLL7/oiy++sHdVAADFAJfqAAAATCI4AUARsHnz5lzj89w5ASgcXKoDgCLg119/1blz5+66PCAgoBBrA5RcBCcAAACTuFQHAABgEsEJAADAJIITAACASQQnAAAAkwhOAHCHxMREOTk53fV35Gzx9/fXjBkzCqxOABwHwQlAkdK/f385OTnZ/J23oUOHysnJSf379y/8igEoEQhOAIocPz8/LVu2TL/++qtl3o0bN7R06VLVqFHDjjUDUNwRnAAUOU2bNpWfn58+//xzy7zPP/9cNWrU0JNPPmmZl5GRoddee02VK1eWh4eH2rRpo127dllta82aNapbt65Kly6t3/3udzp16lSu/W3ZskVt27ZV6dKl5efnp9dee03p6ekF1j4AjovgBKBIGjBggD755BPL47i4OIWHh1uVefPNN7VixQotWrRIe/fuVUBAgEJDQ/XTTz9Jks6ePas//OEP6tKli5KSkvTnP/9ZI0aMsNrGiRMn1LFjR7300kv67rvvFB8fry1btigyMrLgGwnA4RCcABRJffr00ZYtW3T69GmdPn1a3377rfr06WNZnp6errlz52rq1Knq1KmTGjRooPnz56t06dJasGCBJGnu3LmqXbu23n//fdWrV0+9e/fO1T8qJiZGvXv31uuvv646deqoVatWmjVrlv7xj3/oxo0bhdlkAA6glL0rAAAPolKlSurcubMWLlwowzDUuXNn+fj4WJafOHFCN2/eVOvWrS3zXF1dFRQUpOTkZElScnKygoODrbbbsmVLq8f79+/Xd999pyVLlljmGYah7Oxs/fDDD3r88ccLonkAHBTBCUCRNWDAAMslszlz5hTIPq5du6a//OUveu2113ItoyM6UPIQnAAUWR07dlRmZqacnJwUGhpqtax27dpyc3PTt99+q5o1a0qSbt68qV27dun111+XJD3++ONatWqV1Xrbt2+3ety0aVMdOnRIAQEBBdcQAEUGfZwAFFkuLi5KTk7WoUOH5OLiYrWsbNmyGjx4sIYPH661a9fq0KFDioiI0PXr1zVw4EBJ0iuvvKJjx45p+PDhOnLkiJYuXaqFCxdabeett97S1q1bFRkZqaSkJB07dkxffvklncOBEorgBKBI8/LykpeXl81lkyZN0ksvvaS+ffuqadOmOn78uNatW6cKFSpIun2pbcWKFfriiy8UGBio2NhYTZw40WobjRs31qZNm3T06FG1bdtWTz75pMaOHauqVasWeNsAOB4nwzAMe1cCAACgKOCMEwAAgEkEJwAAAJMITgAAACYRnAAAAEwiOAEAAJhEcAIAADCJ4AQAAGASwQkAAMAkghMAAIBJBCcAAACTCE4AAAAmEZwAAABM+n/XjH+dFEOQEQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}